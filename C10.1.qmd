# Pruebas de Hipótesis Paramétricas en R

En la investigación agronómica, es fundamental tomar decisiones basadas en datos. Las pruebas de hipótesis permiten evaluar si los resultados observados en una muestra pueden generalizarse a la población de interés o si son producto del azar. Este capítulo guía al estudiante en la aplicación de pruebas de hipótesis paramétricas utilizando R, desde la formulación de hipótesis hasta la interpretación de resultados, empleando ejemplos prácticos y reales del ámbito agronómico (López & González, 2018).

## Fundamentos de las pruebas de hipótesis

Una prueba de hipótesis es un procedimiento estadístico que permite decidir, con un nivel de confianza predefinido, si una afirmación sobre un parámetro poblacional es compatible con los datos muestrales. El proceso general incluye:

1.  Plantear la hipótesis nula ($H_0$) y la alternativa ($H_a$).

2.  Seleccionar el estadístico de prueba adecuado según el tipo de dato y los supuestos.

3.  Calcular el valor del estadístico y el valor-p.

4.  Comparar el valor-p con el nivel de significancia ($\alpha$), generalmente 0.05.

5.  Tomar una decisión: rechazar o no rechazar $H_0$.

**Criterios de selección de la prueba:**

1.  Tipo de variable (cuantitativa o cualitativa).

2.  Tamaño de la muestra.

3.  Conocimiento de la varianza poblacional.

4.  Independencia o dependencia entre muestras.

5.  Homogeneidad de varianzas.

## Prueba de hipótesis sobre una media

Esta prueba se utiliza para determinar si la media de una población difiere de un valor específico. Es útil, por ejemplo, para verificar si el peso promedio de semillas, el rendimiento de un cultivo o el contenido de un nutriente cumple con un estándar.

### Criterios de selección

1.  Variable cuantitativa continua.

2.  La muestra debe ser aleatoria.

3.  Si la varianza poblacional es conocida y la muestra es grande ($n \geq 30$), se usa la prueba z.

4.  Si la varianza es desconocida y la muestra es pequeña ($n<30$), se usa la prueba t de Student.

### Fórmulas

**a) Prueba z (varianza conocida):**

$$\huge z = \frac{\bar{x} - \mu_0}{\sigma / \sqrt{n}}  $$​​

**b) Prueba t (varianza desconocida):**

$$\huge t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}} $$

donde $gl = n-1$.

### Ejemplo hipotético

Supóngase que se afirma que el peso promedio de semillas de maíz es de 250 mg. Se toma una muestra de 20 semillas, obteniéndose una media de 242 mg y una desviación estándar de 15 mg. Se desea saber, con un nivel de significancia del 5%, si el peso medio difiere del valor afirmado.

**1. Planteamiento de hipótesis:**

1.  $H_0: \mu = 250$ mg

2.  $H_a: \mu \neq 250$ mg

**2. Cálculo del estadístico:**

$$\Large t = \frac{242 - 250}{15 / \sqrt{20}} = \frac{-8}{3.354} = -2.39 $$

**3. Región crítica:**

Para $gl=19$ y $\alpha = 0.05$ (bilateral), el valor crítico es $\pm 2.093$.

**4. Decisión:**

Como $|-2.39| > 2.093$, se rechaza H_0.

**5. Conclusión:**

Con un 5% de significancia, existe evidencia de que el peso medio difiere de 250 mg.

### Código en R explicado

```{r message=FALSE, warning=FALSE}
# Instalar paquete si no está instalado
## Para manipulación y visualización de datos
if (!require(BSDA)) install.packages("BSDA")


# Prueba t con estadísticos resumidos usando tsum.test()
tsum.test(mean.x = 242,
          s.x = 15,
          n.x = 20,
          mu = 250,
          alternative = "two.sided",
          conf.level = 0.95)
```

**Parámetros de `tsum.test()`:**

1.  **mean.x**: media muestral (242 mg)

2.  **s.x**: desviación estándar muestral (15 mg)

3.  **n.x**: tamaño de muestra (20)

4.  **mu**: valor hipotético bajo H₀ (250 mg)

5.  **alternative**: tipo de prueba ("two.sided" para bilateral)

6.  **conf.level**: nivel de confianza (0.95 para 95%)

## Prueba de hipótesis sobre dos medias

Permite comparar si las medias de dos poblaciones son iguales o diferentes. Es útil, por ejemplo, para comparar el rendimiento de dos variedades de cultivo, el efecto de dos tratamientos o la altura de plantas de dos especies.

### Criterios de selección

1.  Las muestras pueden ser independientes (grupos distintos) o dependientes (mediciones pareadas).

2.  Se debe verificar si las varianzas son iguales o diferentes.

3.  Si las muestras son grandes ($n_1, n_2 \geq 30$), se puede usar la prueba z; si son pequeñas y la varianza es desconocida, se usa la prueba t.

### Fórmulas

**a) Muestras independientes, varianzas iguales (t “pooled”):**

$$\huge t = \frac{\bar{x}_1 - \bar{x}_2}{s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}  $$

donde

$$\huge s_p^2 = \frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}  $$

**b) Muestras independientes, varianzas diferentes (Welch):**

$$\huge t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}} $$

**c) Muestras dependientes (pareadas):**

$$\huge t = \frac{\bar{d}}{s_d / \sqrt{n}}$$ ​

donde $\bar{d}$ es la media de las diferencias y $s_d$​ su desviación estándar.

### Ejemplo hipotético (independientes, varianzas iguales)

Se comparan las alturas de dos especies forestales.

1.  Especie 1: $\bar{x}_1 = 25.97$ m, $s_1 = 1.36$, $n_1 = 13$

2.  Especie 2: $\bar{x}_2 = 25.39$ m, $s_2 = 1.77$, $n_2 = 14$

**1. Hipótesis:**

1.  $H_0: \mu_1 = \mu_2$

2.  $H_a: \mu_1 \neq \mu_2$

**2. Cálculo:**

$$\LARGE s_p^2 = \frac{12 \times 1.36^2 + 13 \times 1.77^2}{25} = 2.30  $$

$$\huge s_p = \sqrt{2.30} = 1.52  $$

$$\huge t = \frac{25.97 - 25.39}{1.52 \sqrt{\frac{1}{13} + \frac{1}{14}}} = 0.94$$

**3. Decisión:** Para $gl=25$, $t_{0.025} = 2.060$. Como $0.94 < 2.060$, no se rechaza $H_0$.

### Código en R explicado

```{r}
# Datos del ejercicio
mean1 <- 25.97; s1 <- 1.36; n1 <- 13  # Especie 1
mean2 <- 25.39; s2 <- 1.77; n2 <- 14  # Especie 2

# Prueba t para dos muestras independientes con varianzas iguales
tsum.test(mean.x = mean1, s.x = s1, n.x = n1,
          mean.y = mean2, s.y = s2, n.y = n2,
          alternative = "two.sided",
          mu = 0,                    # diferencia hipotética (H₀: μ₁ - μ₂ = 0)
          var.equal = TRUE,          # asume varianzas iguales (pooled)
          conf.level = 0.95)         # nivel de confianza
```

**Parámetros de `tsum.test()` para dos muestras:**

1.  **mean.x, s.x, n.x**: estadísticos de la muestra 1

2.  **mean.y, s.y, n.y**: estadísticos de la muestra 2

3.  **mu**: diferencia hipotética bajo H₀ (0 para igualdad de medias)

4.  **var.equal = TRUE**: usa varianza pooled (varianzas iguales)

5.  **alternative**: "two.sided" para prueba bilateral

### Ejemplo hipotético (pareadas)

Se evalúa el efecto de una capacitación en 10 empleados, midiendo el puntaje antes y después.

**1. Hipótesis:**

1.  $H_0: \mu_D = 0$ (no hay diferencia)

2.  $H_a: \mu_D \neq 0$ (hay diferencia)

**2. Cálculo:**\
Supóngase que la media de las diferencias es $-0.4$ y la desviación estándar $0.8$ .

$$\huge t = \frac{-0.4}{0.8/\sqrt{10}} = -1.58 $$

**3. Decisión:**\
Para $gl = 9$, $t_{0.05} = 2.262$ . Como $|-1.58| < 2.262$, no se rechaza $H_0$.

### Código en R explicado

```{r}
# Datos del ejercicio (estadísticos de las diferencias)
n <- 10
mean_diff <- -0.4    # media de diferencias (antes - después)
sd_diff <- 0.8       # desviación estándar de diferencias

# Prueba t pareada usando estadísticos resumidos
# Para muestras pareadas, usamos tsum.test() con una sola muestra
# (las diferencias)
tsum.test(mean.x = mean_diff,
          s.x = sd_diff,
          n.x = n,
          mu = 0,                    # H₀: μ_D = 0
          alternative = "two.sided",
          conf.level = 0.95)
```

**Una prueba t pareada es equivalente a una prueba t de una muestra sobre las diferencias.**

Por eso usamos `tsum.test()` con:

1.  **mean.x**: media de las diferencias (-0.4)

2.  **s.x**: desviación estándar de las diferencias (0.8)

3.  **n.x**: número de pares (10)

4.  **mu = 0**: hipótesis nula (no hay diferencia promedio)

**Alternativa con datos individuales:**

Si tuvieras los datos originales:

```{r}
# Datos
antes <- c(9.0,7.3,6.7,5.3,8.7,6.3,7.9,7.3,8.0,8.5)
despues <- c(9.2,8.2,8.5,4.9,8.9,5.8,8.2,7.8,9.5,8.0)
# Test para datos pareados
t.test(antes, despues,
       paired = TRUE,
       alternative = "two.sided",
       conf.level = 0.95)
```

Por eso usamos `t.test()` con:

1.  **antes**: Vector numerico con los datos iniciales.

2.  **despues**: Vector numerico con los datos finales o pareados.

3.  **paired**: si es una prueba de t pareada (TRUE)

4.  **alternative**: "two.sided" hace referencia a que compara una igualdad.

## Prueba de hipótesis sobre una proporción

Permite determinar si la proporción de una característica en la población es igual a un valor específico. Por ejemplo, si la proporción de agricultores que adopta una tecnología supera el 60%.

### Criterios de selección

1.  Variable cualitativa dicotómica.

2.  Tamaño muestral suficiente para aproximación normal ($np_0 > 5np$ y $n(1-p_0) > 5$).

**Fórmula**

$$\huge z = \frac{\hat{p} - p_0}{\sqrt{p_0(1-p_0)/n}}$$

### Ejemplo hipotético

De 180 agricultores, 120 adoptaron un fertilizante. Se desea saber si la proporción es diferente de 0.60.

$$\LARGE \hat{p} = \frac{120}{180} = 0.667$$

$$\LARGE z = \frac{0.667 - 0.60}{\sqrt{0.60 \times 0.40 / 180}} = 1.56$$

Para $\alpha = 0.05$, $z_{0.025} = 1.96$. Como $1.56 < 1.96$, no se rechaza $H_0$.

### Código en R explicado

```{r}
prop.test(x = 120, n = 180,
          p = 0.60,                # valor bajo H0
          alternative = "two.sided",
          correct = FALSE)         # sin corrección de continuidad
```

1.  **x**: número de éxitos.

2.  **n**: tamaño de la muestra.

3.  **p**: proporción bajo $H_0$​.

## Prueba de hipótesis sobre dos proporciones

Permite comparar si la proporción de una característica es igual en dos poblaciones. Por ejemplo, comparar la proporción de adopción de una tecnología entre hombres y mujeres.

### Criterios de selección

1.  Variable cualitativa dicotómica.

2.  Muestras independientes.

3.  Tamaño muestral suficiente.

### Fórmulas

$$\huge \hat{p}_c = \frac{x_1 + x_2}{n_1 + n_2}$$

$$\LARGE z = \frac{\hat{p}_1 - \hat{p}_2}{\sqrt{\hat{p}_c(1-\hat{p}_c)\left(\frac{1}{n_1} + \frac{1}{n_2}\right)}}$$

### Ejemplo hipotético

En una encuesta, 110 de 200 hombres y 210 de 300 mujeres respondieron. ¿Existe diferencia en las proporciones?

$$\LARGE \hat{p}_1 = 0.55,; \hat{p}_2 = 0.70$$

$$\LARGE \hat{p}_c = \frac{110+210}{200+300} = 0.64$$

$$\LARGE z = \frac{0.55 - 0.70}{\sqrt{0.64 \times 0.36 \left(\frac{1}{200} + \frac{1}{300}\right)}} = -3.42$$

Como $|-3.42| > 1.96$, se rechaza $H_0$.

### Código en R explicado

```{r}
xp <- c(110, 210)   # éxitos en cada grupo
np <- c(200, 300)   # tamaño de cada grupo

prop.test(xp, np,
          alternative = "two.sided",
          correct = FALSE)
```

1.  **xp**: vector de éxitos.

2.  **np**: vector de tamaños.

## Prueba de hipótesis sobre varianzas

Permite verificar si la variabilidad de un proceso cumple con un estándar o si dos poblaciones tienen la misma varianza. Es útil, por ejemplo, para comparar la uniformidad de dos métodos de riego.

### Criterios de selección

1.  Variable cuantitativa continua.

2.  Normalidad de los datos.

### Fórmulas

**a) Una varianza (**$\chi^2$):

$$\huge \chi^2 = \frac{(n-1)s^2}{\sigma_0^2} $$​

**b) Dos varianzas (F de Fisher):**

$$\huge F = \frac{s_1^2}{s_2^2}$$

### Ejemplo hipotético (dos varianzas)

Se desea comparar la varianza de dos tratamientos de riego.

```{r}
trat1 <- c(10,12,11,13,12,11,14,13)
trat2 <- c(9,10,11,10,12,10,11,10)

var.test(trat1, trat2,
         alternative = "two.sided",
         conf.level = 0.95)
```

`var.test`: realiza la prueba F para comparar varianzas.

# Pruebas de Hipótesis Paramétricas en R

En la investigación agronómica, es fundamental tomar decisiones basadas en datos. Las pruebas de hipótesis permiten evaluar si los resultados observados en una muestra pueden generalizarse a la población de interés o si son producto del azar. Este capítulo guía al estudiante en la aplicación de pruebas de hipótesis paramétricas utilizando R, desde la formulación de hipótesis hasta la interpretación de resultados, empleando ejemplos prácticos y reales del ámbito agronómico (López & González, 2018).

## Fundamentos de las pruebas de hipótesis

Una prueba de hipótesis es un procedimiento estadístico que permite decidir, con un nivel de confianza predefinido, si una afirmación sobre un parámetro poblacional es compatible con los datos muestrales. El proceso general incluye:

1.  Plantear la hipótesis nula ($H_0$) y la alternativa ($H_a$).

2.  Seleccionar el estadístico de prueba adecuado según el tipo de dato y los supuestos.

3.  Calcular el valor del estadístico y el valor-p.

4.  Comparar el valor-p con el nivel de significancia ($\alpha$), generalmente 0.05.

5.  Tomar una decisión: rechazar o no rechazar $H_0$.

**Criterios de selección de la prueba:**

1.  Tipo de variable (cuantitativa o cualitativa).

2.  Tamaño de la muestra.

3.  Conocimiento de la varianza poblacional.

4.  Independencia o dependencia entre muestras.

5.  Homogeneidad de varianzas.

## Prueba de hipótesis sobre una media

Esta prueba se utiliza para determinar si la media de una población difiere de un valor específico. Es útil, por ejemplo, para verificar si el peso promedio de semillas, el rendimiento de un cultivo o el contenido de un nutriente cumple con un estándar.

### Criterios de selección

1.  Variable cuantitativa continua.

2.  La muestra debe ser aleatoria.

3.  Si la varianza poblacional es conocida y la muestra es grande ($n \geq 30$), se usa la prueba z.

4.  Si la varianza es desconocida y la muestra es pequeña ($n<30$), se usa la prueba t de Student.

### Fórmulas

**a) Prueba z (varianza conocida):**

$$\huge z = \frac{\bar{x} - \mu_0}{\sigma / \sqrt{n}}  $$​​

**b) Prueba t (varianza desconocida):**

$$\huge t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}} $$

donde $gl = n-1$.

### Ejemplo hipotético

Supóngase que se afirma que el peso promedio de semillas de maíz es de 250 mg. Se toma una muestra de 20 semillas, obteniéndose una media de 242 mg y una desviación estándar de 15 mg. Se desea saber, con un nivel de significancia del 5%, si el peso medio difiere del valor afirmado.

**1. Planteamiento de hipótesis:**

1.  $H_0: \mu = 250$ mg

2.  $H_a: \mu \neq 250$ mg

**2. Cálculo del estadístico:**

$$\Large t = \frac{242 - 250}{15 / \sqrt{20}} = \frac{-8}{3.354} = -2.39 $$

**3. Región crítica:**

Para $gl=19$ y $\alpha = 0.05$ (bilateral), el valor crítico es $\pm 2.093$.

**4. Decisión:**

Como $|-2.39| > 2.093$, se rechaza H_0.

**5. Conclusión:**

Con un 5% de significancia, existe evidencia de que el peso medio difiere de 250 mg.

### Código en R explicado

```{r message=FALSE, warning=FALSE}
# Instalar paquete si no está instalado
## Para realizar pruebas de hipotesis
if (!require(BSDA)) install.packages("BSDA")
if (!require(EnvStats)) install.packages("EnvStats")


# Prueba t con estadísticos resumidos usando tsum.test()
tsum.test(mean.x = 242,
          s.x = 15,
          n.x = 20,
          mu = 250,
          alternative = "two.sided",
          conf.level = 0.95)
```

**Parámetros de `tsum.test()`:**

1.  **mean.x**: media muestral (242 mg)

2.  **s.x**: desviación estándar muestral (15 mg)

3.  **n.x**: tamaño de muestra (20)

4.  **mu**: valor hipotético bajo H₀ (250 mg)

5.  **alternative**: tipo de prueba ("two.sided" para bilateral)

6.  **conf.level**: nivel de confianza (0.95 para 95%)

## Prueba de hipótesis sobre dos medias

Permite comparar si las medias de dos poblaciones son iguales o diferentes. Es útil, por ejemplo, para comparar el rendimiento de dos variedades de cultivo, el efecto de dos tratamientos o la altura de plantas de dos especies.

### Criterios de selección

1.  Las muestras pueden ser independientes (grupos distintos) o dependientes (mediciones pareadas).

2.  Se debe verificar si las varianzas son iguales o diferentes.

3.  Si las muestras son grandes ($n_1, n_2 \geq 30$), se puede usar la prueba z; si son pequeñas y la varianza es desconocida, se usa la prueba t.

### Fórmulas

**a) Muestras independientes, varianzas iguales (t “pooled”):**

$$\huge t = \frac{\bar{x}_1 - \bar{x}_2}{s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}  $$

donde

$$\huge s_p^2 = \frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}  $$

**b) Muestras independientes, varianzas diferentes (Welch):**

$$\huge t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}} $$

**c) Muestras dependientes (pareadas):**

$$\huge t = \frac{\bar{d}}{s_d / \sqrt{n}}$$ ​

donde $\bar{d}$ es la media de las diferencias y $s_d$​ su desviación estándar.

### Ejemplo hipotético (independientes, varianzas iguales)

Se comparan las alturas de dos especies forestales.

1.  Especie 1: $\bar{x}_1 = 25.97$ m, $s_1 = 1.36$, $n_1 = 13$

2.  Especie 2: $\bar{x}_2 = 25.39$ m, $s_2 = 1.77$, $n_2 = 14$

**1. Hipótesis:**

1.  $H_0: \mu_1 = \mu_2$

2.  $H_a: \mu_1 \neq \mu_2$

**2. Cálculo:**

$$\LARGE s_p^2 = \frac{12 \times 1.36^2 + 13 \times 1.77^2}{25} = 2.30  $$

$$\huge s_p = \sqrt{2.30} = 1.52  $$

$$\huge t = \frac{25.97 - 25.39}{1.52 \sqrt{\frac{1}{13} + \frac{1}{14}}} = 0.94$$

**3. Decisión:** Para $gl=25$, $t_{0.025} = 2.060$. Como $0.94 < 2.060$, no se rechaza $H_0$.

### Código en R explicado

```{r}
# Datos del ejercicio
mean1 <- 25.97; s1 <- 1.36; n1 <- 13  # Especie 1
mean2 <- 25.39; s2 <- 1.77; n2 <- 14  # Especie 2

# Prueba t para dos muestras independientes con varianzas iguales
tsum.test(mean.x = mean1, s.x = s1, n.x = n1,
          mean.y = mean2, s.y = s2, n.y = n2,
          alternative = "two.sided",
          mu = 0,        # diferencia hipotética (H₀: μ₁ - μ₂ = 0)
          var.equal = TRUE,          # asume varianzas iguales (pooled)
          conf.level = 0.95)         # nivel de confianza
```

**Parámetros de `tsum.test()` para dos muestras:**

1.  **mean.x, s.x, n.x**: estadísticos de la muestra 1

2.  **mean.y, s.y, n.y**: estadísticos de la muestra 2

3.  **mu**: diferencia hipotética bajo H₀ (0 para igualdad de medias)

4.  **var.equal = TRUE**: usa varianza pooled (varianzas iguales)

5.  **alternative**: "two.sided" para prueba bilateral

### Ejemplo hipotético (pareadas)

Se evalúa el efecto de una capacitación en 10 empleados, midiendo el puntaje antes y después.

**1. Hipótesis:**

1.  $H_0: \mu_D = 0$ (no hay diferencia)

2.  $H_a: \mu_D \neq 0$ (hay diferencia)

**2. Cálculo:**\
Supóngase que la media de las diferencias es $-0.4$ y la desviación estándar $0.8$ .

$$\huge t = \frac{-0.4}{0.8/\sqrt{10}} = -1.58 $$

**3. Decisión:**\
Para $gl = 9$, $t_{0.05} = 2.262$ . Como $|-1.58| < 2.262$, no se rechaza $H_0$.

### Código en R explicado

```{r}
# Datos del ejercicio (estadísticos de las diferencias)
n <- 10
mean_diff <- -0.4    # media de diferencias (antes - después)
sd_diff <- 0.8       # desviación estándar de diferencias

# Prueba t pareada usando estadísticos resumidos
# Para muestras pareadas, usamos tsum.test() con una sola muestra
# (las diferencias)
tsum.test(mean.x = mean_diff,
          s.x = sd_diff,
          n.x = n,
          mu = 0,                    # H₀: μ_D = 0
          alternative = "two.sided",
          conf.level = 0.95)
```

**Una prueba t pareada es equivalente a una prueba t de una muestra sobre las diferencias.**

Por eso usamos `tsum.test()` con:

1.  **mean.x**: media de las diferencias (-0.4)

2.  **s.x**: desviación estándar de las diferencias (0.8)

3.  **n.x**: número de pares (10)

4.  **mu = 0**: hipótesis nula (no hay diferencia promedio)

**Alternativa con datos individuales:**

Si tuvieras los datos originales:

```{r}
# Datos
antes <- c(9.0,7.3,6.7,5.3,8.7,6.3,7.9,7.3,8.0,8.5)
despues <- c(9.2,8.2,8.5,4.9,8.9,5.8,8.2,7.8,9.5,8.0)
# Test para datos pareados
t.test(antes, despues,
       paired = TRUE,
       alternative = "two.sided",
       conf.level = 0.95)
```

Por eso usamos `t.test()` con:

1.  **antes**: Vector numerico con los datos iniciales.

2.  **despues**: Vector numerico con los datos finales o pareados.

3.  **paired**: si es una prueba de t pareada (TRUE)

4.  **alternative**: "two.sided" hace referencia a que compara una igualdad.

## Prueba de hipótesis sobre una proporción

Permite determinar si la proporción de una característica en la población es igual a un valor específico. Por ejemplo, si la proporción de agricultores que adopta una tecnología supera el 60%.

### Criterios de selección

1.  Variable cualitativa dicotómica.

2.  Tamaño muestral suficiente para aproximación normal ($np_0 > 5np$ y $n(1-p_0) > 5$).

**Fórmula**

$$\huge z = \frac{\hat{p} - p_0}{\sqrt{p_0(1-p_0)/n}}$$

### Ejemplo hipotético

De 180 agricultores, 120 adoptaron un fertilizante. Se desea saber si la proporción es diferente de 0.60.

$$\LARGE \hat{p} = \frac{120}{180} = 0.667$$

$$\LARGE z = \frac{0.667 - 0.60}{\sqrt{0.60 \times 0.40 / 180}} = 1.56$$

Para $\alpha = 0.05$, $z_{0.025} = 1.96$. Como $1.56 < 1.96$, no se rechaza $H_0$.

### Código en R explicado

```{r}
prop.test(x = 120, n = 180,
          p = 0.60,                # valor bajo H0
          alternative = "two.sided",
          correct = FALSE)         # sin corrección de continuidad
```

1.  **x**: número de éxitos.

2.  **n**: tamaño de la muestra.

3.  **p**: proporción bajo $H_0$​.

## Prueba de hipótesis sobre dos proporciones

Permite comparar si la proporción de una característica es igual en dos poblaciones. Por ejemplo, comparar la proporción de adopción de una tecnología entre hombres y mujeres.

### Criterios de selección

1.  Variable cualitativa dicotómica.

2.  Muestras independientes.

3.  Tamaño muestral suficiente.

### Fórmulas

$$\huge \hat{p}_c = \frac{x_1 + x_2}{n_1 + n_2}$$

$$\LARGE z = \frac{\hat{p}_1 - \hat{p}_2}{\sqrt{\hat{p}_c(1-\hat{p}_c)\left(\frac{1}{n_1} + \frac{1}{n_2}\right)}}$$

### Ejemplo hipotético

En una encuesta, 110 de 200 hombres y 210 de 300 mujeres respondieron. ¿Existe diferencia en las proporciones?

$$\LARGE \hat{p}_1 = 0.55,; \hat{p}_2 = 0.70$$

$$\LARGE \hat{p}_c = \frac{110+210}{200+300} = 0.64$$

$$\LARGE z = \frac{0.55 - 0.70}{\sqrt{0.64 \times 0.36 \left(\frac{1}{200} + \frac{1}{300}\right)}} = -3.42$$

Como $|-3.42| > 1.96$, se rechaza $H_0$.

### Código en R explicado

```{r}
xp <- c(110, 210)   # éxitos en cada grupo
np <- c(200, 300)   # tamaño de cada grupo

prop.test(xp, np,
          alternative = "two.sided",
          correct = FALSE)
```

1.  **xp**: vector de éxitos.

2.  **np**: vector de tamaños.

## Prueba de hipótesis sobre varianzas

La prueba de hipótesis sobre varianzas permite evaluar si la variabilidad observada en una muestra es compatible con un valor de referencia o si existen diferencias en la variabilidad entre dos poblaciones. Este tipo de prueba es fundamental en agronomía para analizar la uniformidad de procesos, como la comparación de la variabilidad en el rendimiento de cultivos bajo diferentes métodos de riego o el control de calidad de productos agrícolas.

### Criterios de selección

1.  La variable de interés debe ser cuantitativa y continua.

2.  Los datos deben provenir de poblaciones con distribución normal.

3.  Para comparar dos varianzas, las muestras deben ser independientes.

### Fórmulas

**a) Una varianza (**$\chi^2$): Esta prueba se utiliza para determinar si la varianza de una población es igual a un valor específico, generalmente un estándar de calidad o una especificación técnica.

$$\huge \chi^2 = \frac{(n-1)s^2}{\sigma_0^2} $$​

donde:

1.  $n$ es el tamaño de la muestra,

2.  $s^2$ es la varianza muestral,

3.  $\sigma_0^2$ es la varianza poblacional bajo la hipótesis nula.

Para este calculo no existe una función predefinida en R que lo realice con fines prácticos se desarrollo la siguiente función personalizada para esta tarea:

```{r}
# Función personalizada para prueba de hipótesis de una varianza
var_test_chi <- function(x = NULL, 
                         n = NULL, 
                         s2 = NULL, 
                         sigma0_2,
                         alternative = "two.sided",
                         alpha = 0.05) {
  
  # Validación de argumentos
  if (is.null(x) && (is.null(n) || is.null(s2))) {
    stop("Debe proporcionar 'x' (vector de datos) o 
         'n' y 's2' (estadísticos muestrales)")
  }
  
  if (!is.null(x) && (!is.null(n) || !is.null(s2))) {
    warning("Se proporcionaron datos y estadísticos. 
            Se usarán los datos 'x'")
  }
  
  # Calcular estadísticos si se proporcionan los datos
  if (!is.null(x)) {
    n <- length(x)
    s2 <- var(x)
  }
  
  # Validar alternative
  alternative <- match.arg(alternative, c("two.sided", "less", "greater"))
  
  # Calcular estadístico chi-cuadrado
  chi_sq <- (n - 1) * s2 / sigma0_2
  df <- n - 1
  
  # Calcular valor-p según el tipo de prueba
  if (alternative == "two.sided") {
    # Para prueba bilateral
    p_value <- 2 * min(pchisq(chi_sq, df), 
                       pchisq(chi_sq, df, lower.tail = FALSE))
  } else if (alternative == "greater") {
    p_value <- pchisq(chi_sq, df, lower.tail = FALSE)
  } else { # alternative == "less"
    p_value <- pchisq(chi_sq, df, lower.tail = TRUE)
  }
  
  # Decisión
  decision <- ifelse(p_value < alpha, "Rechazar H0", "No rechazar H0")
  
  # Valor crítico
  if (alternative == "two.sided") {
    crit_lower <- qchisq(alpha/2, df)
    crit_upper <- qchisq(1 - alpha/2, df)
    critical_value <- c(crit_lower, crit_upper)
  } else if (alternative == "greater") {
    critical_value <- qchisq(1 - alpha, df)
  } else { # alternative == "less"
    critical_value <- qchisq(alpha, df)
  }
  
  # Crear objeto de resultado
  result <- list(
    statistic = chi_sq,
    parameter = df,
    p.value = p_value,
    critical.value = critical_value,
    alternative = alternative,
    method = "Prueba de hipótesis para una varianza (Chi-cuadrado)",
    data.name = deparse(substitute(x)),
    sample.size = n,
    sample.variance = s2,
    null.variance = sigma0_2,
    alpha = alpha,
    decision = decision
  )
  
  class(result) <- "var_test_custom"
  return(result)
}

# Método print personalizado para mostrar resultados de forma clara
print.var_test_custom <- function(x, ...) {
  cat("\n")
  cat(x$method, "\n")
  cat("Datos:", x$data.name, "\n")
  cat("\n")
  cat("Hipótesis:\n")
  if (x$alternative == "two.sided") {
    cat("H0: sigma^2 =", x$null.variance, "\n")
    cat("Ha: sigma^2 ≠", x$null.variance, "\n")
  } else if (x$alternative == "greater") {
    cat("H0: sigma^2 ≤", x$null.variance, "\n")
    cat("Ha: sigma^2 >", x$null.variance, "\n")
  } else {
    cat("H0: sigma^2 ≥", x$null.variance, "\n")
    cat("Ha: sigma^2 <", x$null.variance, "\n")
  }
  cat("\n")
  cat("Estadísticos de la muestra:\n")
  cat("n =", x$sample.size, "\n")
  cat("s^2 =", round(x$sample.variance, 4), "\n")
  cat("\n")
  cat("Estadístico de prueba:\n")
  cat("Chi-cuadrado =", round(x$statistic, 4), "\n")
  cat("Grados de libertad =", x$parameter, "\n")
  cat("\n")
  cat("Valor crítico(s):\n")
  if (length(x$critical.value) == 2) {
    cat("Chi^2(", x$alpha/2, ",", x$parameter, ") =",
        round(x$critical.value[1], 4), "\n")
    cat("Chi^2(", 1-x$alpha/2, ",", x$parameter, ") =",
        round(x$critical.value[2], 4), "\n")
  } else {
    cat("Chi^2 crítico =", round(x$critical.value, 4), "\n")
  }
  cat("\n")
  cat("Valor-p =", round(x$p.value, 6), "\n")
  cat("Nivel de significancia =", x$alpha, "\n")
  cat("\n")
  cat("Decisión:", x$decision, "\n")
  cat("\n")
}
```

Esta función cuenta con la siguiente sintaxis para su uso:

$$ \Large \text{var\_test\_chi}(x, sigma0_2, alternative, alpha) $$ **Argumentos en orden:**

1.  **x**: Vector con los datos de la muestra

2.  **sigma0_2**: Varianza poblacional con la que se está comparando

3.  **alternative**: Opción en carácter que indica el tipo de prueba utilizando los mismos argumentos que las otras funciones "greater", "less" y "two.sided".

4.  **alpha**: nivel de significancia

También tiene la siguiente sintaxis cuando no se cuenta con los datos de la muestra directamente:

$$ \Large \text{var\_test\_chi}(n, s2, sigma0_2, alternative, alpha) $$ **Argumentos en orden:**

1.  **n**: Tamaño de la muestra

2.  **s2**: Varianza muestral

3.  **sigma0_2**: Varianza poblacional con la que se está comparando

4.  **alternative**: Opción en carácter que indica el tipo de prueba utilizando los mismos argumentos que las otras funciones "greater", "less" y "two.sided".

5.  **alpha**: nivel de significancia

**b) Dos varianzas (F de Fisher):**

$$\huge F = \frac{s_1^2}{s_2^2}$$

donde:

1.  $s_1^2$ y $s_2^2$ son las varianzas muestrales de los dos grupos,

2.  $n_1$ y $n_2$ son los tamaños de muestra de cada grupo.

### Ejemplo hipotético (una varianza)

Supóngase que una empresa agrícola establece que la varianza máxima aceptable en el peso de frutos de tomate es de $\sigma_0^2 = 4$ g². Se toma una muestra de 10 frutos y se obtiene una varianza muestral de $s^2 = 5.8$ g². Se desea saber, con un nivel de significancia del 5%, si la variabilidad excede el estándar.

**1. Planteamiento de hipótesis:**

1.  $H_0: \sigma^2 = 4$ g² (la varianza cumple el estándar)

2.  $H_a: \sigma^2 > 4$ g² (la varianza excede el estándar)

**2. Cálculo del estadístico:**

$$\LARGE \chi^2 = \frac{(10-1) \times 5.8}{4} = \frac{52.2}{4} = 13.05$$

**Decisión:**

El valor crítico para $\alpha = 0.05$ y $gl = 9$ es $\chi^2\_{0.05,9} = 16.92$. Como $13.05 < 16.92$, no se rechaza $H_0$​.

**Código en R explicado:**

```{r}
# Aplicacion de la funcion personalizada
var_test_chi(n = 10, s2 = 5.8,
                              sigma0_2 = 4,
                              alternative = "greater",
                              alpha = 0.05)

```

Para la solución de este problema se emplea la funcion personalizada `var_test_chi`que permite realizar una prueba de hipotesis de la varianza para una muestra empleando los argumentos mencionados en la sección donde se presentó la función.

### Ejemplo hipotético (dos varianzas)

Se desea comparar la varianza del rendimiento de dos tratamientos de riego.

**Datos:**

1.  Tratamiento 1: 10, 12, 11, 13, 12, 11, 14, 13

2.  Tratamiento 2: 9, 10, 11, 10, 12, 10, 11, 10

**Planteamiento de hipótesis:**

1.  $H_0: \sigma_1^2 = \sigma_2^2$​ (las varianzas son iguales)

2.  $H_a: \sigma_1^2 \neq \sigma_2^2$ (las varianzas son diferentes)

**Cálculo y decisión en R:**

```{r}
trat1 <- c(10, 12, 11, 13, 12, 11, 14, 13)
trat2 <- c(9, 10, 11, 10, 12, 10, 11, 10)

var.test(trat1, trat2,
         alternative = "two.sided", # prueba bilateral
         conf.level = 0.95)         # nivel de confianza
```

1.  **var.test**: realiza la prueba F para comparar varianzas.

2.  **alternative**: define si la prueba es bilateral o unilateral.

3.  **conf.level**: establece el nivel de confianza.

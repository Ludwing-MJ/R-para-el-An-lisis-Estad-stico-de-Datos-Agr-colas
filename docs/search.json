[
  {
    "objectID": "C5.2.html",
    "href": "C5.2.html",
    "title": "11  Ejemplo empleando el formulario",
    "section": "",
    "text": "11.1 Base de datos\nReferencia del dataset: Fisher, R. (1936). Iris [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C56C76\nAcceso a recursos: El script completo con el ejemplo desarrollado y la base de datos IRIS pueden descargarse en el siguiente repositorio:\nA continuación, se presenta un conjunto de datos correspondientes a la longitud del pétalo (en cm) de 150 flores de la especie Iris, organizados en formato matricial para facilitar su visualización y análisis. Estos datos serán utilizados para ilustrar el cálculo de estadísticos descriptivos para datos agrupados, siguiendo las metodologías propuestas en la sección aterior.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ejemplo empleando el formulario</span>"
    ]
  },
  {
    "objectID": "C5.2.html#base-de-datos",
    "href": "C5.2.html#base-de-datos",
    "title": "11  Ejemplo empleando el formulario",
    "section": "",
    "text": "1.4\n1.4\n1.3\n1.5\n1.4\n1.7\n1.4\n1.5\n1.4\n1.5\n\n\n1.5\n1.6\n1.4\n1.1\n1.2\n1.5\n1.3\n1.4\n1.7\n1.5\n\n\n1.7\n1.5\n1.0\n1.7\n1.9\n1.6\n1.6\n1.5\n1.4\n1.6\n\n\n1.6\n1.5\n1.5\n1.4\n1.5\n1.2\n1.3\n1.4\n1.3\n1.5\n\n\n1.3\n1.3\n1.3\n1.6\n1.9\n1.4\n1.6\n1.4\n1.5\n1.4\n\n\n4.7\n4.5\n4.9\n4.0\n4.6\n4.5\n4.7\n3.3\n4.6\n3.9\n\n\n3.5\n4.2\n4.0\n4.7\n3.6\n4.4\n4.5\n4.1\n4.5\n3.9\n\n\n4.8\n4.0\n4.9\n4.7\n4.3\n4.4\n4.8\n5.0\n4.5\n3.5\n\n\n3.8\n3.7\n3.9\n5.1\n4.5\n4.5\n4.7\n4.4\n4.1\n4.0\n\n\n4.4\n4.6\n4.0\n3.3\n4.2\n4.2\n4.2\n4.3\n3.0\n4.1\n\n\n6.0\n5.1\n5.9\n5.6\n5.8\n6.6\n4.5\n6.3\n5.8\n6.1\n\n\n5.1\n5.3\n5.5\n5.0\n5.1\n5.3\n5.5\n6.7\n6.9\n5.0\n\n\n5.7\n4.9\n6.7\n4.9\n5.7\n6.0\n4.8\n4.9\n5.6\n5.8\n\n\n6.1\n6.4\n5.6\n5.1\n5.6\n6.1\n5.6\n5.5\n4.8\n5.4\n\n\n5.6\n5.1\n5.1\n5.9\n5.7\n5.2\n5.0\n5.2\n5.4\n5.1",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ejemplo empleando el formulario</span>"
    ]
  },
  {
    "objectID": "C5.2.html#construcción-de-la-tabla-de-frecuencias",
    "href": "C5.2.html#construcción-de-la-tabla-de-frecuencias",
    "title": "11  Ejemplo empleando el formulario",
    "section": "11.2 Construcción de la Tabla de Frecuencias",
    "text": "11.2 Construcción de la Tabla de Frecuencias\n\n11.2.1 Determinación del rango (R)\nEl rango es la diferencia entre el valor máximo y el valor mínimo de la variable:\n\\[\\huge R = X_{\\text{max}} - X_{\\text{min}}\\] Para la longitud de pétalo: \\[\\huge R = 6.9 - 1.0 = 5.9\\]\n\n\n11.2.2 Cálculo del número de clases (K)\nEl número de clases se determina con la Regla de Sturges: \\[\\huge k = 1 + 3.322 \\log_{10} N\\] Donde \\(n\\) es el número total de datos: \\[\\LARGE k = 1 + 3.322 \\log_{10} 150 \\approx 1 + 3.322 \\times 2.1761 \\approx 8.22\\] Se redondea al entero más cercano:\n\\[\\Huge k = 8\\]\n\n\n11.2.3 Cálculo de la amplitud de clase (C)\nLa amplitud de clase se calcula así: \\[\\Huge C = \\frac{R}{k}\\] Sustituyendo valores: \\[\\Huge C = \\frac{5.9}{8} = 0.7375 \\approx 0.75\\]\n\n\n11.2.4 Determinación de los límites de clase\nEl primer límite inferior es el valor mínimo (\\(1.0\\)). Los siguientes se obtienen sumando la amplitud de clase (\\(C\\)).\nPara evitar que un valor pertenezca a dos clases al mismo tiempo, se utiliza la notación de intervalos semiabiertos:\n\nEl corchete \\([\\) indica que el límite inferior está incluido en la clase.\nEl paréntesis \\()\\) indica que el límite superior no está incluido en la clase.\n\nPor ejemplo, el primer intervalo se escribe:\n\\[\\LARGE [1.00, 1.75)\\]\nEsto significa que la clase incluye todos los valores \\(x\\) tales que \\(1.00≤x&lt;1.75\\).\nLos intervalos de clase quedan así: \\[\\large \\begin{aligned}\n\\text{Clase 1:} & \\quad [1.00, 1.75) \\\\\n\\text{Clase 2:} & \\quad [1.75, 2.50) \\\\\n\\text{Clase 3:} & \\quad [2.50, 3.25) \\\\\n\\text{Clase 4:} & \\quad [3.25, 4.00) \\\\\n\\text{Clase 5:} & \\quad [4.00, 4.75) \\\\\n\\text{Clase 6:} & \\quad [4.75, 5.50) \\\\\n\\text{Clase 7:} & \\quad [5.50, 6.25) \\\\\n\\text{Clase 8:} & \\quad [6.25, 7.00] \\\\\n\\end{aligned}\\]\nNótese que en la última clase se utiliza el corchete de cierre \\(]\\) para incluir el valor máximo.\n\n\n11.2.5 Cálculo de la marca de clase\nLa marca de clase es el punto medio de cada intervalo: \\[\\huge x_i = \\frac{L_i + L_s}{2}\\] Por ejemplo, para la primera clase: \\[ \\huge x_1 = \\frac{1.00 + 1.75}{2} = 1.375\\]\n\n\n11.2.6 Cálculo de la frecuencia absoluta\nLa frecuencia absoluta es el número de datos en cada clase, obtenida por conteo directo.\n\n\n11.2.7 Cálculo de la frecuencia relativa\nLa frecuencia relativa se calcula así: \\[\\huge fr_i = \\frac{f_i}{N}\\]\nPor ejemplo, para la primera clase: \\[\\huge fr_i = \\frac{48}{150} = 0.32\\]\n\n\n11.2.8 Cálculo de la frecuencia acumulada\nLa frecuencia acumulada es la suma de las frecuencias absolutas hasta la clase \\(i\\): \\[\\huge fa_i = \\sum_{j=1}^{i} f_j\\]\nPor ejemplo, para la cuarta clase: \\[ \\Large fa_4 = f_1 + f_2 + f_3 + f_4 = 48 + 0 + 0 + 15 = 63\\]\n\n\n11.2.9 Cálculo de \\(f_i x_i\\)​ y \\(f_i x_i^2\\)\nEstos productos se utilizan para cálculos posteriores: \\[\\huge f_i x_i = f_i \\times x_i\\] \\[\\huge f_i x_i^2 = f_i \\times (x_i)^2\\] Por ejemplo, para la primera clase: \\[\\LARGE f_1 x_1 = 48 \\times 1.375 = 66.00\\] \\[\\LARGE f_1 x_1^2 = 48 \\times (1.375)^2 = 48 \\times 1.890625 = 90.75\\]",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ejemplo empleando el formulario</span>"
    ]
  },
  {
    "objectID": "C5.2.html#tabla-de-frecuencia",
    "href": "C5.2.html#tabla-de-frecuencia",
    "title": "11  Ejemplo empleando el formulario",
    "section": "11.3 Tabla de frecuencia",
    "text": "11.3 Tabla de frecuencia\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase\nLímite Inferior (LI)\nLímite Superior (LS)\nMarca de clase (\\(x_i\\))\nFrecuencia ( \\(f_i\\) ​)\nFrecuencia relativa (\\(fr_i\\)​)\nFrecuencia acumulada (\\(fa_i\\))\n\\(f_i x_i\\)\n\\(f_i x_i^2\\)\n\n\n\n\n1\n1.000\n1.750\n1.375\n48\n0.320\n48\n66.000\n90.750\n\n\n2\n1.750\n2.500\n2.125\n2\n0.013\n50\n4.250\n9.031\n\n\n3\n2.500\n3.250\n2.875\n1\n0.007\n51\n2.875\n8.266\n\n\n4\n3.250\n4.000\n3.625\n10\n0.067\n61\n36.250\n131.406\n\n\n5\n4.000\n4.750\n4.375\n34\n0.227\n95\n148.750\n650.781\n\n\n6\n4.750\n5.500\n5.125\n27\n0.180\n122\n138.375\n709.172\n\n\n7\n5.500\n6.250\n5.875\n22\n0.147\n144\n129.250\n759.344\n\n\n8\n6.250\n7.000\n6.625\n6\n0.040\n150\n39.750\n263.344\n\n\nTotal\n\n\n\n150\n1.000\n\n565.500\n2622.094",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ejemplo empleando el formulario</span>"
    ]
  },
  {
    "objectID": "C5.2.html#medidas-de-tendencia-central",
    "href": "C5.2.html#medidas-de-tendencia-central",
    "title": "11  Ejemplo empleando el formulario",
    "section": "11.4 Medidas de tendencia central",
    "text": "11.4 Medidas de tendencia central\nUna vez construida la tabla de frecuencia, se procede a calcular las medidas de tendencia central, que resumen la posición central de la distribución de los datos.\n\n11.4.1 Media Aritmética\nLa formula para calcular la media aritmpetica es la siguiente:\n\\[\\huge \\bar{x} = \\frac{\\sum_{i=1}^{k} f_i \\cdot x_i}{N}\\]\nSustituyendo valores\n\\[\\huge \\bar{x} = \\frac{565.50}{150}=3.77\\]\n\n\n11.4.2 Mediana\nPara el calculo de la mediana hay que identificar la primera clase donde la frecuencia acumulada \\(fa_i\\) supera \\(N/2\\). Para este ejemplo \\(N/2\\) al sustituir valores equivale a \\(150/2=75\\) siendo la clase numero 5 aquella donde la frecuencia acumulada supera \\(N/2\\) siendo la formula para el cálculo de la mediana la siguiente:\n\\[\\huge Me = L_{inf} + \\frac{\\frac{N}{2} - Fa_{ant}}{f_m} \\cdot c\\] Sustituyendo valores \\[\\huge Me = 4.00 + \\frac{\\frac{150}{2} - 61}{34} \\cdot 0.75=4.31\\]\n\n\n11.4.3 Moda\nPara el calculo de la moda hay que identificar clase con mayor frecuencia absoluta siendo la clase numero 1 para este ejemplo. Siendo la formula para el cálculo de la moda la siguiente:\n\\[ \\huge Mo = L_{inf} + \\frac{d_1}{d_1 + d_2} \\cdot c\\]\nSustituyendo valores:\n\\[ \\LARGE Mo = 1.00 + \\frac{(48-0)}{(48-0) + (48-2)} \\cdot 0.75=1.383\\]",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ejemplo empleando el formulario</span>"
    ]
  },
  {
    "objectID": "C5.2.html#medidas-de-dispersión",
    "href": "C5.2.html#medidas-de-dispersión",
    "title": "11  Ejemplo empleando el formulario",
    "section": "11.5 Medidas de dispersión",
    "text": "11.5 Medidas de dispersión\n\n11.5.1 Rango\nEl rango se aproxima restando el límite inferior de la primera clase al límite superior de la última clase siendo su formula la siguiente:\n\\[\\huge Rango = L_{sup,k} - L_{inf,1}\\]\nSustituyendo valores:\n\\[\\huge Rango = 7.00 - 1.00=6.00\\]\n\n\n11.5.2 Varianza\nPara el calculo de la varianza se utilizará la siguiente formula operativa, que resulta especialmente útil porque se dispone de la suma de los productos de las frecuencias por los puntos medios y sus cuadrados.\n\\[ \\LARGE s^2 = \\frac{\\sum_{i=1}^{k} f_i x_i^2 - \\frac{\\left(\\sum_{i=1}^{k} f_i x_i\\right)^2}{N}}{N - 1}\\]\nSustituyendo valores:\n\\[ \\LARGE s^2 = \\frac{2622.094 - \\frac{\\left(565.500\\right)^2}{150}}{150 - 1}=3.29\\]\n\n\n11.5.3 Desviación Estándar\nLa desviación estándar es la raíz cuadrada de la varianza y se expresa en las mismas unidades que los datos originales. Para datos agrupados, la desviación estándar se calcula como:\n\\[\\huge s = \\sqrt{s^2}\\]\nSustituyendo valores\n\\[\\huge s = \\sqrt{3.29}=1.645\\]\n\n\n11.5.4 Coeficiente de Variación\nEl coeficiente de variación es una medida relativa de dispersión que se calcula dividiendo la desviación estándar entre la media aritmética: \\[ \\huge CV = \\frac{s}{\\bar{x}} \\cdot 100\\%\\]\nSustituyendo valores:\n\\[ \\huge CV = \\frac{1.645}{3.77} \\cdot 100\\%=43.63\\%\\]",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ejemplo empleando el formulario</span>"
    ]
  },
  {
    "objectID": "C5.2.html#medidas-de-posición-relativa",
    "href": "C5.2.html#medidas-de-posición-relativa",
    "title": "11  Ejemplo empleando el formulario",
    "section": "11.6 Medidas de posición relativa",
    "text": "11.6 Medidas de posición relativa\n\n11.6.1 Cuartiles\nPara calcular los cuartiles en datos agrupados, primero se identifica la clase cuartil, que es la primera clase cuya frecuencia acumulada es mayor o igual a \\(i⋅N/4\\), donde \\(i\\) es el número del cuartil (1, 2 o 3). Luego, se aplica la siguiente fórmula:\n\\[\\huge Q_i = L_{inf} + \\frac{\\frac{i \\cdot N}{4} - Fa_{ant}}{f_q} \\cdot c\\]\nPara el ejemplo se calculará el cuartil 1 (Q1) por lo que primero se identifica la clase dentro de la que se encuentra, para ello se usa la formula \\(i⋅N/4\\), sustituyendo valores esto sería \\(1\\cdot 150/4=38.5\\) siendo la clase donde la frecuencia acumulada supera este valor por primera vez la clase 1, ya con esta información se procede a sustituir valores en la fórmula.\n\\[\\huge Q_1 = 1.0 + \\frac{\\frac{1 \\cdot 150}{4} - 0}{48} \\cdot 0.75=1.59\\]\n\n\n11.6.2 Percentiles\nPara calcular los percentiles en datos agrupados, primero se identifica la clase percentil, que es la primera clase cuya frecuencia acumulada es mayor o igual a \\(p \\cdot N/100\\). Luego, se aplica la siguiente fórmula:\n\\[\\huge P_p = L_{inf} + \\frac{\\frac{p \\cdot N}{100} - Fa_{ant}}{f_p} \\cdot c\\]\nPara el ejemplo se calculará el percentil 80 (\\(p=80\\)) para ello primero se identifica la clase a la que pertenece este percentil usando la formula \\(p \\cdot N/100\\) la cual al sustituir los valores equivale a: \\(80 \\cdot 150/100= 120\\) con este dato se ubica la clase 6 como la clase donde se encuentra el percentil 80 al ser la primera donde la frecuencia acumulada supera 120. Una vez obtenida esta información se procede a sustituir valores en la formula:\n\\[\\huge P_{80} = 4.75 + \\frac {120 - 95}{27} \\cdot 0.75=5.44\\]",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ejemplo empleando el formulario</span>"
    ]
  },
  {
    "objectID": "C5.2.html#interpretación-de-resultados",
    "href": "C5.2.html#interpretación-de-resultados",
    "title": "11  Ejemplo empleando el formulario",
    "section": "11.7 Interpretación de Resultados",
    "text": "11.7 Interpretación de Resultados\n\n11.7.1 Media aritmética\nLa media aritmética obtenida fue de 3.77 cm. Esto indica que, en promedio, la longitud del pétalo de las flores analizadas es de 3.77 centímetros. Esta medida representa el valor central alrededor del cual tienden a agruparse los datos y es útil para describir el comportamiento general de la variable en estudio (López & González, 2018).\n\n\n11.7.2 Mediana\nLa mediana calculada fue de 4.31 cm. Esto significa que el 50% de las flores tiene una longitud de pétalo menor o igual a 4.31 cm, mientras que el otro 50% tiene una longitud mayor o igual a este valor. La mediana es especialmente útil cuando la distribución de los datos es asimétrica o presenta valores extremos, ya que no se ve afectada por estos (López & González, 2018).\n\n\n11.7.3 Moda\nLa moda resultó ser 1.375 cm, correspondiente a la clase con mayor frecuencia absoluta. Esto indica que la longitud de pétalo más común entre las flores analizadas se encuentra en el intervalo de 1.00 a 1.75 cm. La moda es relevante para identificar el valor o rango de valores que se presentan con mayor frecuencia en el conjunto de datos (López & González, 2018).\n\n\n11.7.4 Rango\nEl rango calculado fue de 6.00 cm, lo que representa la diferencia entre la longitud máxima y mínima de los pétalos observados. Este valor proporciona una idea general de la dispersión de los datos, mostrando el intervalo total en el que se distribuyen las observaciones (López & González, 2018).\n\n\n11.7.5 Varianza y desviación estándar\nLa varianza obtenida fue de 3.67 cm² y la desviación estándar fue de 1.83 cm. Estos valores indican que, en promedio, las longitudes de los pétalos se desvían 1.83 cm respecto a la media. Una desviación estándar relativamente alta, como en este caso, sugiere que existe una considerable variabilidad en la longitud de los pétalos dentro del grupo analizado (López & González, 2018).\n\n\n11.7.6 Coeficiente de variación\nEl coeficiente de variación fue de 46.88%. Este valor, al ser mayor al 30%, indica que la dispersión relativa de los datos respecto a la media es alta. En términos prácticos, esto significa que la longitud de los pétalos presenta una considerable heterogeneidad dentro del conjunto de flores estudiadas (López & González, 2018).\n\n\n11.7.7 Cuartil 1 (Q1)\nEl primer cuartil (Q1) se ubicó en 1.59 cm. Esto implica que el 25% de las flores tiene una longitud de pétalo menor o igual a 1.59 cm. El análisis de los cuartiles permite identificar la distribución de los datos en segmentos y facilita la detección de posibles asimetrías o concentraciones de valores (López & González, 2018).\n\n\n11.7.8 Percentil 80 (P80)\nEl percentil 80 se calculó en 5.78 cm, lo que significa que el 80% de las flores tiene una longitud de pétalo menor o igual a 5.78 cm. El percentil 80 es útil para identificar valores altos dentro de la distribución y para realizar comparaciones entre diferentes grupos o tratamientos (López & González, 2018).",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ejemplo empleando el formulario</span>"
    ]
  },
  {
    "objectID": "C0.html",
    "href": "C0.html",
    "title": "1  Instalación y configuración",
    "section": "",
    "text": "1.1 Descarga de R y RStudio\nAntes de iniciar el trabajo con análisis estadístico en R, es fundamental realizar la instalación y configuración tanto del lenguaje R como del entorno de desarrollo RStudio. R es un lenguaje de programación y entorno computacional ampliamente utilizado en el análisis estadístico, la visualización de datos y la investigación reproducible (Ihaka & Gentleman, 1996). Por su parte, RStudio constituye un Entorno de Desarrollo Integrado (IDE) diseñado específicamente para facilitar el uso de R, proporcionando una interfaz intuitiva y herramientas avanzadas que optimizan el flujo de trabajo (Xie et al., 2018). Esta sección describe los pasos necesarios para descargar, instalar y configurar ambos programas, asegurando un entorno de trabajo funcional y eficiente.\nPara utilizar R y RStudio, es necesario descargar ambos programas desde sus sitios oficiales. R proporciona el núcleo del lenguaje y las herramientas computacionales fundamentales, mientras que RStudio actúa como una interfaz que simplifica el uso de R y mejora la experiencia del usuario, integrando funciones para la gestión de proyectos, edición de scripts y visualización de resultados (Xie et al., 2018).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Instalación y configuración</span>"
    ]
  },
  {
    "objectID": "C0.html#descarga-de-r-y-rstudio",
    "href": "C0.html#descarga-de-r-y-rstudio",
    "title": "1  Instalación y configuración",
    "section": "",
    "text": "1.1.1 Descarga de R\nSe recomienda descargar una versión estable de R para evitar posibles incompatibilidades con paquetes que aún no han sido actualizados para las versiones más recientes. Por ejemplo, la versión R 4.4.3 es reconocida por su estabilidad y amplio soporte dentro de la comunidad de usuarios (R Core Team, 2023). El repositorio oficial de R se encuentra disponible en https://cran.r-project.org/bin/windows/base/old/, donde es posible acceder a todas las versiones publicadas. Para descargar una versión específica, se debe seleccionar el nombre de la versión deseada y hacer clic en el archivo con terminación -win.exe, lo que iniciará la descarga del instalador correspondiente (R Core Team, 2023).\n\n\n1.1.2 Descarga de RStudio\nLa descarga de RStudio se realiza desde su página oficial, donde se encuentra disponible la versión más reciente para los principales sistemas operativos. Para usuarios de Windows, se debe seleccionar la opción “Download RStudio Desktop for Windows”, mientras que para quienes utilizan macOS o Linux, la misma página ofrece las versiones correspondientes para estos sistemas (Xie et al., 2018). Es importante asegurarse de descargar la versión adecuada según el sistema operativo del equipo para garantizar la compatibilidad y el correcto funcionamiento del entorno.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Instalación y configuración</span>"
    ]
  },
  {
    "objectID": "C0.html#instalación-de-r-y-rstudio",
    "href": "C0.html#instalación-de-r-y-rstudio",
    "title": "1  Instalación y configuración",
    "section": "1.2 Instalación de R y RStudio",
    "text": "1.2 Instalación de R y RStudio\nLa instalación de R y RStudio debe realizarse siguiendo un orden específico para evitar conflictos y asegurar que ambos programas funcionen correctamente. A continuación, se describen los pasos detallados para cada uno:\n\nInstalación de R: Una vez descargado el instalador de R, se debe ejecutar el archivo .exe y seguir las instrucciones proporcionadas por el asistente de instalación. En la mayoría de los casos, es suficiente con aceptar las configuraciones predeterminadas, a menos que se requiera una configuración personalizada para necesidades específicas del usuario o del proyecto (R Core Team, 2023).\nInstalación de RStudio: Después de instalar R, se procede a ejecutar el instalador de RStudio previamente descargado. Al igual que en el caso de R, se pueden aceptar las opciones predeterminadas durante la instalación. Es relevante destacar que RStudio permite gestionar múltiples versiones de R en un mismo dispositivo, lo que resulta especialmente útil para trabajar en proyectos que requieren versiones específicas del lenguaje. Esta selección puede realizarse desde la configuración de RStudio, facilitando así la administración de entornos de trabajo diferenciados (Xie et al., 2018; R Core Team, 2023).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Instalación y configuración</span>"
    ]
  },
  {
    "objectID": "C0.html#configuración-inicial-de-rstudio",
    "href": "C0.html#configuración-inicial-de-rstudio",
    "title": "1  Instalación y configuración",
    "section": "1.3 Configuración inicial de RStudio",
    "text": "1.3 Configuración inicial de RStudio\nTras completar la instalación de R y RStudio, es recomendable realizar una configuración inicial que permita personalizar el entorno de trabajo, mejorar la organización y facilitar el desarrollo de análisis estadísticos. Estas configuraciones contribuyen a optimizar la experiencia del usuario y a establecer un flujo de trabajo más eficiente y productivo (Xie et al., 2018). A continuación, se describen los pasos esenciales para configurar RStudio de manera adecuada.\n\n1.3.1 Seleccionar la versión de R\nRStudio permite elegir la versión de R que se utilizará, lo cual es especialmente útil si se tienen múltiples versiones instaladas en el mismo dispositivo. Esta funcionalidad garantiza la compatibilidad con proyectos que requieren versiones específicas del lenguaje (R Core Team, 2023). Para seleccionar la versión de R en RStudio, se deben seguir estos pasos:\n\nIr al menú Tools y seleccionar Global Options.\nEn la ventana emergente, dirigirse a la pestaña General.\nEn el apartado R version, elegir la versión deseada de R.\n\n\n\n1.3.2 Configurar la apariencia de RStudio\nRStudio ofrece opciones de personalización para adaptar su apariencia a las preferencias del usuario, lo que puede mejorar la experiencia de trabajo y reducir la fatiga visual durante sesiones prolongadas (Xie et al., 2018). Para cambiar el tema de la interfaz y ajustar la fuente, se deben seguir los siguientes pasos:\n\nAcceder al menú Tools y seleccionar Global Options.\nEn la ventana emergente, ir a la pestaña Appearance.\nElegir el tema preferido, ya sea claro u oscuro (por ejemplo, el tema Cobalt para reducir la fatiga visual).\nAjustar el tamaño y el tipo de fuente según las preferencias personales.\n\n\n\n1.3.3 Configurar el panel de trabajo\nLa interfaz de RStudio está organizada en cuatro paneles principales: editor de scripts, consola, entorno/archivos y gráficos/ayuda. Estos paneles pueden reorganizarse para optimizar el flujo de trabajo. Para modificar la disposición de los paneles, se deben seguir estos pasos:\n\nIr al menú Tools y seleccionar Global Options.\nAcceder a la sección Pane Layout.\nAjustar la ubicación de los paneles según las necesidades, por ejemplo, colocando el editor de scripts en la parte superior izquierda y la consola en la parte inferior.\nGuardar los cambios para aplicar la nueva disposición.\n\n\n\n1.3.4 Habilitar el número de líneas en el editor de scripts\nLa numeración de líneas en el editor de scripts facilita la navegación y depuración del código. Para habilitar esta opción, se deben seguir los siguientes pasos:\n\nAcceder al menú Tools y seleccionar Global Options.\nIr a la pestaña Code y luego a Display.\nMarcar la casilla Show line numbers para activar la numeración de líneas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Instalación y configuración</span>"
    ]
  },
  {
    "objectID": "C0.html#organización-de-proyectos",
    "href": "C0.html#organización-de-proyectos",
    "title": "1  Instalación y configuración",
    "section": "1.4 Organización de proyectos",
    "text": "1.4 Organización de proyectos\nLa organización adecuada de proyectos en RStudio es esencial para establecer un flujo de trabajo eficiente, reproducible y estructurado. Una gestión ordenada de archivos y scripts no solo facilita el desarrollo de los análisis, sino que también mejora la colaboración y la reproducibilidad de los resultados (Xie et al., 2018).\n\n1.4.1 Crear un proyecto en RStudio\nPara organizar los archivos, datos y scripts de un análisis específico, RStudio permite crear proyectos siguiendo estos pasos:\n\nEn la barra de menú, seleccionar File &gt; New Project.\nElegir una de las siguientes opciones:\nNew Directory: para crear un proyecto desde cero en una nueva carpeta.\nExisting Directory: para convertir una carpeta existente en un proyecto de RStudio.\nVersion Control: para clonar un repositorio de Git y trabajar en un proyecto con control de versiones.\nConfigurar el nombre y la ubicación del proyecto según las necesidades del análisis.\nHacer clic en Create Project para finalizar la configuración.\n\nEl uso de proyectos en RStudio permite mantener una estructura clara y organizada, facilitando la gestión de los recursos necesarios para el análisis y promoviendo la reproducibilidad (Xie et al., 2018).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Instalación y configuración</span>"
    ]
  },
  {
    "objectID": "C0.html#directorio-de-trabajo-o-working-directory",
    "href": "C0.html#directorio-de-trabajo-o-working-directory",
    "title": "1  Instalación y configuración",
    "section": "1.5 Directorio de trabajo o Working Directory",
    "text": "1.5 Directorio de trabajo o Working Directory\nEl directorio de trabajo es la carpeta donde R buscará los archivos y guardará los resultados generados durante el análisis. Para establecerlo manualmente, se puede utilizar la función setwd(), como se muestra a continuación:\n\n# Establecer directorio de trabajo\nsetwd(\"ruta/del/directorio\")\n\nSin embargo, al trabajar con proyectos en RStudio, el directorio de trabajo se configura automáticamente al abrir el archivo del proyecto, lo que elimina la necesidad de establecerlo manualmente y reduce errores relacionados con rutas incorrectas (R Core Team, 2023).\n\n1.5.1 Uso de archivos .Rproj\nEl archivo .Rproj es el elemento central de cada proyecto en RStudio. Este archivo almacena las configuraciones específicas del proyecto, como el directorio de trabajo, las opciones de visualización y otros ajustes personalizados. Al abrir un archivo .Rproj, se carga automáticamente el entorno de trabajo asociado, lo que facilita la continuidad y la gestión del análisis (Xie et al., 2018).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Instalación y configuración</span>"
    ]
  },
  {
    "objectID": "C1.1.html",
    "href": "C1.1.html",
    "title": "2  Aspectos introductorios",
    "section": "",
    "text": "2.1 Definición de estadística\nLa estadística es una ciencia derivada de la matemática que se ocupa de la extracción de información contenida en datos provenientes de muestras y de su uso para hacer inferencias acerca de la población de donde fueron extraídos estos datos. Además, la estadística estudia los métodos científicos para recolectar, organizar, resumir y analizar datos, así como para extraer conclusiones válidas y tomar decisiones razonables basadas en tal análisis (López & González, 2018).\nEl término “estadística” tiene su origen en la palabra alemana Statistik, utilizada por el profesor Gottfried Achenwall en el siglo XVIII, y proviene del término latino status, que significa estado o situación. Históricamente, la estadística ha estado vinculada a la recolección de datos por parte de los gobiernos, especialmente en relación con información demográfica, como los censos (López & González, 2018).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aspectos introductorios</span>"
    ]
  },
  {
    "objectID": "C1.1.html#división-de-la-estadística",
    "href": "C1.1.html#división-de-la-estadística",
    "title": "2  Aspectos introductorios",
    "section": "2.2 División de la estadística",
    "text": "2.2 División de la estadística\nLa estadística, como disciplina científica, se divide tradicionalmente en dos grandes ramas: la estadística descriptiva y la estadística inferencial. Esta división responde tanto a los objetivos como a los métodos empleados en el análisis de datos.\nLa estadística descriptiva comprende el conjunto de métodos y técnicas destinados a recolectar, organizar, presentar y resumir datos de manera cuantitativa o gráfica. Su propósito principal es describir las características principales de un conjunto de datos, facilitando su interpretación y permitiendo identificar patrones, tendencias o comportamientos dentro de la información analizada (López & González, 2018; Montgomery & Runger, 2018).\nPor otro lado, la estadística inferencial se ocupa de realizar generalizaciones, predicciones o inferencias sobre una población a partir de la información obtenida en una muestra representativa. Esta rama utiliza herramientas de probabilidad para estimar parámetros poblacionales, probar hipótesis y cuantificar el grado de incertidumbre asociado a las conclusiones (López & González, 2018; Walpole et al., 2012).\nAdemás de estas dos ramas fundamentales, la estadística moderna reconoce otras áreas especializadas que amplían su campo de aplicación:\n\nLa estadística paramétrica se centra en el análisis de datos bajo el supuesto de que estos provienen de poblaciones que siguen distribuciones conocidas, generalmente la normal. Permite realizar estimaciones y pruebas de hipótesis sobre parámetros poblacionales (López & González, 2018; Montgomery & Runger, 2018).\nLa estadística no paramétrica incluye métodos que no requieren suposiciones estrictas sobre la distribución de los datos, siendo especialmente útil cuando no se puede asumir normalidad o cuando los datos son de nivel ordinal o nominal (Conover, 1999).\nLa geoestadística aplica técnicas estadísticas al análisis de variables distribuidas en el espacio o el tiempo, siendo fundamental en disciplinas como la agronomía, la geografía y la gestión ambiental (López & González, 2018; Webster & Oliver, 2007).\nLa inferencia bayesiana utiliza el teorema de Bayes para actualizar la probabilidad de una hipótesis a medida que se dispone de nueva información, incorporando el conocimiento previo en el análisis estadístico (Gelman et al., 2013).\nLa estadística multivariada estudia simultáneamente múltiples variables, permitiendo analizar relaciones complejas y estructuras latentes en grandes conjuntos de datos (Johnson & Wichern, 2014).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aspectos introductorios</span>"
    ]
  },
  {
    "objectID": "C1.1.html#definiciones-importantes",
    "href": "C1.1.html#definiciones-importantes",
    "title": "2  Aspectos introductorios",
    "section": "2.3 Definiciones importantes",
    "text": "2.3 Definiciones importantes\nEn el estudio de la estadística, es fundamental comprender ciertos conceptos básicos que constituyen la base para el análisis y la interpretación de datos. Entre los más relevantes se encuentran: individuo o unidad estadística, población, muestra, parámetro, estimador e indicador.\n\n2.3.1 Individuo o unidad estadística\nEl individuo o unidad estadística es el elemento básico sobre el cual se realiza la observación o medición en un estudio estadístico. Puede tratarse de una persona, animal, planta, objeto o cualquier entidad sobre la que se recolectan datos. Por ejemplo, en un estudio agronómico, una unidad estadística puede ser una planta de maíz, una parcela de terreno o un saco de fertilizante (López & González, 2018; Walpole et al., 2012).\n\n\n2.3.2 Población\nLa población se define como el conjunto total de unidades estadísticas que comparten al menos una característica observable y relevante para el estudio. El análisis de toda la población se denomina censo. En agronomía, la población puede estar formada por todos los árboles de una plantación, todos los lotes de un cultivo o todos los animales de una granja (López & González, 2018; Montgomery & Runger, 2018).\n\n\n2.3.3 Muestra\nLa muestra es un subconjunto representativo de la población, seleccionado con el propósito de inferir características o parámetros de la población total. El muestreo permite realizar estudios más eficientes y menos costosos que el censo, siempre que la muestra sea seleccionada adecuadamente (López & González, 2018; Walpole et al., 2012).\n\n\n2.3.4 Parámetro\nUn parámetro es un valor numérico que resume o describe una característica de la población, como la media, la varianza o la proporción. Los parámetros son generalmente desconocidos y se estiman a partir de los datos muestrales (Montgomery & Runger, 2018).\n\n\n2.3.5 Estimador\nEl estimador es una función o estadístico calculado a partir de los datos de la muestra, utilizado para aproximar el valor de un parámetro poblacional. Por ejemplo, la media muestral es un estimador de la media poblacional (Walpole et al., 2012).\n\n\n2.3.6 Indicador\nUn indicador es un elemento extraído de la realidad que permite cuantificar características medibles de un fenómeno o sistema. Su principal función es servir como base para la construcción de índices relativos, facilitando la comparación y el análisis entre diferentes situaciones o periodos. Los indicadores transforman observaciones concretas en valores numéricos que reflejan la presencia, magnitud o evolución de una característica específica. De este modo, permiten señalar o evidenciar que una variable está ocurriendo y proporcionan información útil para la toma de decisiones. La objetividad de los indicadores puede variar según la naturaleza de la característica que representan, siendo algunos más fácilmente cuantificables que otros (López & González, 2018).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aspectos introductorios</span>"
    ]
  },
  {
    "objectID": "C2.1.html",
    "href": "C2.1.html",
    "title": "3  Clasificación de Variables",
    "section": "",
    "text": "3.1 Definición de Variable\nUna variable en estadística se define como aquello que se observa o mide sobre las unidades estadísticas (López & González, 2018). Constituye una característica que varía de un individuo a otro dentro de la población o muestra bajo estudio. Las variables representan los atributos o propiedades que pueden ser medidos, observados o categorizados en las unidades de análisis.\nDesde el punto de vista de la notación estadística, las variables se representan mediante letras mayúsculas del alfabeto (X, Y, Z), mientras que los valores específicos que estas asumen se denotan con letras minúsculas correspondientes (x, y, z) (López & González, 2018). Esta distinción notacional permite diferenciar claramente entre el concepto abstracto de la variable y sus manifestaciones concretas en los datos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Clasificación de Variables</span>"
    ]
  },
  {
    "objectID": "C2.1.html#tipos-de-variables",
    "href": "C2.1.html#tipos-de-variables",
    "title": "3  Clasificación de Variables",
    "section": "3.2 Tipos de Variables",
    "text": "3.2 Tipos de Variables\nDependiendo de su naturaleza, las variables estadísticas se clasifican en dos categorías principales que determinan tanto los métodos de análisis apropiados como las técnicas de presentación de datos más adecuadas (López & González, 2018).\n\n3.2.1 Variables Cuantitativas\nLas variables cuantitativas son aquellas que expresan cantidades y cuyos resultados son de naturaleza numérica (López & González, 2018). Estas variables permiten realizar operaciones matemáticas y estadísticas avanzadas debido a su carácter numérico. Se subdividen en dos tipos fundamentales:\n\n3.2.1.1 Variables Cuantitativas Discretas\nTambién denominadas variables de conteo, son aquellas que no aceptan valores decimales y típicamente resultan de procesos de enumeración (López & González, 2018). Ejemplos relevantes en el contexto agronómico incluyen: número de plantas de café por metro cuadrado, cantidad de áfidos por planta, número de brotes por planta, número de racimos de banano por hectárea, y número de ausencias de un trabajador por mes.\nMatemáticamente, estas variables pueden representarse mediante conjuntos discretos. Por ejemplo, si X representa el número de árboles con cáncer en una muestra de 10 árboles, entonces X ∈ {0, 1, 2, 3, …, 9, 10} (López & González, 2018).\n\n\n3.2.1.2 Variables Cuantitativas Continuas\nEste tipo de variables pueden asumir cualquier valor dentro de un rango determinado, incluyendo valores decimales, y resultan típicamente de procesos de medición (López & González, 2018). En el ámbito agronómico, ejemplos representativos incluyen: altura de plantas, peso de semillas, temperatura de almacenamiento, diámetro de árboles, caudal de ríos, y precipitación pluvial.\nLa representación matemática de estas variables utiliza intervalos continuos. Por ejemplo, si D representa el diámetro de árboles de Pinus maximinoii en una plantación, entonces D ∈ [10, 50] centímetros (López & González, 2018).\n\n\n\n3.2.2 Variables Cualitativas\nLas variables cualitativas presentan como posibles resultados una cualidad o atributo del individuo investigado (López & González, 2018). Las posibles cualidades que puede presentar una variable cualitativa se denominan modalidades, categorías o atributos de la variable.\nSegún el número de categorías, estas variables se clasifican en:\n\nDicotómicas: presentan únicamente dos modalidades, como sexo (masculino, femenino) o resultado de evaluación (aprobado, reprobado)\nPolitómicas: presentan más de dos categorías, como estado civil, color de ojos, lugar de origen, o susceptibilidad de plantas a enfermedades (López & González, 2018)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Clasificación de Variables</span>"
    ]
  },
  {
    "objectID": "C2.1.html#mapa-mental-de-la-clasificación-de-variables-estadísticas",
    "href": "C2.1.html#mapa-mental-de-la-clasificación-de-variables-estadísticas",
    "title": "3  Clasificación de Variables",
    "section": "3.3 Mapa mental de la clasificación de variables estadísticas",
    "text": "3.3 Mapa mental de la clasificación de variables estadísticas\nA continuación, se presenta un mapa mental que sintetiza la información esencial sobre la clasificación de variables estadísticas, facilitando la comprensión visual de los conceptos abordados. Para explorar el mapa mental de manera interactiva y detallada, se recomienda acceder al siguiente enlace: https://ma-variables.vercel.app/.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Clasificación de Variables</span>"
    ]
  },
  {
    "objectID": "C2.1.html#escalas-de-medición",
    "href": "C2.1.html#escalas-de-medición",
    "title": "3  Clasificación de Variables",
    "section": "3.4 Escalas de Medición",
    "text": "3.4 Escalas de Medición\nLas escalas de medición constituyen un sistema de clasificación que determina el nivel de información que proporcionan las variables y, consecuentemente, los tipos de análisis estadísticos que pueden aplicarse (López & González, 2018).\n\n3.4.1 Escalas para Información Cualitativa\n\n3.4.1.1 Escala Nominal\nLa escala nominal representa el nivel más básico de medición y consiste en asignar nombres o etiquetas a las observaciones para distinguir diferentes agrupamientos (López & González, 2018). Cuando se emplean números en esta escala, estos tienen únicamente carácter simbólico, no numérico.\nEjemplos en el contexto agronómico incluyen: especies arbóreas presentes en una cuenca, tipos de uso del suelo (agrícola, forestal, pecuario), y municipio de procedencia de estudiantes (López & González, 2018).\n\n\n3.4.1.2 Escala Ordinal\nEn este nivel de medición, las unidades mantienen una relación jerárquica que permite establecer ordenamientos del tipo “mayor que” o “menor que” (López & González, 2018). Las categorías poseen un orden lógico, pero las distancias entre ellas no son necesariamente iguales.\nEjemplos representativos incluyen: nivel de estudios (primaria, secundaria, diversificado, universitaria), grado de aceptación de productos (buena, regular, mala), y escalas de severidad de enfermedades en plantas. La escala de Likert constituye un ejemplo paradigmático de medición ordinal, típicamente empleando cinco niveles de respuesta desde “totalmente en desacuerdo” hasta “totalmente de acuerdo” (López & González, 2018).\n\n\n\n3.4.2 Escalas para Información Cuantitativa\n\n3.4.2.1 Escala de Intervalo\nEsta escala proporciona información más precisa y permite mediciones sofisticadas al informar tanto sobre el orden de los objetos como sobre las distancias numéricas entre ellos (López & González, 2018). Los intervalos de igual tamaño en la escala representan diferencias equivalentes, independientemente de su ubicación en la escala.\nSin embargo, la escala de intervalo carece de un punto cero absoluto, siendo este arbitrario y no representando la ausencia total de la característica medida (López & González, 2018). Ejemplos incluyen: temperatura, coordenadas geográficas, y resultados de exámenes académicos.\n\n\n3.4.2.2 Escala de Razón\nLos atributos cuantitativos organizados en escala de razón poseen tanto intervalos significativos como un punto cero real que indica ausencia absoluta del valor medido (López & González, 2018). Esta escala permite realizar todas las operaciones matemáticas, incluyendo la determinación de razones o proporciones entre medidas.\nVariables agronómicas medidas en esta escala incluyen: peso, longitud, diámetro, volumen, estatura, y densidad. Por ejemplo, un individuo de 190 cm es exactamente dos veces más alto que uno de 95 cm, relación que se mantiene independientemente de la unidad de medida empleada (López & González, 2018).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Clasificación de Variables</span>"
    ]
  },
  {
    "objectID": "C2.1.html#mapa-mental-de-las-escalas-de-medición",
    "href": "C2.1.html#mapa-mental-de-las-escalas-de-medición",
    "title": "3  Clasificación de Variables",
    "section": "3.5 Mapa mental de las escalas de medición",
    "text": "3.5 Mapa mental de las escalas de medición\nA continuación, se presenta un mapa mental que sintetiza la información esencial sobre las escalas de medición de variables estadísticas, facilitando la comprensión visual de los conceptos abordados. Para explorar el mapa mental de manera interactiva y detallada, se recomienda acceder al siguiente enlace: https://ma-escalas.vercel.app/.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Clasificación de Variables</span>"
    ]
  },
  {
    "objectID": "C3.1.html",
    "href": "C3.1.html",
    "title": "4  Introducción a la Notación Sumatoria",
    "section": "",
    "text": "4.1 Elementos de la Notación Sumatoria\nLa notación sumatoria, representada por la letra griega sigma mayúscula (Σ), es una herramienta matemática que permite expresar de manera concisa la suma de una serie de términos. En lugar de escribir largas sumas de forma explícita, la notación sumatoria ofrece una manera compacta y generalizable de representar estas operaciones, facilitando el análisis y la manipulación de datos en diversos campos, incluyendo la agronomía (López & González, 2018).\nLa notación sumatoria se compone de los siguientes elementos clave:\nLa expresión general de la notación sumatoria se presenta de la siguiente manera:\n\\[\\huge\\sum_{i=m}^{n} xi\\]\nDonde:\nPor ejemplo, la suma de los primeros nnn números se expresa como:\n\\[\\huge\\sum_{i=m}^{n} i=1+2+3+...+n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Introducción a la Notación Sumatoria</span>"
    ]
  },
  {
    "objectID": "C3.1.html#elementos-de-la-notación-sumatoria",
    "href": "C3.1.html#elementos-de-la-notación-sumatoria",
    "title": "4  Introducción a la Notación Sumatoria",
    "section": "",
    "text": "Índice de Sumación: Es una variable, comúnmente denotada por \\(i\\), \\(j\\) o \\(k\\), que actúa como un contador, indicando el término específico que se está sumando en cada iteración.\nLímite Inferior: Es el valor inicial del índice de sumación, situado debajo del símbolo Σ. Indica el punto de partida de la suma.\nLímite Superior: Es el valor final del índice de sumación, situado encima del símbolo Σ. Indica el punto de finalización de la suma.\nSumando: Es la expresión matemática que se va a sumar, y generalmente depende del índice de sumación. Esta expresión define cómo se calcula cada término de la suma.\n\n\n\n\n\n\\(i\\) es el índice de sumación.\n\\(m\\) es el límite inferior.\n\\(n\\) es el límite superior.\n\\(xᵢ\\) es el sumando.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Introducción a la Notación Sumatoria</span>"
    ]
  },
  {
    "objectID": "C3.1.html#propiedades-de-la-notación-sumatoria",
    "href": "C3.1.html#propiedades-de-la-notación-sumatoria",
    "title": "4  Introducción a la Notación Sumatoria",
    "section": "4.2 Propiedades de la Notación Sumatoria",
    "text": "4.2 Propiedades de la Notación Sumatoria\nLa notación sumatoria es fundamental en el análisis estadístico, ya que permite expresar de manera compacta la suma de una serie de términos. Sus propiedades facilitan la manipulación algebraica de expresiones y el desarrollo de fórmulas estadísticas (López & González, 2018). A continuación se detallan las propiedades de la notación sumatoria:\n\n4.2.1 Suma de una constante\nCuando se suma una constante \\(k\\) un número \\(n\\) de veces, el resultado es igual al producto de la constante por el número de sumandos:\n\\[{\\huge \\sum_{i=1}^{n} k = n \\cdot k}\\]\nPor ejemplo, si \\(k = 3\\) y \\(n = 5\\):\n\\[{\\huge \\sum_{i=1}^{5} 3 = 3 + 3 + 3 + 3 + 3 = 5 \\times 3 = 15}\\]\nEsta propiedad es útil para simplificar sumas donde el sumando no depende del índice de sumación.\n\n\n4.2.2 Factor constante\nSi cada término de la suma es el producto de una constante \\(k\\) y una variable \\(x_i\\)​, la constante puede factorizarse fuera de la sumatoria:\n\\[{\\huge \\sum_{i=1}^{n} k \\cdot x_i = k \\sum_{i=1}^{n} x_i}\\]\nEsto permite simplificar cálculos y es especialmente útil en operaciones como el cálculo de medias ponderadas.\n\n\n4.2.3 Suma de variables\nLa suma de la suma de dos variables es igual a la suma de las sumas de cada variable por separado:\n\\[{\\huge \\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i}\\]\nEsta propiedad refleja la linealidad de la suma y es fundamental en la manipulación de expresiones estadísticas.\n\n\n4.2.4 Diferencia de variables\nDe manera análoga, la suma de la diferencia entre dos variables es igual a la diferencia entre las sumas de cada variable:\n\\[{\\huge \\sum_{i=1}^{n} (x_i - y_i) = \\sum_{i=1}^{n} x_i - \\sum_{i=1}^{n} y_i}\\]\nEsta propiedad también se deriva de la linealidad de la suma.\n\n\n4.2.5 Producto de dos variables\nLa suma del producto de dos variables se expresa como:\n\\[{\\huge \\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\ldots + x_n y_n}\\]\nEs importante destacar que, en general,\n\\[{\\huge \\sum_{i=1}^{n} x_i y_i \\neq \\left(\\sum_{i=1}^{n} x_i\\right) \\left(\\sum_{i=1}^{n} y_i\\right)}\\]\nEsta distinción es crucial en el cálculo de covarianzas y otros estadísticos.\n\n\n4.2.6 Suma de cuadrados vs. cuadrado de la suma\nSe debe diferenciar entre la suma de los cuadrados y el cuadrado de la suma:\n\\[{\\huge \\sum_{i=1}^{n} x_i^2 \\neq \\left(\\sum_{i=1}^{n} x_i\\right)^2}\\]\nLa suma de cuadrados es: \\[{\\huge \\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\ldots + x_n^2}\\]\nEl cuadrado de la suma es: \\[{\\huge \\left(\\sum_{i=1}^{n} x_i\\right)^2 = \\left(x_1 + x_2 + \\ldots + x_n\\right)^2}\\]\nAmbas expresiones son diferentes y tienen aplicaciones distintas en estadística, por ejemplo, en el cálculo de la varianza.\n\n\n4.2.7 Constante multiplicada por el cuadrado\nSi se multiplica una constante \\(k\\) por el cuadrado de cada término y se suman los resultados, se puede factorizar la constante fuera de la sumatoria:\n\\[{\\huge \\sum_{i=1}^{n} k \\cdot x_i^2 = k \\sum_{i=1}^{n} x_i^2}\\]\nEsta propiedad es útil en el desarrollo de fórmulas para momentos y otras medidas estadísticas.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Introducción a la Notación Sumatoria</span>"
    ]
  },
  {
    "objectID": "C3.1.html#aplicación-de-la-notación-sumatoria-en-estadística",
    "href": "C3.1.html#aplicación-de-la-notación-sumatoria-en-estadística",
    "title": "4  Introducción a la Notación Sumatoria",
    "section": "4.3 Aplicación de la notación sumatoria en estadística",
    "text": "4.3 Aplicación de la notación sumatoria en estadística\nLa notación sumatoria es una herramienta esencial en estadística, permitiendo expresar de manera concisa y eficiente operaciones de suma que son fundamentales en el cálculo de diversos estadísticos. En el contexto de la estadística y su aplicación en agronomía, la notación sumatoria facilita la comprensión y el cálculo de estadísticos clave. Estos estadísticos son fundamentales para resumir y analizar datos relacionados con el rendimiento de cultivos, características de plantas y otros parámetros relevantes en la investigación y la práctica agrícola (López & González, 2018). A continuación, se presentan ejemplos de cómo la notación sumatoria se aplica en el cálculo de estos estadísticos.\n\n4.3.1 Media Aritmética (Promedio)\nLa media aritmética es el valor representativo de un conjunto de datos y se utiliza para resumir el rendimiento promedio de cultivos, alturas de plantas u otras variables de interés en agronomía (López & González, 2018).\n\\[\n\\huge\n\\bar{x} = \\frac{\\sum_{i=1}^{n} x_i}{n}\n\\]\n\n\n4.3.2 Varianza Muestral\nLa varianza muestral cuantifica la dispersión de los datos respecto a la media, permitiendo evaluar la uniformidad de características como el peso de frutos o el rendimiento entre parcelas (López & González, 2018). \\[\n\\LARGE\nS^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1} = \\frac{\\sum_{i=1}^{n} x_i^2 - \\frac{(\\sum_{i=1}^{n} x_i)^2}{n}}{n-1}\n\\]\n\n\n4.3.3 Desviación Estándar Muestral\nLa desviación estándar, al ser la raíz cuadrada de la varianza, expresa la dispersión de los datos en las mismas unidades que la variable original, facilitando la interpretación de la variabilidad en experimentos agrícolas (López & González, 2018). \\[\n\\LARGE\nS = \\sqrt{S^2} = \\sqrt{\\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}}\n\\]\n\n\n4.3.4 Covarianza Muestral\nLa covarianza permite analizar la relación lineal entre dos variables, como la asociación entre la cantidad de fertilizante aplicado y el rendimiento del cultivo, siendo fundamental en estudios de correlación y regresión (López & González, 2018). \\[\n\\huge\nCov(x, y) = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{n-1}\n\\]\n\n\n4.3.5 Coeficiente de Correlación de Pearson\nEl coeficiente de correlación de Pearson mide la fuerza y dirección de la relación lineal entre dos variables, lo que resulta útil para evaluar la asociación entre factores ambientales y respuestas agronómicas (López & González, 2018). \\[\n\\LARGE\nr = \\frac{Cov(x, y)}{S_x S_y} = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}}\n\\]\n\n\n4.3.6 Ecuación de la Recta de Regresión Lineal Simple\nLa regresión lineal simple modela la relación entre una variable dependiente y una independiente, permitiendo predecir valores y analizar el efecto de factores como la fertilización sobre el rendimiento (López & González, 2018). \\[\n\\huge\ny = \\beta_0 + \\beta_1 x\n\\]\n\n\n4.3.7 Estimador del Intercepto (β₀)\nEl intercepto de la recta de regresión representa el valor esperado de la variable dependiente cuando la independiente es cero, lo que puede interpretarse como el rendimiento base en ausencia de tratamiento (López & González, 2018). \\[\n\\huge\n\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}\n\\]\n\n\n4.3.8 Estimador de la Pendiente (β₁)\nLa pendiente de la recta de regresión indica el cambio promedio en la variable dependiente por cada unidad de cambio en la independiente, siendo clave para interpretar el efecto de tratamientos en ensayos agrícolas (López & González, 2018). \\[\n\\huge\n\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}\n\\]\n\n\n4.3.9 Coeficiente de Determinación (R²)\nEl coeficiente de determinación expresa la proporción de la variabilidad de la variable dependiente explicada por el modelo de regresión, siendo un indicador de la calidad del ajuste en estudios agronómicos (López & González, 2018). \\[\n\\huge\nR^2 = \\frac{\\left[ \\sum_{i=1}^{n} (\\hat{y}_i - \\bar{y})^2 \\right]}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Introducción a la Notación Sumatoria</span>"
    ]
  },
  {
    "objectID": "C3.2.html",
    "href": "C3.2.html",
    "title": "5  Ejemplo Aplicado Sumatoria Simple",
    "section": "",
    "text": "5.1 Cálculo de la Suma Total de los Valores Observados\nPara ilustrar el uso de la notación sumatoria, se simulan los rendimientos de diez parcelas experimentales de maíz, expresados en kilogramos por planta. Los valores observados son los siguientes:\nTotal de observaciones: \\(n = 10\\)\nEl primer paso consiste en sumar todos los valores observados, utilizando la notación sumatoria: \\[\n\\large\\sum_{i=1}^{10} y_i = 23 + 25 + 18 + 27 + 22 + 20 + 24 + 26 + 19 + 21 = 225\n\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Ejemplo Aplicado Sumatoria Simple</span>"
    ]
  },
  {
    "objectID": "C3.2.html#cálculo-de-la-media-muestral",
    "href": "C3.2.html#cálculo-de-la-media-muestral",
    "title": "5  Ejemplo Aplicado Sumatoria Simple",
    "section": "5.2 Cálculo de la Media Muestral",
    "text": "5.2 Cálculo de la Media Muestral\nLa media muestral se obtiene dividiendo la suma total entre el número de observaciones ( n = 10 ): \\[\n\\large\\bar{y} = \\frac{1}{n} \\sum_{i=1}^{n} y_i = \\frac{225}{10} = 22.5\n\\]\nEsto significa que, en promedio, cada parcela produjo 22.5 kg por planta.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Ejemplo Aplicado Sumatoria Simple</span>"
    ]
  },
  {
    "objectID": "C3.2.html#cálculo-de-la-varianza-muestral",
    "href": "C3.2.html#cálculo-de-la-varianza-muestral",
    "title": "5  Ejemplo Aplicado Sumatoria Simple",
    "section": "5.3 Cálculo de la Varianza Muestral",
    "text": "5.3 Cálculo de la Varianza Muestral\nLa varianza muestral mide la dispersión de los datos respecto a la media. Para calcularla, se sigue el siguiente procedimiento:\n\nSe resta la media a cada valor observado (( \\(y_i - \\bar{y}\\)).\nSe eleva al cuadrado cada una de estas diferencias ( \\((y_i - \\bar{y})^2\\)).\nSe suman todos los cuadrados de las diferencias.\nFinalmente, se divide esta suma entre \\(n-1\\) (en este caso, 9).\n\nLa tabla siguiente resume estos cálculos:\n\n\n\n\\(i\\)\n\\(y_i\\)\n\\(y_i - \\bar{y}\\)\n\\((y_i - \\bar{y})^2\\)\n\n\n\n\n1\n23\n0.5\n0.25\n\n\n2\n25\n2.5\n6.25\n\n\n3\n18\n-4.5\n20.25\n\n\n4\n27\n4.5\n20.25\n\n\n5\n22\n-0.5\n0.25\n\n\n6\n20\n-2.5\n6.25\n\n\n7\n24\n1.5\n2.25\n\n\n8\n26\n3.5\n12.25\n\n\n9\n19\n-3.5\n12.25\n\n\n10\n21\n-1.5\n2.25\n\n\n\nSumando la última columna: \\[\n\\LARGE\\sum_{i=1}^{10} (y_i - \\bar{y})^2  = 82.5\n\\]\nLa varianza muestral se calcula así: \\[\n\\LARGE\\ s^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (y_i - \\bar{y})^2 = \\frac{82.5}{9} = 9.17\n\\]\nPor lo tanto, la varianza muestral es 9.17 kg² por planta².",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Ejemplo Aplicado Sumatoria Simple</span>"
    ]
  },
  {
    "objectID": "C3.3.html",
    "href": "C3.3.html",
    "title": "6  Sumatorias Dobles y Múltiples",
    "section": "",
    "text": "6.1 Propiedades básicas de las sumatorias dobles\nLa notación sumatoria puede extenderse para representar sumas sobre dos o más índices, lo que resulta útil en el análisis de datos organizados en tablas o matrices, como ocurre frecuentemente en experimentos agrícolas con varios tratamientos y repeticiones (López & González, 2018). La sumatoria doble se expresa de la siguiente manera: \\[\\huge\\sum_{i=1}^{n}\\sum_{j=1}^{m} x_{ij}\\]\nEn esta expresión, \\(x_{ij}\\)​ representa el elemento ubicado en la fila \\(i\\) y la columna \\(j\\) de una matriz de datos. El primer índice (\\(i\\)) recorre las filas y el segundo (\\(j\\)) las columnas. Este tipo de sumatoria es fundamental para calcular totales generales, promedios por tratamiento o por repetición, y para el análisis de varianza en diseños experimentales.\nCuando los datos se organizan en más dimensiones (por ejemplo, en matrices, cubos o hipercubos) la notación sumatoria se extiende añadiendo un índice por dimensión (Wackerly et al., 2014).\nSumatoria triple (o múltiple) sobre un arreglo de orden 3:\n\\(\\Huge\\sum_{i=1}^{n}\\sum_{j=1}^{m}\\sum_{k=1}^{p} x_{ijk}\\)\nPara sumas finitas, el orden de los signos sigma es intercambiable, debido a la conmutatividad y asociatividad de la adición (Montgomery, 2017). Para los fines del curso solamente se profundizará en las sumatorias dobles.\nLas sumatorias dobles conservan las propiedades fundamentales de las sumatorias simples, pero su aplicación requiere consideraciones adicionales debido a la presencia de múltiples índices. Estas propiedades son esenciales para la manipulación algebraica de expresiones estadísticas en el análisis de datos multidimensionales (Wackerly et al., 2014).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Sumatorias Dobles y Múltiples</span>"
    ]
  },
  {
    "objectID": "C3.3.html#propiedades-básicas-de-las-sumatorias-dobles",
    "href": "C3.3.html#propiedades-básicas-de-las-sumatorias-dobles",
    "title": "6  Sumatorias Dobles y Múltiples",
    "section": "",
    "text": "6.1.1 Propiedad del factor constante\nCuando una constante \\(c\\) multiplica a cada término de una sumatoria doble, esta constante puede factorizarse fuera de ambos signos de sumatoria. Esta propiedad se deriva directamente de la distributividad de la multiplicación sobre la adición (Ross, 2014).\nEnunciado formal:\n\\(\\huge \\sum_{i=1}^{n}\\sum_{j=1}^{m} c\\,x_{ij}=c\\sum_{i=1}^{n}\\sum_{j=1}^{m} x_{ij}\\)\nDemostración:\nLa demostración se basa en la aplicación repetida de la propiedad del factor constante para sumatorias simples:\n\\(\\Large \\sum_{i=1}^{n}\\sum_{j=1}^{m} c\\,x_{ij} = \\sum_{i=1}^{n}\\left(c\\sum_{j=1}^{m} x_{ij}\\right) = c\\sum_{i=1}^{n}\\sum_{j=1}^{m} x_{ij}\\)\nAplicación en estadística agrícola:\nEsta propiedad resulta fundamental cuando se requiere convertir unidades de medida. Por ejemplo, si los rendimientos están expresados en kg/ha y se desea convertirlos a t/ha, se multiplica por la constante \\(c=0.001\\):\n\\(\\Large \\sum_{i=1}^{n}\\sum_{j=1}^{m} 0.001 \\cdot x_{ij} = 0.001 \\sum_{i=1}^{n}\\sum_{j=1}^{m} x_{ij}\\)\n\n\n6.1.2 Propiedad de linealidad (aditividad)\nLa sumatoria doble de una suma de términos es igual a la suma de las sumatorias dobles de cada término por separado. Esta propiedad refleja la linealidad inherente del operador suma y es fundamental en el desarrollo de fórmulas estadísticas complejas (Montgomery, 2017).\nEnunciado formal:\n\\(\\Large \\sum_{i=1}^{n}\\sum_{j=1}^{m}\\bigl(x_{ij}+y_{ij}\\bigr) = \\sum_{i=1}^{n}\\sum_{j=1}^{m} x_{ij} + \\sum_{i=1}^{n}\\sum_{j=1}^{m} y_{ij}\\)\n\n\n6.1.3 Propiedad de descomposición en sumas parciales\nEsta propiedad establece que una sumatoria doble puede descomponerse en una sumatoria simple de sumatorias simples, lo que facilita el cálculo de totales por filas, columnas o grupos específicos. La conmutatividad de la adición garantiza que el orden de evaluación no afecte el resultado final (Hogg et al., 2019).\nEnunciado formal:\n\\(\\Large \\sum_{i=1}^{n}\\sum_{j=1}^{m} x_{ij} = \\sum_{i=1}^{n}\\left(\\sum_{j=1}^{m} x_{ij}\\right) = \\sum_{j=1}^{m}\\left(\\sum_{i=1}^{n} x_{ij}\\right)\\)\nInterpretación estadística:\n\n\\(\\sum_{j=1}^{m} x_{ij}\\)​ representa el total de la fila \\(i\\)\n\\(\\sum_{i=1}^{n} x_{ij}\\)​ representa el total de la columna \\(j\\)\nLa suma total puede calcularse como la suma de totales por filas o por columnas",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Sumatorias Dobles y Múltiples</span>"
    ]
  },
  {
    "objectID": "C3.3.html#aplicaciones-en-estadística-agrícola",
    "href": "C3.3.html#aplicaciones-en-estadística-agrícola",
    "title": "6  Sumatorias Dobles y Múltiples",
    "section": "6.2 Aplicaciones en Estadística Agrícola",
    "text": "6.2 Aplicaciones en Estadística Agrícola\nPara ilustrar la aplicación práctica de las sumatorias dobles, se presenta un ejemplo donde se analiza el rendimiento de tres variedades de maíz en tres localidades diferentes, diferenciando entre producción de grano y producción de rastrojo.\n\n6.2.1 Planteamiento del problema\nUn investigador evalúa tres variedades de maíz (V1, V2, V3) en tres localidades (L1, L2, L3), registrando tanto la producción de grano como la de rastrojo en kilogramos por parcela. Los datos se organizan en dos matrices de 3×3:\nMatriz de producción de grano (\\(G_{ij}\\)):\n\n\n\n\nL1\nL2\nL3\n\n\n\n\nV1\n4500\n4700\n4400\n\n\nV2\n4200\n4300\n4100\n\n\nV3\n4800\n4900\n4700\n\n\n\nMatriz de producción de rastrojo (\\(R_{ij}\\)):\n\n\n\n\nL1\nL2\nL3\n\n\n\n\nV1\n3000\n3200\n3100\n\n\nV2\n2800\n2900\n2700\n\n\nV3\n3500\n3600\n3400\n\n\n\nDonde i representa la variedad (i = 1, 2, 3) y j la localidad (j = 1, 2, 3).\n\n\n6.2.2 Análisis paso a paso de la producción de grano\nCálculo de totales por variedad (sumas por filas)\nPara cada variedad \\(i\\) , se calcula el total de producción de grano mediante:\n\n\n\n\n\n\n\n\n\nVariedad\nNotación sumatoria\nCálculo detallado\nTotal (kg)\n\n\n\n\nV1\n\\[\\large \\sum_{i=1}^{n} G_{i1} = G_{.1} \\]\n\\(4500 + 4700 + 4400\\)\n13,600\n\n\nV2\n\\[\\large \\sum_{i=1}^{n} G_{i2} = G_{.2} \\]\n\\(4200 + 4300 + 4100\\)\n12,600\n\n\nV3\n\\[\\large \\sum_{i=1}^{n} G_{i3} = G_{.3} \\]\n\\(4800 + 4900 + 4700\\)\n14,400\n\n\n\nCálculo de totales por localidad (sumas por columnas)\nPara cada localidad \\(j\\), se obtiene el total mediante:\n\n\n\n\n\n\n\n\n\nLocalidad\nNotación sumatoria\nCálculo detallado\nTotal (kg)\n\n\n\n\nL1\n\\[\\large \\sum_{j=1}^{n} G_{1j} = G_{1.} \\]\n\\(4500 + 4200 + 4800\\)\n13,500\n\n\nL2\n\\[\\large \\sum_{j=1}^{n} G_{2j} = G_{2.} \\]\n\\(4700 + 4300 + 4900\\)\n13,900\n\n\nL3\n\\[\\large \\sum_{j=1}^{n} G_{3j} = G_{3.} \\]\n\\(4400 + 4100 + 4700\\)\n13,200\n\n\n\nDemostración de la equivalencia de métodos de cálculo para el total de producción de grano\nLa suma total de producción de grano puede obtenerse mediante tres métodos equivalentes:\nMétodo 1: Suma directa de todos los elementos\n\\(\\sum_{i=1}^{3} \\sum_{j=1}^{3} G_{ij} = 4500 + 4700 + 4400 + 4200 + 4300 + 4100 + 4800 + 4900 + 4700 = 40,600 \\text{ kg}\\)\nMétodo 2: Suma de totales por variedad\n\\(\\Large \\sum_{i=1}^{3} \\sum_{j=1}^{3} G_{ij} = G_{..} = 13,600 + 12,600 + 14,400 = 40,600 \\text{ kg}\\)\nMétodo 3: Suma de totales por localidad\n\\(\\Large \\sum_{i=1}^{3} \\sum_{j=1}^{3} G_{ij} = G_{..} = 13,500 + 13,900 + 13,200 = 40,600 \\text{ kg}\\)\nEsta equivalencia demuestra la propiedad de descomposición en sumas parciales y confirma la consistencia de los cálculos.\n\n\n6.2.3 Aplicación de la propiedad de linealidad: Cálculo de biomasa total para la variedad 3\nPara ilustrar la propiedad de linealidad, se calcula la biomasa total de la variedad 3 (V3), definida como la suma de producción de grano y rastrojo.\nDatos para la variedad 3:\n\n\n\n\n\n\n\n\n\nLocalidad\nGrano (\\(G_{3j}\\))\nRastrojo (\\(R_{3j}\\))\nBiomasa (\\(B_{3j}\\))\n\n\n\n\nL1\n4,800\n3,500\n8,300\n\n\nL2\n4,900\n3,600\n8,500\n\n\nL3\n4,700\n3,400\n8,100\n\n\n\nPlanteamiento con notación sumatoria\nLa biomasa total de la variedad 3 se expresa como:\n\\(\\Large \\sum_{j=1}^{3} B_{3j} = \\sum_{j=1}^{3} (G_{3j} + R_{3j})\\)\nAplicación de la propiedad de linealidad\nUtilizando la propiedad de linealidad de las sumatorias:\n\\(\\Large \\sum_{j=1}^{3} (G_{3j} + R_{3j}) = \\sum_{j=1}^{3} G_{3j} + \\sum_{j=1}^{3} R_{3j}\\)\nCálculos detallados\n\nSuma de producción de grano para V3:\n\\(\\Large \\sum_{j=1}^{3} G_{3j} = 4,800 + 4,900 + 4,700 = 14,400 \\text{ kg}\\)\nSuma de producción de rastrojo para V3:\n\\(\\Large \\sum_{j=1}^{3} R_{3j} = 3,500 + 3,600 + 3,400 = 10,500 \\text{ kg}\\)\nBiomasa total para V3:\n\\(\\large \\sum_{j=1}^{3} B_{3j} = \\sum_{j=1}^{3} G_{3j} + \\sum_{j=1}^{3} R_{3j} = 14,400 + 10,500 = 24,900 \\text{ kg}\\)\nVerificación mediante suma directa\n\\(\\Large \\sum_{j=1}^{3} B_{3j} = 8,300 + 8,500 + 8,100 = 24,900 \\text{ kg}\\)\n\nLa coincidencia de resultados confirma la validez de la propiedad de linealidad.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Sumatorias Dobles y Múltiples</span>"
    ]
  },
  {
    "objectID": "C4.1.html",
    "href": "C4.1.html",
    "title": "7  Estadística descriptiva para datos sin agrupar",
    "section": "",
    "text": "7.1 Medidas de Tendencia Central\nEn el análisis estadístico, la descripción y el resumen de conjuntos de datos constituyen pasos fundamentales para la comprensión de fenómenos en ciencias aplicadas, como la agronomía. Las medidas de tendencia central, dispersión y posición relativa permiten sintetizar la información, identificar patrones y tomar decisiones informadas en la gestión de recursos agrícolas (López & González, 2018; Montgomery, 2017). Estas herramientas facilitan la interpretación de datos experimentales y la comparación entre diferentes tratamientos o condiciones de cultivo.\nPara ejemplificar el desarrollo de este tema, se utilizará la siguiente base de datos, correspondiente al rendimiento de maíz (en toneladas por hectárea) en ocho parcelas de diferente tamaño:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Estadística descriptiva para datos sin agrupar</span>"
    ]
  },
  {
    "objectID": "C4.1.html#medidas-de-tendencia-central",
    "href": "C4.1.html#medidas-de-tendencia-central",
    "title": "7  Estadística descriptiva para datos sin agrupar",
    "section": "",
    "text": "7.1.1 Media aritmética\nLa media aritmética representa el valor promedio de un conjunto de datos y constituye la medida de tendencia central más utilizada en estadística descriptiva (López & González, 2018). Se define como la suma de todos los valores dividida entre el número total de observaciones.\nFórmula:\n\\[\\huge \\bar{x} = \\frac{\\sum_{i=1}^{n} x_i}{n}\\]\ndonde \\(x_i\\) representa cada valor individual y \\(n\\) es el número total de observaciones.\nCálculo con los datos de ejemplo:\nDatos ordenados: 5.8, 5.9, 6.0, 6.1, 6.2, 6.3, 6.4, 6.5\n\\[\\bar{x} = \\frac{6.2 + 5.8 + 6.5 + 6.0 + 6.3 + 5.9 + 6.4 + 6.1}{8} = \\frac{49.2}{8} = 6.150\\; \\text{t ha}^{-1}\\]\nLa media aritmética es útil para describir el valor central de un conjunto de datos homogéneo, aunque presenta sensibilidad a valores extremos (Montgomery, 2017).\n\n\n7.1.2 Mediana\nLa mediana es el valor que divide un conjunto de datos ordenados en dos partes iguales, de manera que el 50% de las observaciones se encuentran por debajo y el 50% por encima de este valor (Steel & Torrie, 1980). Esta medida es especialmente útil cuando los datos presentan distribuciones asimétricas o contienen valores atípicos.\nProcedimiento de cálculo:\nPara un conjunto de datos con \\(n\\) observaciones ordenadas:\n\nSi \\(n\\) es impar:\n\\[\\huge\\text{Mediana} = x_{(n+1)/2} \\]\nSi \\(n\\) es par: \\[\\huge\\text{Mediana} = \\frac{x_{n/2} + x_{(n/2)+1}}{2}\\]\n\nCálculo con los datos de ejemplo:\nComo \\(n = 8\\) (par), la mediana se calcula:\n\\[\\large\\text{Mediana} = \\frac{x_4 + x_5}{2} = \\frac{6.1 + 6.2}{2} = 6.150\\; \\text{t ha}^{-1}\\]\nLa mediana es robusta ante valores atípicos y proporciona una medida de tendencia central más estable que la media aritmética en presencia de datos extremos (Anderson et al., 2018).\n\n\n7.1.3 Moda\nLa moda es el valor que aparece con mayor frecuencia en un conjunto de datos. En variables continuas, puede no existir moda o pueden existir múltiples modas (López & González, 2018). En el ejemplo presentado, todos los valores son únicos, por lo que no existe moda. La moda es particularmente útil para describir variables cualitativas o discretas, donde indica la categoría más frecuente.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Estadística descriptiva para datos sin agrupar</span>"
    ]
  },
  {
    "objectID": "C4.1.html#medidas-de-dispersión",
    "href": "C4.1.html#medidas-de-dispersión",
    "title": "7  Estadística descriptiva para datos sin agrupar",
    "section": "7.2 Medidas de Dispersión",
    "text": "7.2 Medidas de Dispersión\n\n7.2.1 Rango\nEl rango es la medida de dispersión más simple y se define como la diferencia entre el valor máximo y el valor mínimo del conjunto de datos (López & González, 2018). Proporciona una idea general de la variabilidad, aunque es muy sensible a valores extremos.\nFórmula:\n\\[\\huge R = x_{\\text{máx}} - x_{\\text{mín}}\\]\nCálculo con los datos de ejemplo:\n\\[\\huge R = 6.5 - 5.8 = 0.700\\; \\text{t ha}^{-1}\\]\n\n\n7.2.2 Varianza\nLa varianza mide la dispersión promedio de los datos respecto a la media aritmética. Para datos muestrales, se utiliza el denominador \\((n-1)\\) para obtener un estimador insesgado de la varianza poblacional (Montgomery, 2017).\nFórmula de la varianza muestral:\n\\[\\huge s^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}\\]\nCálculo paso a paso:\n\\[\\begin{aligned}\ns^2 &=  \\frac{0.0025 + 0.1225 + 0.1225 + 0.0225 + 0.0225 + 0.0625 + 0.0625 + 0.0025}{7} \\\\[4pt]\n&= \\frac{0.4200}{7} = 0.0600\\; \\text{(t ha}^{-1}\\text{)}^2\n\\end{aligned}\\]\n\n\n7.2.3 Desviación estándar\nLa desviación estándar es la raíz cuadrada positiva de la varianza y se expresa en las mismas unidades que los datos originales:\n\\[\\LARGE s = \\sqrt{s^2} = \\sqrt{0.0600} = 0.245\\; \\text{t ha}^{-1}\\]\n\n\n7.2.4 Coeficiente de variación\nEl coeficiente de variación (CV) expresa la dispersión relativa respecto a la media, permitiendo comparar la variabilidad entre diferentes conjuntos de datos que pueden tener diferentes unidades o magnitudes (Steel & Torrie, 1980).\nFórmula:\n\\[\\huge CV = \\frac{s}{\\bar{x}} \\times 100\\%\\]\nCálculo con los datos de ejemplo:\n\\[\\LARGE CV = \\frac{0.245}{6.150} \\times 100\\% = 3.98\\%\\]\nEste bajo coeficiente de variación indica una dispersión relativamente pequeña en los rendimientos, sugiriendo homogeneidad en el desempeño productivo de las parcelas.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Estadística descriptiva para datos sin agrupar</span>"
    ]
  },
  {
    "objectID": "C4.1.html#medidas-de-posición-relativa",
    "href": "C4.1.html#medidas-de-posición-relativa",
    "title": "7  Estadística descriptiva para datos sin agrupar",
    "section": "7.3 Medidas de Posición Relativa",
    "text": "7.3 Medidas de Posición Relativa\n\n7.3.1 Cuartiles\nLos cuartiles son valores que dividen un conjunto de datos ordenados en cuatro partes iguales. El primer cuartil (\\(Q_1\\)) es el valor por debajo del cual se encuentra el 25% de los datos, mientras que el tercer cuartil (\\(Q_3\\)) es el valor por debajo del cual se encuentra el 75% de los datos (López & González, 2018).\nMétodo de cálculo:\nPara un conjunto de datos ordenados de tamaño \\(n\\), la posición de un cuartil se determina por:\n\\[\\huge \\text{Posición} = p \\times (n+1)\\]\ndonde \\(p = 0.25\\) para \\(Q_1\\) y \\(p = 0.75\\) para \\(Q_3\\).\nSi la posición no es un número entero, se interpola linealmente entre los valores adyacentes.\nPrimer cuartil (\\(Q_1\\)):\n\\[\\large\\text{Posición de } Q_1 = 0.25 \\times (8+1) = 2.25\\]\n\\[Q_1 = x_2 + 0.25 \\times (x_3 - x_2) = 5.9 + 0.25 \\times (6.0 - 5.9) = 5.925\\; \\text{t ha}^{-1}\\]\nTercer cuartil (\\(Q_3\\)):\n\\[\\large\\text{Posición de } Q_3 = 0.75 \\times (8+1) = 6.75\\]\n\\[Q_3 = x_6 + 0.75 \\times (x_7 - x_6) = 6.3 + 0.75 \\times (6.4 - 6.3) = 6.375\\; \\text{t ha}^{-1}\\]\n\n\n7.3.2 Rango intercuartílico (RIC)\nEl rango intercuartílico es una medida de dispersión que representa la diferencia entre el tercer cuartil y el primer cuartil. Esta medida indica la amplitud del 50% central de los datos y es menos sensible a valores extremos que el rango total (Steel & Torrie, 1980).\nFórmula:\n\\[\\huge RIC = Q_3 - Q_1\\]\nCálculo con los datos de ejemplo:\n\\[\\Large RIC = 6.375 - 5.925 = 0.450\\; \\text{t ha}^{-1}\\]\nInterpretación del rango intercuartílico:\nEl rango intercuartílico de 0.450 t ha⁻¹ indica que el 50% central de las parcelas presenta una variación de rendimiento de 0.450 toneladas por hectárea. Esta medida es particularmente útil para:\n\nIdentificar la dispersión de la porción central de los datos\nDetectar valores atípicos (observaciones que se encuentran más allá de \\(Q_1 - 1.5 \\times RIC\\) o \\(Q_3 + 1.5 \\times RIC\\))\nComparar la variabilidad entre diferentes conjuntos de datos de manera robusta\n\nEn el contexto agronómico, un RIC relativamente pequeño sugiere que la mayoría de las parcelas tienen rendimientos similares, lo que puede indicar condiciones de cultivo homogéneas y prácticas de manejo consistentes (Montgomery, 2017).\n\n\n7.3.3 Percentiles\nLos percentiles dividen los datos en cien partes iguales, permitiendo identificar la posición relativa de cualquier observación dentro del conjunto de datos (Anderson et al., 2018). Son especialmente útiles para establecer rangos de referencia y realizar comparaciones.\nPercentil 10 (\\(P_{10}\\)):\n\\[\\large\\text{Posición de } P_{10} = 0.10 \\times (8+1) = 0.9\\]\n\\[P_{10} = x_1 + 0.9 \\times (x_2 - x_1) = 5.8 + 0.9 \\times (5.9 - 5.8) = 5.890\\; \\text{t ha}^{-1}\\]\nPercentil 90 (\\(P_{90}\\)):\n\\[\\large\\text{Posición de } P_{90} = 0.90 \\times (8+1) = 8.1\\]\nComo la posición (8.1) excede el número de datos (8), se utiliza el valor máximo:\n\\[P_{90} = x_8 = 6.5\\; \\text{t ha}^{-1}\\]\n\n\n7.3.4 Interpretación de los Resultados\nLos resultados obtenidos proporcionan una descripción completa del comportamiento de los rendimientos de maíz:\n\nTendencia central: El rendimiento promedio es de 6.150 t ha⁻¹, coincidiendo con la mediana, lo que sugiere una distribución simétrica.\nDispersión: La variabilidad es baja (CV = 3.98%), indicando homogeneidad en el desempeño productivo.\nPosición relativa:\n\nEl 25% de las parcelas tienen rendimientos por debajo de 5.925 t ha⁻¹\nEl 75% de las parcelas tienen rendimientos por debajo de 6.375 t ha⁻¹\nSolo el 10% de las parcelas tienen rendimientos por debajo de 5.890 t ha⁻¹\n\n\nEsta información es fundamental para la toma de decisiones en el manejo agronómico, permitiendo identificar parcelas de alto y bajo rendimiento, establecer metas productivas y evaluar la efectividad de diferentes prácticas de cultivo.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Estadística descriptiva para datos sin agrupar</span>"
    ]
  },
  {
    "objectID": "c4.3.html",
    "href": "c4.3.html",
    "title": "9  Cálculos en R",
    "section": "",
    "text": "9.1 Base de datos\nEl conjunto de datos IRIS es uno de los conjuntos de datos más utilizados en la literatura de estadística y aprendizaje automático. Fue introducido por Ronald Fisher en 1936 y contiene mediciones de cuatro características morfológicas de flores de tres especies distintas de iris: Iris setosa, Iris versicolor e Iris virginica. Este dataset es ampliamente empleado para ilustrar técnicas de análisis estadístico y clasificación supervisada (Fisher, 1936).\nReferencia del dataset: Fisher, R. (1936). Iris [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C56C76\nAcceso a recursos: El script completo con el ejemplo desarrollado y la base de datos IRIS pueden descargarse en el siguiente repositorio: https://github.com/Ludwing-MJ/MTCDPR_sin_agrupar",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Cálculos en R</span>"
    ]
  },
  {
    "objectID": "c4.3.html#configuración-del-entorno-de-trabajo",
    "href": "c4.3.html#configuración-del-entorno-de-trabajo",
    "title": "9  Cálculos en R",
    "section": "9.2 Configuración del Entorno de Trabajo",
    "text": "9.2 Configuración del Entorno de Trabajo\nAntes de comenzar cualquier análisis, es fundamental configurar adecuadamente el entorno de trabajo. Esto implica instalar y cargar los paquetes necesarios, así como explorar y comprender la estructura del conjunto de datos que se utilizará. En esta sección, se detallarán los pasos para configurar el entorno de trabajo y realizar una exploración inicial del conjunto de datos.\nSe recomienda crear un proyecto nuevo en R para organizar adecuadamente el trabajo de estadística descriptiva. Se sugiere seguir los siguientes pasos para establecer un entorno de trabajo ordenado:\n\nCrear una nueva carpeta en el directorio de trabajo denominada “Estadistica_Descriptiva_Iris”\nCrear un nuevo proyecto de R dentro de esta carpeta utilizando RStudio\nCrear un script donde se realizará y documentará el análisis estadístico\n\n\n9.2.1 Instalación y Carga de Paquetes\nSe procede a instalar y cargar los paquetes necesarios para el análisis estadístico descriptivo. Se utiliza la función condicional if(!require()) para verificar si el paquete está instalado antes de proceder con la instalación:\n\n# Instalación y carga de paquetes necesarios\n## Para manipulación y visualización de datos\nif (!require(tidyverse)) install.packages(\"tidyverse\")\n## Para estadísticas descriptivas\nif (!require(psych)) install.packages(\"psych\")\n\n\n\n9.2.2 Carga y exploración de los Datos\nEl dataset iris es un conjunto de datos clásico en estadística que contiene mediciones de características morfológicas de flores de tres especies del género Iris. Este dataset está incluido por defecto en R, lo que facilita su acceso para fines didácticos y de análisis estadístico.\n\n# Cargar el dataset iris\ndata(iris)\n\n# Explorar la estructura del dataset\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\nLa función str() proporciona información sobre la estructura del dataset:\n\nobject: Nombre del objeto a examinar\n\n\n# Visualizar las primeras observaciones\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\nLa función head() muestra las primeras filas del dataset:\n\nx: Objeto del cual mostrar las primeras filas\nn: Número de filas a mostrar (por defecto 6)\n\n\n# Resumen básico del dataset\nsummary(iris)\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\n\nLa función summary() proporciona un resumen estadístico básico:\n\nobject: Objeto del cual generar el resumen\nmaxsum: Número máximo de elementos a mostrar para factores (por defecto 7)\ndigits: Número de dígitos significativos para valores numéricos",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Cálculos en R</span>"
    ]
  },
  {
    "objectID": "c4.3.html#medidas-de-tendencia-central",
    "href": "c4.3.html#medidas-de-tendencia-central",
    "title": "9  Cálculos en R",
    "section": "9.3 Medidas de Tendencia Central",
    "text": "9.3 Medidas de Tendencia Central\n\n9.3.1 Media Aritmética\nLa función mean() calcula la media aritmética de un vector numérico.\n\nx: Vector numérico del cual se calculará la media.\ntrim: Fracción de valores a recortar de cada extremo del vector (por defecto 0).\nna.rm: Valor lógico que indica si se deben remover los valores NA (por defecto FALSE).\n\n\n# Calcular la media para la longitud del sépalo\nmean(iris$Sepal.Length)\n\n[1] 5.843333\n\n\n\n\n9.3.2 Mediana\nLa función median() calcula la mediana de un vector numérico.\n\nx: Vector numérico del cual se calculará la mediana.\nna.rm: Valor lógico que indica si se deben remover los valores NA (por defecto FALSE).\ntype: Tipo de algoritmo para calcular la mediana (entero entre 1 y 9).\n\n\n# Calcular la mediana para la longitud del sépalo\nmedian(iris$Sepal.Length)\n\n[1] 5.8\n\n\n\n\n9.3.3 Moda\nNo existe una función base en R para calcular la moda directamente. Se puede crear una función personalizada para calcular la moda que maneja valores faltantes y múltiples modas:\n\n# Función para calcular la moda\nmoda &lt;- function(x) {\n  # Eliminar valores NA\n  x &lt;- na.omit(x)\n\n  # Verificar si el vector está vacío\n  if (length(x) == 0) return(NA_character_)\n\n  # Calcular la frecuencia de cada valor\n  tabla &lt;- table(x)\n\n  # Identificar el/los valores con mayor frecuencia\n  max_frecuencia &lt;- max(tabla)\n  modas &lt;- names(tabla[tabla == max_frecuencia])\n\n  # Verificar si todos los valores son únicos (sin moda)\n  if (max_frecuencia == 1) return(NA_character_)\n\n  # Retornar la moda como un string separado por comas\n  return(paste(modas, collapse = \", \"))\n}\n\nUna vez ya definida la función para calcular la moda (tarea que se realiza la cada vez que se abre el software y se desea cargar la función en el entorno de trabajo). Se procede a calcular la moda para la longitud del sépalo:\n\n# Calcular la moda para la longitud del sépalo\nmoda(iris$Sepal.Length)\n\n[1] \"5\"",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Cálculos en R</span>"
    ]
  },
  {
    "objectID": "c4.3.html#medidas-de-dispersión",
    "href": "c4.3.html#medidas-de-dispersión",
    "title": "9  Cálculos en R",
    "section": "9.4 Medidas de Dispersión",
    "text": "9.4 Medidas de Dispersión\n\n9.4.1 Rango\nLa función range() devuelve los valores mínimo y máximo de un vector numérico. La función diff() calcula la diferencia entre los valores máximo y mínimo.\n\nx: Vector numérico del cual se calculará el rango.\nna.rm: Valor lógico que indica si se deben remover los valores NA (por defecto FALSE).\n\n\n# Obtener el valor minimo y máximo de la logitud del sépalo\nrange(iris$Sepal.Length)\n\n[1] 4.3 7.9\n\n# Calcular el rango para la longitud del sépalo\ndiff(range(iris$Sepal.Length))\n\n[1] 3.6\n\n\n\n\n9.4.2 Varianza\nLa función var() calcula la varianza de un vector numérico.\n\nx: Vector numérico del cual se calculará la varianza.\ny: Vector numérico opcional para calcular la covarianza.\nna.rm: Valor lógico que indica si se deben remover los valores NA (por defecto FALSE).\nuse: Método para manejar valores faltantes (por defecto “everything”).\n\n\n# Calcular la varianza para la longitud del sépalo\nvar(iris$Sepal.Length)\n\n[1] 0.6856935\n\n\n\n\n9.4.3 Desviación Estándar\nLa función sd() calcula la desviación estándar de un vector numérico.\n\nx: Vector numérico del cual se calculará la desviación estándar.\nna.rm: Valor lógico que indica si se deben remover los valores NA (por defecto FALSE).\n\n\n# Calcular la desviación estándar para la longitud del sépalo\nsd(iris$Sepal.Length)\n\n[1] 0.8280661\n\n\n\n\n9.4.4 Coeficiente de Variación\nNo existe una función base en R para calcular el coeficiente de variación directamente. Se puede crear una función personalizada o calcularse mediante operaciones aritméticas:\n\n# Función para calcular el coeficiente de variación\ncv &lt;- function(x) {\n  (sd(x) / mean(x)) * 100\n}\n# Calcular el coeficiente de variación para la longitud del sépalo\ncv(iris$Sepal.Length)\n\n[1] 14.17113\n\n# Calcular el coeficiente de variación para la longitud del sépalo\n(sd(iris$Sepal.Length) / mean(iris$Sepal.Length)) * 100\n\n[1] 14.17113",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Cálculos en R</span>"
    ]
  },
  {
    "objectID": "c4.3.html#medidas-de-posición-relativa",
    "href": "c4.3.html#medidas-de-posición-relativa",
    "title": "9  Cálculos en R",
    "section": "9.5 Medidas de Posición Relativa",
    "text": "9.5 Medidas de Posición Relativa\n\n9.5.1 Cuartiles\nLa función quantile() calcula los cuartiles y otros percentiles de un vector numérico.\n\nx: Vector numérico del cual se calcularán los cuantiles.\nprobs: Vector de probabilidades (0.25 para Q₁, 0.75 para Q₃).\nna.rm: Valor lógico que indica si se deben remover los valores NA (por defecto FALSE).\ntype: Método de cálculo (entero entre 1 y 9, por defecto 7).\n\n\n# Calcular cuartiles para la longitud del sépalo\nquantile(iris$Sepal.Length, probs = c(0.25, 0.5, 0.75))\n\n25% 50% 75% \n5.1 5.8 6.4 \n\n# Calcular Q1 y Q3 por separado\nQ1 &lt;- quantile(iris$Sepal.Length, 0.25); Q1\n\n25% \n5.1 \n\nQ3 &lt;- quantile(iris$Sepal.Length, 0.75); Q3\n\n75% \n6.4 \n\n\n\n\n9.5.2 Rango intercuartílico\nLa función IQR() calcula en automático el rango intercuartílico (Q1-Q3) de un vector numérico.\n\nx: Vector numérico del cual se calcularán los cuantiles.\nna.rm: Valor lógico que indica si se deben remover los valores NA (por defecto FALSE).\ntype: Método de cálculo (entero entre 1 y 9, por defecto 7).\n\n\n# Rango intercuartílico\nIQR(iris$Sepal.Length)\n\n[1] 1.3\n\n\n\n\n9.5.3 Percentiles\nLa función quantile() también se utiliza para calcular percentiles.\n\nx: Vector numérico del cual se calcularán los cuantiles.\nprobs: Vector de probabilidades (ej. 0.10 para el percentil 10, 0.90 para el percentil 90).\nna.rm: Valor lógico que indica si se deben remover los valores NA (por defecto FALSE).\ntype: Método de cálculo (entero entre 1 y 9, por defecto 7).\n\n\n# Calcular percentiles específicos\nquantile(iris$Sepal.Length, c(0.10, 0.90))\n\n10% 90% \n4.8 6.9 \n\n# Calcular el percentil 95\nquantile(iris$Sepal.Length, 0.95)\n\n  95% \n7.255",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Cálculos en R</span>"
    ]
  },
  {
    "objectID": "c4.3.html#análisis-completo-con-el-paquete-psych",
    "href": "c4.3.html#análisis-completo-con-el-paquete-psych",
    "title": "9  Cálculos en R",
    "section": "9.6 Análisis Completo con el Paquete psych",
    "text": "9.6 Análisis Completo con el Paquete psych\nLa función describe() del paquete psych calcula múltiples estadísticas descriptivas en una sola línea de código.\n\nx: Data frame o vector numérico.\nna.rm: Remover valores faltantes (por defecto TRUE).\ntrim: Fracción para la media recortada (por defecto 0.1).\nskew: Calcular asimetría (por defecto TRUE).\nkurtosis: Calcular curtosis (por defecto TRUE).\nranges: Calcular rangos (por defecto TRUE).\n\n\n# Análisis descriptivo completo del dataset iris\ndescribe(iris[,1:4])\n\n             vars   n mean   sd median trimmed  mad min max range  skew\nSepal.Length    1 150 5.84 0.83   5.80    5.81 1.04 4.3 7.9   3.6  0.31\nSepal.Width     2 150 3.06 0.44   3.00    3.04 0.44 2.0 4.4   2.4  0.31\nPetal.Length    3 150 3.76 1.77   4.35    3.76 1.85 1.0 6.9   5.9 -0.27\nPetal.Width     4 150 1.20 0.76   1.30    1.18 1.04 0.1 2.5   2.4 -0.10\n             kurtosis   se\nSepal.Length    -0.61 0.07\nSepal.Width      0.14 0.04\nPetal.Length    -1.42 0.14\nPetal.Width     -1.36 0.06\n\n\nInterpretación de los Estimadores de la Función describe()\nLa función describe() proporciona los siguientes estimadores estadísticos:\n\nn: Número de observaciones válidas (sin valores faltantes)\nmean: Media aritmética de los datos\nsd: Desviación estándar muestral\nmedian: Mediana o percentil 50\ntrimmed: Media recortada al 10% (elimina el 10% de valores extremos de cada cola)\nmad: Desviación absoluta mediana, medida robusta de dispersión\nmin: Valor mínimo observado\nmax: Valor máximo observado\nrange: Diferencia entre el valor máximo y mínimo\nskew: Coeficiente de asimetría. Valores cercanos a 0 indican distribución simétrica, valores positivos indican asimetría hacia la derecha, valores negativos hacia la izquierda\nkurtosis: Coeficiente de curtosis. Valores cercanos a 0 indican distribución normal, valores positivos indican distribución leptocúrtica (más puntiaguda), valores negativos indican distribución platicúrtica (más aplanada)\nse: Error estándar de la media, calculado como sd/√n",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Cálculos en R</span>"
    ]
  },
  {
    "objectID": "c4.3.html#visualización-de-datos",
    "href": "c4.3.html#visualización-de-datos",
    "title": "9  Cálculos en R",
    "section": "9.7 Visualización de Datos",
    "text": "9.7 Visualización de Datos\nLa visualización de datos es una parte esencial del análisis estadístico descriptivo, ya que permite identificar patrones, tendencias y anomalías en los datos de manera gráfica. A continuación, se presentan ejemplos de diferentes tipos de gráficos que se pueden utilizar para visualizar el dataset iris.\n\n9.7.1 Diagrama de Caja (Boxplot)\nEl diagrama de caja es una herramienta útil para visualizar la distribución de una variable numérica y comparar distribuciones entre diferentes grupos. Este gráfico muestra la mediana, los cuartiles (Q1 y Q3), los valores atípicos y los bigotes (valores mínimo y máximo dentro de un rango razonable).\n\n# Diagrama de caja para visualizar la longitud del sépalo por especie\nggplot(iris, aes(x = Species, y = Sepal.Length, fill = Species)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(title = \"Distribución de la Longitud del Sépalo por Especie\",\n       y = \"Longitud del Sépalo (cm)\")\n\n\n\n\n\n\n\n\nInterpretación:\n\nLa línea dentro de la caja representa la mediana.\nLos bordes de la caja representan los cuartiles Q1 (25%) y Q3 (75%).\nLos bigotes se extienden hasta los valores mínimo y máximo dentro de 1.5 veces el rango intercuartílico (IQR).\nLos puntos fuera de los bigotes son considerados valores atípicos.\n\n\n\n9.7.2 Histograma\nEl histograma es un gráfico que muestra la distribución de frecuencia de una variable numérica. Divide los datos en intervalos (bins) y muestra la frecuencia de observaciones en cada intervalo.\n\n# Histograma de la longitud del sépalo\nggplot(iris, aes(x = Sepal.Length)) +\n  geom_histogram(binwidth = 0.1, fill = \"steelblue\", color = \"black\") +\n  theme_minimal() +\n  labs(title = \"Distribución de la Longitud del Sépalo\",\n       x = \"Longitud del Sépalo (cm)\",\n       y = \"Frecuencia\")\n\n\n\n\n\n\n\n\nInterpretación:\n\nEl eje x representa los valores de la variable.\nEl eje y representa la frecuencia de observaciones en cada intervalo.\nLa forma del histograma puede indicar la simetría, asimetría y curtosis de la distribución.\n\n\n\n9.7.3 Gráfico de Dispersión (Scatter Plot)\nEl gráfico de dispersión se utiliza para visualizar la relación entre dos variables numéricas. Cada punto en el gráfico representa una observación, con la posición del punto determinada por los valores de las dos variables.\n\n# Gráfico de dispersión entre la longitud y el ancho del sépalo\nggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_point() +\n  theme_minimal() +\n  labs(title = \"Relación entre Longitud y Ancho del Sépalo\",\n       x = \"Longitud del Sépalo (cm)\",\n       y = \"Ancho del Sépalo (cm)\")\n\n\n\n\n\n\n\n\nInterpretación:\n\nEl gráfico muestra la relación entre dos variables.\nLos patrones en el gráfico pueden indicar correlación positiva, negativa o ninguna correlación.\nSe pueden utilizar diferentes colores o formas para representar diferentes grupos.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Cálculos en R</span>"
    ]
  },
  {
    "objectID": "C5.1.html",
    "href": "C5.1.html",
    "title": "10  Introducción y formulario",
    "section": "",
    "text": "10.1 Construcción de la Tabla de Frecuencia\nEl análisis de datos agrupados es una técnica que permite resumir y describir conjuntos extensos de observaciones mediante la organización de los valores en intervalos o clases (Lind, Marchal, & Wathen, 2017). Esta agrupación facilita la identificación de patrones y tendencias generales, así como la comparación entre diferentes conjuntos de datos. Para caracterizar la distribución de los datos agrupados, se emplean varios tipos de medidas: las medidas de tendencia central, las medidas de dispersión y las medidas de posición relativa (Triola, 2018).\nAplicaciones de la estadística descriptiva para datos agrupados\nA pesar de la disponibilidad de software estadístico avanzado, el análisis de datos agrupados sigue siendo relevante en diversas situaciones prácticas (Anderson et al., 2018). A continuación, se presentan algunos campos de aplicación:\nAntes de calcular estas medidas, es necesario construir una tabla de frecuencia para los datos agrupados. Este proceso implica los siguientes pasos:",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Introducción y formulario</span>"
    ]
  },
  {
    "objectID": "C5.1.html#construcción-de-la-tabla-de-frecuencia",
    "href": "C5.1.html#construcción-de-la-tabla-de-frecuencia",
    "title": "10  Introducción y formulario",
    "section": "",
    "text": "10.1.1 Determinación del número de clases\nEl número de clases, denotado como \\(k\\), se estima frecuentemente mediante la regla de Sturges, que se expresa como:\n\\[\\huge k = 1 + 3.322 \\log_{10}(N)\\]\ndonde \\(N\\) representa el número total de observaciones. Esta fórmula proporciona una guía para seleccionar un número de clases que permita un análisis adecuado, evitando tanto la excesiva fragmentación como la pérdida de información relevante (Triola, 2014).\nRecomendación para la aproximación del resultado de la regla de Sturges: Dado que el número de clases debe ser un entero, es común redondear el resultado de la fórmula de Sturges al entero más cercano. Sin embargo, es importante considerar el contexto del análisis y la naturaleza de los datos. En algunos casos, puede ser preferible redondear hacia arriba o hacia abajo para obtener un número de clases que facilite la interpretación y la comparación. Por ejemplo, si el resultado de la fórmula es 6.2, se podría optar por 6 o 7 clases, dependiendo de si se prefiere una representación más resumida o más detallada de los datos. En general, se recomienda experimentar con diferentes números de clases y evaluar el impacto en la claridad y la utilidad del análisis (Anderson et al., 2018).\n\n\n10.1.2 Cálculo del intervalo de clase\nEl intervalo de clase, simbolizado como \\(c\\), corresponde a la amplitud de cada clase y se calcula dividiendo el rango de los datos entre el número de clases: \\[\\huge\nc = \\frac{Rango}{k}\n\\]\nEl rango se obtiene restando el valor mínimo del valor máximo del conjunto de datos. Es recomendable ajustar el valor de \\(c\\) a un número conveniente para facilitar la interpretación y la construcción de la tabla (Lind et al., 2017).\n\n\n10.1.3 Definición de los límites de clase\nCada clase se define por un límite inferior y un límite superior. Para evitar ambigüedades en la asignación de los datos a las clases, se utiliza una notación estándar:\n\nCorchete [ : Indica que el límite está incluido en el intervalo.\nParéntesis ) : Indica que el límite no está incluido en el intervalo.\n\nPor ejemplo, el intervalo [10, 20) incluye todos los valores desde 10 hasta 19.999…, pero no incluye el valor 20. Esta distinción es crucial para evitar ambigüedades y asegurar que cada dato se clasifique en un único intervalo. La correcta definición de los límites de clase garantiza que cada observación se asigne a una única clase, evitando la superposición y facilitando el análisis (López & González, 2018).\n\n\n10.1.4 Frecuencia Absoluta\nLa frecuencia absoluta, denotada como \\(f_i\\)​, representa el número de observaciones que pertenecen a la clase \\(i\\). Este valor proporciona una medida directa de la concentración de datos en cada intervalo y es fundamental para el cálculo de las demás medidas estadísticas (Triola, 2014).\n\n\n10.1.5 Frecuencia Relativa\nLa frecuencia relativa, denotada como \\(fr_i\\)​, se calcula dividiendo la frecuencia absoluta de la clase \\(i\\) entre el número total de observaciones \\(N\\):\n\\[\\huge fr_i = \\frac{f_i}{N}\\]\nLa frecuencia relativa expresa la proporción de observaciones que pertenecen a cada clase y permite comparar la distribución de diferentes conjuntos de datos, independientemente de su tamaño. La suma de las frecuencias relativas de todas las clases debe ser igual a 1 (Lind et al., 2017).\n\n\n10.1.6 Frecuencia Acumulada\nLa frecuencia acumulada, denotada como \\(Fa_i\\)​, representa el número total de observaciones que son menores o iguales al límite superior de la clase \\(i\\). Se calcula sumando las frecuencias absolutas de todas las clases anteriores a la clase \\(i\\) y la frecuencia absoluta de la clase \\(i\\): \\[\\huge Fa_i = \\sum_{j=1}^{i} f_j\\]\nLa frecuencia acumulada proporciona información sobre la distribución de los datos a lo largo de todo el rango de valores y es útil para identificar percentiles y cuartiles (Anderson et al., 2018).\n\n\n10.1.7 Frecuencia Relativa Acumulada\nLa frecuencia relativa acumulada, denotada como \\(Fra_i\\)​, se calcula dividiendo la frecuencia acumulada de la clase \\(i\\) entre el número total de observaciones \\(N\\):\n\\[\\huge Fra_i = \\frac{Fa_i}{N}\\]\nLa frecuencia relativa acumulada expresa la proporción de observaciones que son menores o iguales al límite superior de la clase \\(i\\) y permite comparar la distribución de diferentes conjuntos de datos en términos de proporciones acumuladas. La frecuencia relativa acumulada del último intervalo debe ser igual a 1 (Triola, 2014).",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Introducción y formulario</span>"
    ]
  },
  {
    "objectID": "C5.1.html#medidas-de-tendencia-central-para-datos-agrupados",
    "href": "C5.1.html#medidas-de-tendencia-central-para-datos-agrupados",
    "title": "10  Introducción y formulario",
    "section": "10.2 Medidas de Tendencia Central para Datos Agrupados",
    "text": "10.2 Medidas de Tendencia Central para Datos Agrupados\nUna vez construida la tabla de frecuencia, se procede a calcular las medidas de tendencia central, que resumen la posición central de la distribución de los datos. Las principales medidas de tendencia central para datos agrupados son la media aritmética, la mediana y la moda.\n\n10.2.1 Media Aritmética\nLa media aritmética para datos agrupados, denotada como \\(\\bar{x}\\), se calcula como la suma ponderada de los puntos medios de cada clase, donde los pesos son las frecuencias absolutas de cada clase: \\[\\huge \\bar{x} = \\frac{\\sum_{i=1}^{k} f_i \\cdot x_i}{N}\\]\ndonde \\(f_i\\)​ es la frecuencia absoluta de la clase \\(i\\), \\(x_i\\)​ es el punto medio de la clase \\(i\\), \\(k\\) es el número de clases y \\(N\\) es el número total de observaciones. El punto medio de cada clase se calcula como el promedio de los límites inferior y superior de la clase (Lind et al., 2017).\n\n\n10.2.2 Mediana\nLa mediana es el valor que divide la distribución de los datos en dos partes iguales. Para calcular la mediana en datos agrupados, primero se identifica la clase mediana, que es la primera clase cuya frecuencia acumulada es mayor o igual a \\(N/2\\). Luego, se aplica la siguiente fórmula:\n\\[\\huge Me = L_{inf} + \\frac{\\frac{N}{2} - Fa_{ant}}{f_m} \\cdot c\\]\ndonde \\(L_{inf}\\)​ es el límite inferior de la clase mediana, \\(N\\) es el número total de observaciones, \\(Fa_{ant}\\)​ es la frecuencia acumulada de la clase anterior a la clase mediana, \\(f_m\\)​ es la frecuencia absoluta de la clase mediana y \\(c\\) es el intervalo de clase (Triola, 2014).\n\n\n10.2.3 Moda\nLa moda es el valor que ocurre con mayor frecuencia en la distribución de los datos. Para calcular la moda en datos agrupados, primero se identifica la clase modal, que es la clase con la mayor frecuencia absoluta. Luego, se aplica la siguiente fórmula: \\[ \\huge Mo = L_{inf} + \\frac{d_1}{d_1 + d_2} \\cdot c\\]\ndonde \\(L_{inf}\\)​ es el límite inferior de la clase modal, \\(d_1\\)​ es la diferencia entre la frecuencia de la clase modal y la frecuencia de la clase anterior, \\(d_2\\)​ es la diferencia entre la frecuencia de la clase modal y la frecuencia de la clase posterior, y \\(c\\) es el intervalo de clase (Anderson et al., 2018).",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Introducción y formulario</span>"
    ]
  },
  {
    "objectID": "C5.1.html#medidas-de-dispersión-para-datos-agrupados",
    "href": "C5.1.html#medidas-de-dispersión-para-datos-agrupados",
    "title": "10  Introducción y formulario",
    "section": "10.3 Medidas de Dispersión para Datos Agrupados",
    "text": "10.3 Medidas de Dispersión para Datos Agrupados\nLas medidas de dispersión cuantifican el grado de variabilidad o dispersión de los datos respecto a las medidas de tendencia central. Las principales medidas de dispersión para datos agrupados son el rango, la varianza, la desviación estándar y el coeficiente de variación.\n\n10.3.1 Rango\nEl rango es la medida de dispersión más simple y se calcula como la diferencia entre el valor máximo y el valor mínimo de los datos. Para datos agrupados, el rango se aproxima restando el límite inferior de la primera clase al límite superior de la última clase:\n\\[\\huge Rango = L_{sup,k} - L_{inf,1}\\]\ndonde \\(L_{sup,k}\\)​ es el límite superior de la última clase y \\(L_{inf,1}\\) es el límite inferior de la primera clase. Aunque es fácil de calcular, el rango es sensible a los valores extremos y no proporciona información sobre la distribución de los datos entre los extremos (Triola, 2014).\n\n\n10.3.2 Varianza\nLa varianza es una medida que cuantifica la dispersión de los datos respecto a la media aritmética. En el caso de datos agrupados, la varianza muestral se calcula considerando la frecuencia de cada clase y el punto medio correspondiente. La fórmula clásica para la varianza es la siguiente:\n\\[\\huge s^2 = \\frac{\\sum_{i=1}^{k} f_i \\cdot (x_i - \\bar{x})^2}{N - 1}\\]\ndonde \\(f_i\\)​ es la frecuencia absoluta de la clase \\(i\\), \\(x_i\\)​ es el punto medio de la clase \\(i\\), \\(\\bar{x}\\) es la media aritmética y \\(N\\) es el número total de observaciones. La varianza proporciona una medida de la dispersión de los datos alrededor de la media, pero se expresa en unidades al cuadrado, lo que dificulta su interpretación directa (Lind et al., 2017).\nComo alternativa, la varianza también puede calcularse utilizando una fórmula operativa, que resulta especialmente útil cuando se dispone de la suma de los productos de las frecuencias por los puntos medios y sus cuadrados. Esta fórmula es algebraicamente equivalente a la anterior y se expresa así:\n\\[ \\LARGE s^2 = \\frac{\\sum_{i=1}^{k} f_i x_i^2 - \\frac{\\left(\\sum_{i=1}^{k} f_i x_i\\right)^2}{N}}{N - 1}\\]\ndonde \\(f_i\\)​ es la frecuencia absoluta de la clase \\(i\\), \\(x_i\\)​ es el punto medio de la clase \\(i\\), \\(N\\) es el número total de observaciones y kkk es el número de clases. En esta fórmula, \\(\\sum_{i=1}^{k} f_i x_i^2\\) representa la suma de los productos de la frecuencia por el cuadrado del punto medio de cada clase, mientras que \\(\\sum_{i=1}^{k} f_i x_i\\) corresponde a la suma de los productos de la frecuencia por el punto medio de cada clase.\nAmbas fórmulas, la clásica y la operativa, son equivalentes y proporcionan el mismo resultado si se aplican correctamente (Lind et al., 2017; López & González, 2018; Triola, 2018).\n\n\n10.3.3 Desviación Estándar\nLa desviación estándar es la raíz cuadrada de la varianza y se expresa en las mismas unidades que los datos originales. Para datos agrupados, la desviación estándar se calcula como: \\[\\huge s = \\sqrt{s^2}\\]\nLa desviación estándar proporciona una medida de la dispersión de los datos alrededor de la media y es más fácil de interpretar que la varianza. Un valor alto de la desviación estándar indica una mayor dispersión de los datos, mientras que un valor bajo indica una menor dispersión (Anderson et al., 2018).\n\n\n10.3.4 Coeficiente de Variación\nEl coeficiente de variación es una medida relativa de dispersión que se calcula dividiendo la desviación estándar entre la media aritmética: \\[ \\huge CV = \\frac{s}{\\bar{x}} \\cdot 100\\%\\]\nEl coeficiente de variación expresa la dispersión de los datos como un porcentaje de la media y permite comparar la variabilidad de diferentes conjuntos de datos, independientemente de sus unidades de medida. Un valor alto del coeficiente de variación indica una mayor variabilidad relativa, mientras que un valor bajo indica una menor variabilidad relativa (Triola, 2014).",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Introducción y formulario</span>"
    ]
  },
  {
    "objectID": "C5.1.html#medidas-de-posición-relativa-para-datos-agrupados",
    "href": "C5.1.html#medidas-de-posición-relativa-para-datos-agrupados",
    "title": "10  Introducción y formulario",
    "section": "10.4 Medidas de Posición Relativa para Datos Agrupados",
    "text": "10.4 Medidas de Posición Relativa para Datos Agrupados\nLas medidas de posición relativa describen la ubicación de un valor específico en relación con el resto de los datos. Las principales medidas de posición relativa son los cuartiles y los percentiles.\n\n10.4.1 Cuartiles\nLos cuartiles dividen la distribución de los datos en cuatro partes iguales, cada una conteniendo el 25% de las observaciones. Los tres cuartiles se denotan como \\(Q_1\\)​, \\(Q_2\\)​ y \\(Q_3\\)​.\n\n\\(Q_1\\)​ (Primer Cuartil): Es el valor que separa el 25% inferior de los datos del 75% superior.\n\\(Q_2\\)​ (Segundo Cuartil): Es el valor que coincide con la mediana y separa el 50% inferior de los datos del 50% superior.\n\\(Q_3\\)​ (Tercer Cuartil): Es el valor que separa el 75% inferior de los datos del 25% superior.\n\nPara calcular los cuartiles en datos agrupados, primero se identifica la clase cuartil, que es la primera clase cuya frecuencia acumulada es mayor o igual a \\(i \\cdot N/4\\), donde \\(i\\) es el número del cuartil (1, 2 o 3). Luego, se aplica la siguiente fórmula: \\[\\huge Q_i = L_{inf} + \\frac{\\frac{i \\cdot N}{4} - Fa_{ant}}{f_q} \\cdot c\\]\ndonde \\(L_{inf}\\)​ es el límite inferior de la clase cuartil, \\(N\\) es el número total de observaciones, \\(Fa_{ant}\\)​ es la frecuencia acumulada de la clase anterior a la clase cuartil, \\(f_q\\)​ es la frecuencia absoluta de la clase cuartil y \\(c\\) es el intervalo de clase (Lind et al., 2017).\n\n\n10.4.2 Percentiles\nLos percentiles dividen la distribución de los datos en cien partes iguales, cada una conteniendo el 1% de las observaciones. El percentil \\(P_p\\)​ es el valor que separa el \\(p \\%\\) inferior de los datos del \\((100−p) \\%\\) superior.\nPara calcular los percentiles en datos agrupados, primero se identifica la clase percentil, que es la primera clase cuya frecuencia acumulada es mayor o igual a \\(p \\cdot N/100\\). Luego, se aplica la siguiente fórmula: \\[\\LARGE P_p = L_{inf} + \\frac{\\frac{p \\cdot N}{100} - Fa_{ant}}{f_p} \\cdot c\\]\ndonde \\(L_{inf}\\)​ es el límite inferior de la clase percentil, \\(N\\) es el número total de observaciones, \\(Fa_{ant}\\)​ es la frecuencia acumulada de la clase anterior a la clase percentil, \\(f_p\\)​ es la frecuencia absoluta de la clase percentil y \\(c\\) es el intervalo de clase (Triola, 2014).",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Introducción y formulario</span>"
    ]
  },
  {
    "objectID": "C5.3.html",
    "href": "C5.3.html",
    "title": "12  Ejemplo en R",
    "section": "",
    "text": "12.1 Base de datos\nReferencia del dataset: Fisher, R. (1936). Iris [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C56C76\nAcceso a recursos: El script completo con el ejemplo desarrollado y la base de datos IRIS pueden descargarse en el siguiente repositorio: https://github.com/Ludwing-MJ/MTCDPR_datos_agrupados\nA continuación, se presenta un conjunto de datos correspondientes a la longitud del pétalo (en cm) de 150 flores de la especie Iris, organizados en formato matricial para facilitar su visualización y análisis. Estos datos serán utilizados para ilustrar el cálculo de estadísticos descriptivos para datos agrupados, siguiendo las metodologías propuestas en la sección anterior.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ejemplo en R</span>"
    ]
  },
  {
    "objectID": "C5.3.html#base-de-datos",
    "href": "C5.3.html#base-de-datos",
    "title": "12  Ejemplo en R",
    "section": "",
    "text": "1.4\n1.4\n1.3\n1.5\n1.4\n1.7\n1.4\n1.5\n1.4\n1.5\n\n\n1.5\n1.6\n1.4\n1.1\n1.2\n1.5\n1.3\n1.4\n1.7\n1.5\n\n\n1.7\n1.5\n1.0\n1.7\n1.9\n1.6\n1.6\n1.5\n1.4\n1.6\n\n\n1.6\n1.5\n1.5\n1.4\n1.5\n1.2\n1.3\n1.4\n1.3\n1.5\n\n\n1.3\n1.3\n1.3\n1.6\n1.9\n1.4\n1.6\n1.4\n1.5\n1.4\n\n\n4.7\n4.5\n4.9\n4.0\n4.6\n4.5\n4.7\n3.3\n4.6\n3.9\n\n\n3.5\n4.2\n4.0\n4.7\n3.6\n4.4\n4.5\n4.1\n4.5\n3.9\n\n\n4.8\n4.0\n4.9\n4.7\n4.3\n4.4\n4.8\n5.0\n4.5\n3.5\n\n\n3.8\n3.7\n3.9\n5.1\n4.5\n4.5\n4.7\n4.4\n4.1\n4.0\n\n\n4.4\n4.6\n4.0\n3.3\n4.2\n4.2\n4.2\n4.3\n3.0\n4.1\n\n\n6.0\n5.1\n5.9\n5.6\n5.8\n6.6\n4.5\n6.3\n5.8\n6.1\n\n\n5.1\n5.3\n5.5\n5.0\n5.1\n5.3\n5.5\n6.7\n6.9\n5.0\n\n\n5.7\n4.9\n6.7\n4.9\n5.7\n6.0\n4.8\n4.9\n5.6\n5.8\n\n\n6.1\n6.4\n5.6\n5.1\n5.6\n6.1\n5.6\n5.5\n4.8\n5.4\n\n\n5.6\n5.1\n5.1\n5.9\n5.7\n5.2\n5.0\n5.2\n5.4\n5.1",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ejemplo en R</span>"
    ]
  },
  {
    "objectID": "C5.3.html#preparación-del-entorno-de-trabajo",
    "href": "C5.3.html#preparación-del-entorno-de-trabajo",
    "title": "12  Ejemplo en R",
    "section": "12.2 Preparación del entorno de trabajo",
    "text": "12.2 Preparación del entorno de trabajo\n\n# Instalación y carga de paquetes necesarios\n## Para manipulación y visualización de datos\nif (!require(tidyverse)) install.packages(\"tidyverse\")\n## Para exportar archivos en excel\nif (!require(writexl)) install.packages(\"writexl\")\n## Para importar archivos en excel\nif (!require(readxl)) install.packages(\"readxl\")",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ejemplo en R</span>"
    ]
  },
  {
    "objectID": "C5.3.html#carga-y-preparación-de-datos",
    "href": "C5.3.html#carga-y-preparación-de-datos",
    "title": "12  Ejemplo en R",
    "section": "12.3 Carga y Preparación de Datos",
    "text": "12.3 Carga y Preparación de Datos\nPrimero, se carga el conjunto de datos iris y se extrae la variable de interés, en este caso, la longitud del pétalo.\n\n# Cargar el dataset iris\ndata(iris)\n\n# Extraer la variable longitud de pétalo\nlongitud_petalo &lt;- iris$Petal.Length",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ejemplo en R</span>"
    ]
  },
  {
    "objectID": "C5.3.html#determinación-de-parámetros-básicos-para-la-agrupación",
    "href": "C5.3.html#determinación-de-parámetros-básicos-para-la-agrupación",
    "title": "12  Ejemplo en R",
    "section": "12.4 Determinación de parámetros básicos para la agrupación",
    "text": "12.4 Determinación de parámetros básicos para la agrupación\nSe define una función personalizada para calcular los parámetros necesarios para agrupar los datos: número de observaciones, valores mínimo y máximo, rango, número de clases (usando la regla de Sturges) y amplitud de clase.\n\n# Función para calcular parámetros de agrupamiento\ncalcular_parametros_agrupamiento &lt;- function(datos) {\n  n &lt;- length(datos)\n  x_min &lt;- min(datos)\n  x_max &lt;- max(datos)\n  rango &lt;- x_max - x_min\n  \n  # Regla de Sturges para número de clases\n  k &lt;- round(1 + 3.322 * log10(n))\n  \n  # Amplitud de clase\n  amplitud &lt;- rango / k\n  \n  return(list(\n    n = n,\n    x_min = x_min,\n    x_max = x_max,\n    rango = rango,\n    k = k,\n    amplitud = amplitud\n  ))\n}\n\nUna vez ya definida la función para calcular los parámetros necesarios para la agrupación de los datos (tarea que se realiza la cada vez que se abre el software y se desea cargar la función en el entorno de trabajo). Se procede a calcularlos:\n\n# Aplicar función\nparametros &lt;- calcular_parametros_agrupamiento(longitud_petalo)\n# Visualizar el resultado\nparametros\n\n$n\n[1] 150\n\n$x_min\n[1] 1\n\n$x_max\n[1] 6.9\n\n$rango\n[1] 5.9\n\n$k\n[1] 8\n\n$amplitud\n[1] 0.7375",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ejemplo en R</span>"
    ]
  },
  {
    "objectID": "C5.3.html#construcción-de-la-tabla-de-frecuencias",
    "href": "C5.3.html#construcción-de-la-tabla-de-frecuencias",
    "title": "12  Ejemplo en R",
    "section": "12.5 Construcción de la tabla de frecuencias",
    "text": "12.5 Construcción de la tabla de frecuencias\nSe utiliza una función personalizada para construir la tabla de frecuencias, calculando los límites de clase, marcas de clase, frecuencias absolutas, relativas y acumuladas, así como sumas necesarias para los cálculos posteriores.\n\n# Función corregida para construir tabla de frecuencias\nconstruir_tabla_frecuencias &lt;- function(datos, parametros) {\n  \n  # Crear breaks (puntos de corte) para las clases\n  # Esto garantiza exactamente k clases\n  breaks &lt;- seq(parametros$x_min, \n                parametros$x_max, \n                length.out = parametros$k + 1)\n  \n  # Crear límites de clase a partir de los breaks\n  limite_inferior &lt;- breaks[-length(breaks)]  # Todos excepto el último\n  limite_superior &lt;- breaks[-1]               # Todos excepto el primero\n  \n  # Calcular marcas de clase\n  marca_clase &lt;- (limite_inferior + limite_superior) / 2\n  \n  # Calcular frecuencias absolutas usando cut()\n  intervalos &lt;- cut(datos, \n                    breaks = breaks,\n                    include.lowest = TRUE,\n                    right = FALSE,\n                    labels = FALSE)  # Usar números en lugar de etiquetas\n  \n  # Contar frecuencias por clase\n  frecuencia_absoluta &lt;- as.numeric(table(factor(intervalos, \n                                                 levels = 1:parametros$k)))\n  \n  # Reemplazar NA por 0 si alguna clase queda vacía\n  frecuencia_absoluta[is.na(frecuencia_absoluta)] &lt;- 0\n  \n  # Calcular frecuencias derivadas\n  frecuencia_relativa &lt;- frecuencia_absoluta / parametros$n\n  frecuencia_acumulada &lt;- cumsum(frecuencia_absoluta)\n  fi_xi &lt;- frecuencia_absoluta * marca_clase\n  fi_xi2 &lt;- frecuencia_absoluta * (marca_clase^2)\n  \n  # Crear tabla\n  tabla &lt;- data.frame(\n    Clase = 1:parametros$k,\n    Limite_Inferior = round(limite_inferior, 3),\n    Limite_Superior = round(limite_superior, 3),\n    Marca_Clase = round(marca_clase, 3),\n    Frecuencia_Absoluta = frecuencia_absoluta,\n    Frecuencia_Relativa = round(frecuencia_relativa, 4),\n    Frecuencia_Acumulada = frecuencia_acumulada,\n    fi_xi = round(fi_xi, 3),\n    fi_xi2 = round(fi_xi2, 3)\n  )\n  \n  return(tabla)\n}\n\nUna vez ya definida la función para construir la tabla de frecuencias (tarea que se realiza la cada vez que se abre el software y se desea cargar la función en el entorno de trabajo). Se procede a emplear la función para construir la tabla:\n\n# Construir tabla de frecuencias\ntabla_freq &lt;- construir_tabla_frecuencias(longitud_petalo, parametros)\n\n# Mostrar tabla\ntabla_freq\n\n  Clase Limite_Inferior Limite_Superior Marca_Clase Frecuencia_Absoluta\n1     1           1.000           1.738       1.369                  48\n2     2           1.738           2.475       2.106                   2\n3     3           2.475           3.213       2.844                   1\n4     4           3.213           3.950       3.581                  10\n5     5           3.950           4.688       4.319                  29\n6     6           4.688           5.425       5.056                  32\n7     7           5.425           6.163       5.794                  22\n8     8           6.163           6.900       6.531                   6\n  Frecuencia_Relativa Frecuencia_Acumulada   fi_xi  fi_xi2\n1              0.3200                   48  65.700  89.927\n2              0.0133                   50   4.213   8.873\n3              0.0067                   51   2.844   8.087\n4              0.0667                   61  35.812 128.254\n5              0.1933                   90 125.244 540.896\n6              0.2133                  122 161.800 818.101\n7              0.1467                  144 127.463 738.486\n8              0.0400                  150  39.188 255.943\n\n\nLa tabla de frecuencias es la base para calcular las medidas de tendencia central y dispersión en datos agrupados. Cada fila representa un intervalo de clase y sus frecuencias asociadas. Si se desea exportar la tabla de frecuencias en un formato tabular para su presentación se utiliza la función write_xlsx como se muestra a continuación.\n\n# Exportar la tabla de frecuencias\nwrite_xlsx(tabla_freq, \"tabla_frecuencias.xlsx\")\n\nAl ejecutar esta linea de código R automáticamente guardará un archivo .xlsx en la carpeta del proyecto.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ejemplo en R</span>"
    ]
  },
  {
    "objectID": "C5.3.html#medidas-de-tendencia-central",
    "href": "C5.3.html#medidas-de-tendencia-central",
    "title": "12  Ejemplo en R",
    "section": "12.6 Medidas de Tendencia Central",
    "text": "12.6 Medidas de Tendencia Central\nSe define una función personalizada para calcular la media, mediana y moda a partir de la tabla de frecuencias.\n\n# Función para calcular medidas de tendencia central\ncalcular_tendencia_central &lt;- function(tabla, parametros) {\n  # Media aritmética\n  media &lt;- sum(tabla$fi_xi) / parametros$n\n  \n  # Mediana\n  n &lt;- parametros$n\n  posicion_mediana &lt;- n / 2\n  clase_mediana &lt;- which(tabla$Frecuencia_Acumulada &gt;= posicion_mediana)[1]\n  L &lt;- tabla$Limite_Inferior[clase_mediana]\n  F_anterior &lt;- ifelse(clase_mediana == 1,\n                       0, tabla$Frecuencia_Acumulada[\n                         clase_mediana - 1])\n  f_m &lt;- tabla$Frecuencia_Absoluta[clase_mediana]\n  A &lt;- tabla$Limite_Superior[clase_mediana] -\n    tabla$Limite_Inferior[clase_mediana]\n  mediana &lt;- L + ((posicion_mediana - F_anterior) / f_m) * A\n  \n  # Moda\n  clase_modal &lt;- which.max(tabla$Frecuencia_Absoluta)\n  fa_ant &lt;- ifelse(clase_modal == 1, \n                   0, tabla$Frecuencia_Absoluta[\n                     clase_modal - 1])\n  fa_sig &lt;- ifelse(clase_modal == parametros$k, \n                   0, tabla$Frecuencia_Absoluta[\n                     clase_modal + 1])\n  d1 &lt;- tabla$Frecuencia_Absoluta[clase_modal] - fa_ant\n  d2 &lt;- tabla$Frecuencia_Absoluta[clase_modal] - fa_sig\n  if ((d1 + d2) == 0) {\n    moda &lt;- NA\n  } else {\n    moda &lt;- tabla$Limite_Inferior[clase_modal] + (d1 / (d1 + d2)) * A\n  }\n  \n  return(list(media = media, mediana = mediana, moda = moda))\n}\n\nEn esta función la media se calcula como el promedio ponderado de las marcas de clase. La mediana y la moda se estiman usando fórmulas específicas para datos agrupados, considerando la posición dentro de la clase correspondiente, una vez ya definida la función se procede a utilizarla para calcular las medidas de tendencia central.\n\n# Calcular medidas\ntendencia &lt;- calcular_tendencia_central(tabla_freq, parametros)\n\n# Mostrar resultados \ntendencia\n\n$media\n[1] 3.748427\n\n$mediana\n[1] 4.306276\n\n$moda\n[1] 1.376851",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ejemplo en R</span>"
    ]
  },
  {
    "objectID": "C5.3.html#medidas-de-dispersión",
    "href": "C5.3.html#medidas-de-dispersión",
    "title": "12  Ejemplo en R",
    "section": "12.7 Medidas de Dispersión",
    "text": "12.7 Medidas de Dispersión\nSe utiliza una función personalizada para calcular el rango, la varianza, la desviación estándar y el coeficiente de variación.\n\n# Función para calcular medidas de dispersión\ncalcular_dispersion &lt;- function(tabla, parametros, media) {\n  # Rango aproximado\n  rango_aprox &lt;- tabla$Limite_Superior[parametros$k] - \n    tabla$Limite_Inferior[1]\n  \n  # Varianza\n  varianza &lt;- (sum(tabla$fi_xi2) - (sum(tabla$fi_xi)^2 / parametros$n)) / \n    (parametros$n - 1)\n  \n  # Desviación estándar\n  desviacion_std &lt;- sqrt(varianza)\n  \n  # Coeficiente de variación\n  cv &lt;- (desviacion_std / media) * 100\n  \n  return(list(\n    rango = rango_aprox,\n    varianza = varianza,\n    desviacion_std = desviacion_std,\n    cv = cv\n  ))\n}\n\nEl rango es la diferencia entre el límite superior del último intervalo y el límite inferior del primero. La varianza y la desviación estándar se calculan usando las sumas ponderadas de las marcas de clase al cuadrado. El coeficiente de variación expresa la dispersión relativa respecto a la media. Para estos cálculos la función emplea las formulas presentadas en la sección anterior y una vez definida se procede al cálculo de las medidas de dispersión:\n\n# Calcular medidas de dispersión\ndispersion &lt;- calcular_dispersion(tabla_freq, parametros, tendencia$media)\n\n# Mostrar los resultados\ndispersion\n\n$rango\n[1] 5.9\n\n$varianza\n[1] 3.22793\n\n$desviacion_std\n[1] 1.796644\n\n$cv\n[1] 47.93062",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ejemplo en R</span>"
    ]
  },
  {
    "objectID": "C5.3.html#medidas-de-posición-relativa",
    "href": "C5.3.html#medidas-de-posición-relativa",
    "title": "12  Ejemplo en R",
    "section": "12.8 Medidas de Posición Relativa",
    "text": "12.8 Medidas de Posición Relativa\nFinalmente, se puede calcular cualquier cuartil o percentil usando una función personalizada.\n\n# Función para calcular cuartiles y percentiles\ncalcular_posicion_relativa &lt;- function(tabla,\n                                       parametros, posicion, \n                                       tipo = \"cuartil\") {\n  if (tipo == \"cuartil\") {\n    pos_valor &lt;- posicion * parametros$n / 4\n  } else if (tipo == \"percentil\") {\n    pos_valor &lt;- posicion * parametros$n / 100\n  }\n  \n  clase_objetivo &lt;- which(tabla$Frecuencia_Acumulada &gt;= pos_valor)[1]\n  fa_anterior &lt;- ifelse(clase_objetivo == 1, 0, \n                        tabla$Frecuencia_Acumulada[clase_objetivo - 1])\n  \n  valor &lt;- tabla$Limite_Inferior[clase_objetivo] + \n    ((pos_valor - fa_anterior) / \n       tabla$Frecuencia_Absoluta[clase_objetivo]) * parametros$amplitud\n  \n  return(valor)\n}\n\nEsta función permite calcular cualquier medida de posición relativa, como cuartiles o percentiles, utilizando la tabla de frecuencias y la fórmula correspondiente para datos agrupados. Una vez definida en el entorno de trabajo se procede a utilizar para calcular Q1 y P80 como en el ejemplo anterior:\n\n# Calcular Q1 \nQ1 &lt;- calcular_posicion_relativa(tabla_freq, parametros, 1, \"cuartil\")\nQ1\n\n[1] 1.576172\n\n# Calcular P80\nP80 &lt;- calcular_posicion_relativa(tabla_freq, parametros, 80, \"percentil\")\nP80\n\n[1] 5.379406",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ejemplo en R</span>"
    ]
  },
  {
    "objectID": "C5.3.html#histograma",
    "href": "C5.3.html#histograma",
    "title": "12  Ejemplo en R",
    "section": "12.9 Histograma",
    "text": "12.9 Histograma\nEl histograma es un gráfico de barras que representa la distribución de frecuencias de los datos agrupados. Cada barra corresponde a un intervalo de clase, y su altura es proporcional a la frecuencia absoluta o relativa de ese intervalo.\nConstrucción en R:\n\nhist(longitud_petalo, \n     breaks = seq(min(longitud_petalo), \n                  max(longitud_petalo), \n                  length.out = parametros$k + 1),\n     main = \"Histograma de la Longitud del Pétalo\",\n     xlab = \"Longitud del Pétalo (cm)\",\n     ylab = \"Frecuencia\",\n     col = \"skyblue\",\n     border = \"black\")\n\n\n\n\n\n\n\n\nExplicación:\n\nhist(): Función para crear histogramas en R.\nlongitud_pedalo: Variable a graficar.\nbreaks: Define los límites de los intervalos de clase. Se utiliza seq() para generar una secuencia de valores desde el mínimo hasta el máximo de la variable, dividida en k + 1 puntos (donde k es el número de clases).\nmain, xlab, ylab: Títulos y etiquetas de los ejes.\ncol, border: Colores de las barras y del borde.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ejemplo en R</span>"
    ]
  },
  {
    "objectID": "C5.3.html#polígono-de-frecuencias",
    "href": "C5.3.html#polígono-de-frecuencias",
    "title": "12  Ejemplo en R",
    "section": "12.10 Polígono de Frecuencias",
    "text": "12.10 Polígono de Frecuencias\nEl polígono de frecuencias es un gráfico de líneas que conecta los puntos medios de las barras del histograma. Se construye uniendo los puntos correspondientes a las marcas de clase y sus respectivas frecuencias.\nConstrucción en R:\n\n# Crear el polígono de frecuencias\nplot(tabla_freq$Marca_Clase,\n     tabla_freq$Frecuencia_Absoluta, \n     type = \"l\",  # \"l\" para líneas\n     main = \"Polígono de Frecuencias de la Longitud del Pétalo\",\n     xlab = \"Longitud del Pétalo (cm)\",\n     ylab = \"Frecuencia\",\n     col = \"blue\",\n     lwd = 2)  # Grosor de la línea\n\n# Agregar puntos en las marcas de clase\npoints(tabla_freq$Marca_Clase,\n       tabla_freq$Frecuencia_Absoluta, \n       col = \"red\", pch = 16)  \n\n\n\n\n\n\n\n# pch = 16 para círculos rellenos\n\nExplicación:\n\nplot(type = \"l\"): Crea un gráfico de líneas.\ntabla_freq$Marca_Clasey tabla_freq$Frecuencia_Absoluta: Vectores con las marcas de clase y las frecuencias absolutas.\npoints(): Agrega puntos en las marcas de clase para resaltar los valores.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ejemplo en R</span>"
    ]
  },
  {
    "objectID": "C5.3.html#ojiva-polígono-de-frecuencias-acumuladas",
    "href": "C5.3.html#ojiva-polígono-de-frecuencias-acumuladas",
    "title": "12  Ejemplo en R",
    "section": "12.11 Ojiva (Polígono de Frecuencias Acumuladas)",
    "text": "12.11 Ojiva (Polígono de Frecuencias Acumuladas)\nLa ojiva es un gráfico de líneas que representa las frecuencias acumuladas. Se construye uniendo los puntos correspondientes a los límites superiores de los intervalos de clase y sus respectivas frecuencias acumuladas.\nConstrucción en R:\n\n# Ojiva \"Menor Que\"\nplot(tabla_freq$Limite_Superior, tabla_freq$Frecuencia_Acumulada, \n     type = \"l\",\n     main = \"Ojiva 'Menor Que' de la Longitud del Pétalo\",\n     xlab = \"Longitud del Pétalo (cm)\",\n     ylab = \"Frecuencia Acumulada\",\n     col = \"blue\")\n\n\n\n\n\n\n\n# Ojiva \"Mayor Que\"\nfrecuencia_acumulada_mayor_que &lt;- rev(cumsum(\n  rev(tabla_freq$Frecuencia_Absoluta)))\nplot(tabla_freq$Limite_Inferior, frecuencia_acumulada_mayor_que,\n     type = \"l\",\n     main = \"Ojiva 'Mayor Que' de la Longitud del Pétalo\",\n     xlab = \"Longitud del Pétalo (cm)\",\n     ylab = \"Frecuencia Acumulada\",\n     col = \"red\")",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ejemplo en R</span>"
    ]
  },
  {
    "objectID": "C5.3.html#gráfico-de-barras",
    "href": "C5.3.html#gráfico-de-barras",
    "title": "12  Ejemplo en R",
    "section": "12.12 Gráfico de Barras",
    "text": "12.12 Gráfico de Barras\nAunque el histograma es el gráfico más común para datos agrupados, también se puede utilizar un gráfico de barras para representar las frecuencias de cada clase.\nConstrucción en R:\n\nbarplot(tabla_freq$Frecuencia_Absoluta,\n        names.arg = tabla_freq$Marca_Clase,\n        main = \"Gráfico de Barras de la Longitud del Pétalo\",\n        xlab = \"Marca de Clase (cm)\",\n        ylab = \"Frecuencia Absoluta\",\n        col = \"orange\",\n        border = \"black\")\n\n\n\n\n\n\n\n\nExplicación:\n\nbarplot(): Función para crear gráficos de barras en R.\ntabla_freq$Frecuencia_Absoluta: Vector con las frecuencias absolutas.\nnames.arg: Etiquetas para cada barra (en este caso, las marcas de clase).",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ejemplo en R</span>"
    ]
  },
  {
    "objectID": "C5.3.html#cálculos-a-partir-de-una-tabla-de-frecuencias",
    "href": "C5.3.html#cálculos-a-partir-de-una-tabla-de-frecuencias",
    "title": "12  Ejemplo en R",
    "section": "12.13 Cálculos a partir de una tabla de frecuencias",
    "text": "12.13 Cálculos a partir de una tabla de frecuencias\nNo siempre es posible encontrar la base de datos completa para poder construir la tabla de frecuencias y realizar las estimaciones, muchas veces se parte de una tabla de frecuencias debido a la sensibilidad de los datos, privacidad o porque los datos son muy antiguos y se han perdido los registos, para este ejemplo se va a explicar como usar las funciones partiendo de la tabla de frecuencias exportada a un archivo excel previamente en esta sección:\n\n12.13.1 Importar la tabla de frecuencias\nCabe resaltar que para que esto funcione la tabla de frecuencias que se vaya a importar debe tener el mismo formato (numero y nombre de columnas ) que la tabla que se muestra a continuación:\n\n\n\n\n\n\n#Importar tabla de frecuencias\ntabla&lt;-read_excel(\"tabla_frecuencias.xlsx\")\n\n\n\n12.13.2 Estimación de los parámetros de agrupación\nUna vez importada la tabla de frecuencias adecuadamente se procede a estimar los parámetros de agrupación a partir de ella, ya que estos son indispensables para las funciones elaboradas para estimar las medidas de tendencia central, dispersión y posición relativa.\n\n# Funcion personalizada para calcular los parametros\ncalcular_parametros_desde_tabla &lt;- function(tabla) {\n  n &lt;- sum(tabla$Frecuencia_Absoluta)\n  x_min &lt;- min(tabla$Limite_Inferior)\n  x_max &lt;- max(tabla$Limite_Superior)\n  rango &lt;- x_max - x_min\n  k &lt;- nrow(tabla)\n  amplitud &lt;- (tabla$Limite_Superior[1] - tabla$Limite_Inferior[1])\n\n  return(list(\n    n = n,\n    x_min = x_min,\n    x_max = x_max,\n    rango = rango,\n    k = k,\n    amplitud = amplitud\n  ))\n}\n\nUna vez cargada la función al entorno de trabajo esta se utiliza con la tabla de frecuencias previamente importada para estimar los parámetros de agrupación\n\n# Estimar los parametros de agrupacion a partir de la tabla de frecuencias\nparametros_tabla &lt;- calcular_parametros_desde_tabla(tabla)\n\n\n\n12.13.3 Estimación de los parámetros con las mismas funciones\nUna vez ya se ha importado la tabla de frecuencias y estimado los parámetros de agrupación a partir de la tabla de frecuencias es posible usar las funciones previamente establecidas para calculas los parámetros como se muestra a continuación:\n\nMedidas de tendencia central\n\n# Calcular medidas\ntendencia_tabla &lt;- calcular_tendencia_central(tabla, parametros_tabla)\n\n# Mostrar resultados \ntendencia_tabla\n\n$media\n[1] 3.748427\n\n$mediana\n[1] 4.306034\n\n$moda\n[1] 1.376596\n\n\nMedidas de dispersión\n\n# Calcular medidas de dispersión\ndispersion_tabla &lt;- calcular_dispersion(tabla, \n                                        parametros_tabla, \n                                        tendencia_tabla$media)\n\n# Mostrar los resultados\ndispersion_tabla\n\n$rango\n[1] 5.9\n\n$varianza\n[1] 3.22793\n\n$desviacion_std\n[1] 1.796644\n\n$cv\n[1] 47.93062\n\n\nMedidas de posición relativa\n\n# Calcular Q1 y P80\nQ1_tabla &lt;- calcular_posicion_relativa(tabla, parametros_tabla,\n                                       1, \"cuartil\");Q1_tabla\n\n[1] 1.576172\n\nP80_tabla &lt;- calcular_posicion_relativa(tabla, parametros_tabla,\n                                        80, \"percentil\");P80_tabla\n\n[1] 5.378906\n\n\n\nComo se puede observar siempre y cuando la tabla de frecuencias siga el formato propuesto las funciones seguirán operando con normalidad partiendo desde una base de datos completa o únicamente desde una tabla de frecuencias, cabe resaltar que el ajustar el formato de la tabla de frecuencias cuando se trabaja con una tabla de frecuencias y no con una base de datos completa es una tarea adicional que se debe llevar a cabo previo al análisis.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Ejemplo en R</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referencias",
    "section": "",
    "text": "Hogg, R. V., McKean, J. W., & Craig, A. T. (2019). Introduction to mathematical statistics (8th ed.). Pearson.\nIhaka, R., & Gentleman, R. (1996). R: A language for data analysis and graphics. Journal of Computational and Graphical Statistics, 5(3), 299-314.\nLópez, E., & González, B. (2018). Notas de Estadística General (Edición marzo 2018). Guatemala: Universidad de San Carlos de Guatemala.\nR Core Team (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.\nXie, Y., Allaire, J. J., & Grolemund, G. (2018). R Markdown: The definitive guide (1st ed.). Chapman and Hall/CRC. https://doi.org/10.1201/9781138359444\nConover, W. J. (1999). Practical Nonparametric Statistics (3rd ed.). Wiley.\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). CRC Press.\nJohnson, R. A., & Wichern, D. W. (2014). Applied Multivariate Statistical Analysis (6th ed.). Pearson.\nMontgomery, D. C. (2017). Design and analysis of experiments (9th ed.). Wiley.\nMontgomery, D. C., & Runger, G. C. (2018). Applied Statistics and Probability for Engineers (7th ed.). Wiley.\nRoss, S. M. (2014). Introduction to probability and statistics for engineers and scientists (5th ed.). Academic Press.\nWackerly, D. D., Mendenhall, W., & Scheaffer, R. L. (2014). Mathematical statistics with applications (7th ed.). Cengage.\nWebster, R., & Oliver, M. A. (2007). Geostatistics for Environmental Scientists (2nd ed.). Wiley.\nWalpole, R. E., Myers, R. H., Myers, S. L., & Ye, K. (2012). Probability and Statistics for Engineers and Scientists (9th ed.). Pearson.",
    "crumbs": [
      "Referencias"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R para el Análisis Estadístico de Datos Agrícolas",
    "section": "",
    "text": "Introducción\nEn el ámbito de la investigación agronómica, la estadística se presenta como una herramienta esencial para la transformación de datos en conocimiento aplicable. Este manual, titulado ‘R para el Análisis Estadístico de Datos Agrícolas’, ha sido concebido como una introducción accesible y práctica al análisis estadístico moderno, con un enfoque particular en el lenguaje R.\nTradicionalmente, la estadística ha proporcionado los cimientos para la toma de decisiones informadas en la agricultura. Sin embargo, la creciente disponibilidad de datos y la necesidad de análisis más sofisticados exigen un enfoque actualizado y eficiente. R, un lenguaje de programación y entorno de software ampliamente adoptado en la ciencia de datos y la estadística aplicada, ofrece la flexibilidad y el poder necesarios para abordar estos desafíos (Ihaka & Gentleman, 1996; R Core Team, 2023).\nEste manual está diseñado para guiar al lector a través de un proceso gradual y comprensible, desde los conceptos estadísticos fundamentales hasta las técnicas esenciales para el análisis estadístico de datos agrícolas. Se abordan temas clave como aspectos introductorios, clasificación de variables, notación sumatoria, medidas de tendencia central y dispersión (tanto para datos agrupados como no agrupados), introducción a probabilidades, distribuciones de probabilidad discretas, la distribución normal, intervalos de confianza, pruebas de hipótesis, y regresión lineal y correlación.\nCada capítulo combina la teoría con ejemplos prácticos y estudios de caso relevantes, facilitando la comprensión y la aplicación de los métodos en situaciones reales. El propósito central es proporcionar una base sólida que permita a los profesionales y estudiantes de agronomía utilizar R de manera efectiva en su trabajo diario. No se requiere experiencia previa en programación o estadística; el manual está estructurado para ser accesible a todos, independientemente de su nivel de conocimientos iniciales.",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "index.html#organización-del-manual",
    "href": "index.html#organización-del-manual",
    "title": "R para el Análisis Estadístico de Datos Agrícolas",
    "section": "Organización del manual",
    "text": "Organización del manual\nEl presente manual se estructura de manera progresiva, comenzando con los fundamentos esenciales y avanzando hacia técnicas estadísticas aplicadas, con el objetivo de facilitar una comprensión integral del análisis estadístico de datos agrícolas utilizando R. Cada capítulo incluye explicaciones detalladas, ejemplos prácticos y código R reproducible, diseñados para consolidar el aprendizaje y fomentar la aplicación efectiva de los conceptos.\nA continuación, se presenta una tabla que resume la organización del manual, detallando los temas cubiertos en cada capítulo:\n\n\n\n\n\n\n\n\nCapítulo\nTítulo\nDescripción\n\n\n\n\n1\nAspectos introductorios\nIntroducción a la estadística, su importancia en agronomía y primeros pasos en R y RStudio.\n\n\n2\nClasificación de variables\nTipos de variables, escalas de medición y ejemplos aplicados al ámbito agrícola.\n\n\n3\nNotación sumatoria\nFundamentos y aplicaciones de la notación sumatoria en el cálculo de estadísticos descriptivos.\n\n\n4\nMedidas de tendencia central y dispersión (datos no agrupados)\nCálculo e interpretación de media, mediana, moda, rango, varianza y desviación estándar para datos no agrupados.\n\n\n5\nMedidas de tendencia central y dispersión (datos agrupados)\nAplicación de medidas de tendencia central y dispersión en tablas de frecuencia utilizando R.\n\n\n6\nIntroducción a probabilidades\nConceptos básicos de probabilidad, espacio muestral, eventos y reglas de probabilidad.\n\n\n7\nDistribuciones de probabilidad discretas\nEstudio de las distribuciones binomial y Poisson, cálculo de probabilidades y representación gráfica en R.\n\n\n8\nDistribución normal\nPropiedades y aplicaciones de la distribución normal, cálculo de probabilidades y gráficos en R.\n\n\n9\nIntervalos de confianza\nConstrucción e interpretación de intervalos de confianza para medias y proporciones con apoyo de R.\n\n\n10\nPruebas de hipótesis\nFormulación y evaluación de hipótesis estadísticas, cálculo de estadísticos de prueba y toma de decisiones.\n\n\n11\nRegresión lineal y correlación\nAjuste de modelos de regresión lineal, interpretación de coeficientes y análisis de correlación en R.\n\n\n\nCada capítulo está diseñado para ser independiente, permitiendo que los lectores avancen a su propio ritmo y consulten las secciones según sus necesidades. La tabla proporciona una visión general de la estructura del manual, facilitando la navegación y la comprensión de los temas abordados.",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "index.html#requisitos-previos",
    "href": "index.html#requisitos-previos",
    "title": "R para el Análisis Estadístico de Datos Agrícolas",
    "section": "Requisitos Previos",
    "text": "Requisitos Previos\nEl presente manual no exige conocimientos previos en programación ni en estadística. Está orientado a personas que se inician en el análisis estadístico de datos agrícolas, partiendo desde los conceptos más básicos y avanzando de manera progresiva. Cada tema se desarrolla con explicaciones claras y detalladas, acompañadas de ejemplos y ejercicios prácticos.\nPara aprovechar al máximo el contenido, se recomienda contar con lo siguiente:\n\nInterés en aprender: La disposición para explorar el análisis estadístico y el uso de nuevas herramientas facilita el proceso de aprendizaje.\nAcceso a una computadora: Es necesario disponer de un equipo con capacidad para instalar R y RStudio, cuyas instrucciones de instalación y configuración se incluyen en el manual.\nConstancia y práctica: El desarrollo de habilidades en estadística y en el uso de R requiere tiempo y dedicación. Los ejercicios propuestos están diseñados para acompañar y reforzar el aprendizaje.\n\nCon este enfoque, cualquier persona interesada podrá utilizar el manual como guía para iniciarse en el análisis estadístico de datos agrícolas empleando R, sin importar su experiencia previa en el área.",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "index.html#software-y-convenciones",
    "href": "index.html#software-y-convenciones",
    "title": "R para el Análisis Estadístico de Datos Agrícolas",
    "section": "Software y convenciones",
    "text": "Software y convenciones\nLa versión en línea de este manual está disponible en https://ludwing-mj.github.io/R-para-el-analisis-estadistico-de-datos-/, y la fuente en español se encuentra alojada en el siguiente repositorio de GitHub https://github.com/Ludwing-MJ/R-para-el-analisis-estadistico-de-datos-. El desarrollo del manual se realizó utilizando Quarto, una herramienta que permite transformar archivos con extensión .qmd en formatos publicables como HTML, PDF y EPUB, facilitando la integración de código, resultados y texto en un solo documento reproducible.\nDurante la elaboración del manual se emplearon diversos paquetes del ecosistema de R, entre los que destacan knitr y bookdown, los cuales permiten combinar las ventajas de LaTeX y R para la generación de documentos dinámicos y reproducibles (Xie et al., 2018). Esta integración posibilita que los ejemplos de código y los resultados presentados sean fácilmente replicables por el\nA lo largo del manual, se presentan fragmentos de código que pueden ser copiados y ejecutados directamente en la consola de R para obtener los mismos resultados que se muestran en el texto. Los bloques de código se destacan en recuadros similares al siguiente:\n\n4 + 6\na &lt;- c(1, 5, 6)\n5 * a\n1:10\n\nLos resultados generados por la ejecución de estos códigos se identifican con el numero uno encerrado entre cochetes ([1]) al inicio de cada línea, indicando que corresponden a la salida producida por R. Todo lo que comience con [1] representa resultados y no debe ser copiado como parte del código. Por ejemplo, al ejecutar el bloque anterior, se obtendrían los siguientes resultados:\n\n\n[1] 10\n\n\n[1]  5 25 30\n\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nPara garantizar la reproducibilidad y transparencia, se recomienda que el lector utilice versiones actualizadas de R y de los paquetes mencionados. La información sobre el entorno de desarrollo y las versiones de los paquetes utilizados en la construcción de este manual puede consultarse ejecutando el siguiente comando en R:\n\ndevtools::session_info()\n\nWarning in system2(\"quarto\", \"-V\", stdout = TRUE, env = paste0(\"TMPDIR=\", : el\ncomando ejecutado '\"quarto\"\nTMPDIR=C:/Users/FAUSAC/AppData/Local/Temp/Rtmp6l3bD0/file1e8811a037bc -V' tiene\nel estatus 1\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.3 (2025-02-28 ucrt)\n os       Windows 11 x64 (build 26100)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  Spanish_Guatemala.utf8\n ctype    Spanish_Guatemala.utf8\n tz       America/Guatemala\n date     2025-06-12\n pandoc   3.4 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n quarto   NA @ C:\\\\PROGRA~1\\\\Quarto\\\\bin\\\\quarto.exe\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n cachem        1.1.0   2024-05-16 [1] CRAN (R 4.4.3)\n cli           3.6.5   2025-04-23 [1] CRAN (R 4.4.3)\n devtools      2.4.5   2022-10-11 [1] CRAN (R 4.4.3)\n digest        0.6.37  2024-08-19 [1] CRAN (R 4.4.3)\n ellipsis      0.3.2   2021-04-29 [1] CRAN (R 4.4.3)\n evaluate      1.0.3   2025-01-10 [1] CRAN (R 4.4.3)\n fastmap       1.2.0   2024-05-15 [1] CRAN (R 4.4.3)\n fs            1.6.6   2025-04-12 [1] CRAN (R 4.4.3)\n glue          1.8.0   2024-09-30 [1] CRAN (R 4.4.3)\n htmltools     0.5.8.1 2024-04-04 [1] CRAN (R 4.4.3)\n htmlwidgets   1.6.4   2023-12-06 [1] CRAN (R 4.4.3)\n httpuv        1.6.16  2025-04-16 [1] CRAN (R 4.4.3)\n jsonlite      2.0.0   2025-03-27 [1] CRAN (R 4.4.3)\n knitr         1.50    2025-03-16 [1] CRAN (R 4.4.3)\n later         1.4.2   2025-04-08 [1] CRAN (R 4.4.3)\n lifecycle     1.0.4   2023-11-07 [1] CRAN (R 4.4.3)\n magrittr      2.0.3   2022-03-30 [1] CRAN (R 4.4.3)\n memoise       2.0.1   2021-11-26 [1] CRAN (R 4.4.3)\n mime          0.13    2025-03-17 [1] CRAN (R 4.4.3)\n miniUI        0.1.2   2025-04-17 [1] CRAN (R 4.4.3)\n pkgbuild      1.4.7   2025-03-24 [1] CRAN (R 4.4.3)\n pkgload       1.4.0   2024-06-28 [1] CRAN (R 4.4.3)\n profvis       0.4.0   2024-09-20 [1] CRAN (R 4.4.3)\n promises      1.3.2   2024-11-28 [1] CRAN (R 4.4.3)\n purrr         1.0.4   2025-02-05 [1] CRAN (R 4.4.3)\n R6            2.6.1   2025-02-15 [1] CRAN (R 4.4.3)\n Rcpp          1.0.14  2025-01-12 [1] CRAN (R 4.4.3)\n remotes       2.5.0   2024-03-17 [1] CRAN (R 4.4.3)\n rlang         1.1.6   2025-04-11 [1] CRAN (R 4.4.3)\n rmarkdown     2.29    2024-11-04 [1] CRAN (R 4.4.3)\n rstudioapi    0.17.1  2024-10-22 [1] CRAN (R 4.4.3)\n sessioninfo   1.2.3   2025-02-05 [1] CRAN (R 4.4.3)\n shiny         1.10.0  2024-12-14 [1] CRAN (R 4.4.3)\n urlchecker    1.0.1   2021-11-30 [1] CRAN (R 4.4.3)\n usethis       3.1.0   2024-11-26 [1] CRAN (R 4.4.3)\n vctrs         0.6.5   2023-12-01 [1] CRAN (R 4.4.3)\n xfun          0.52    2025-04-02 [1] CRAN (R 4.4.3)\n xtable        1.8-4   2019-04-21 [1] CRAN (R 4.4.3)\n\n [1] C:/Users/FAUSAC/AppData/Local/R/win-library/4.4\n [2] C:/Program Files/R/R-4.4.3/library\n\n──────────────────────────────────────────────────────────────────────────────",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "C6.1.html",
    "href": "C6.1.html",
    "title": "13  Introducción a probabilidades",
    "section": "",
    "text": "13.1 Conceptos Fundamentales\nLa mayor parte de los problemas en estadística involucran elementos de incertidumbre, ya que usualmente no es posible determinar anticipadamente las características de una población desconocida o prever las consecuencias exactas de la toma de una decisión. Por lo tanto, es conveniente disponer de una medida que exprese esa incertidumbre en términos de una escala numérica. Esta medida es la probabilidad (López & González, 2018).\nEn el contexto agronómico, la probabilidad permite modelar y cuantificar la variabilidad inherente en los procesos biológicos, climáticos y productivos. Por ejemplo, se puede utilizar para evaluar la probabilidad de ocurrencia de plagas, el éxito de tratamientos fitosanitarios, o la variabilidad en rendimientos de cultivos.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introducción a probabilidades</span>"
    ]
  },
  {
    "objectID": "C6.1.html#conceptos-fundamentales",
    "href": "C6.1.html#conceptos-fundamentales",
    "title": "13  Introducción a probabilidades",
    "section": "",
    "text": "13.1.1 Experimento y Experimento Aleatorio\nUn experimento es el proceso mediante el cual se obtiene una observación o medida de un fenómeno. Cuando el resultado del experimento no puede preverse con certeza debido a la variabilidad inherente del fenómeno, se denomina experimento aleatorio (López & González, 2018).\nEjemplos de experimentos aleatorios:\n\nLanzamiento de un dado y observación del número mostrado en la cara superior\nLanzamiento de una moneda cuatro veces y observación del número de caras obtenido\nPrueba de duración de una lámpara, anotando el tiempo transcurrido desde que se enciende hasta que se quema\nCruzamiento de animales y observación del sexo del primero que nace\nConteo del número de larvas de gusano cogollero en plantas de maíz\nConteo del número de piezas defectuosas producidas en una línea de producción durante 24 horas\n\n\n\n13.1.2 Espacio Muestral\nEl espacio muestral es el conjunto de todos los posibles resultados de un experimento aleatorio. Se denota con el símbolo \\(\\Omega\\) (López & González, 2018).\nEjemplos de espacios muestrales:\n\nPara el lanzamiento de un dado: \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\)\nPara el lanzamiento de una moneda cuatro veces: \\(\\Omega = \\{0, 1, 2, 3, 4\\}\\)\nPara la duración de una lámpara: \\(\\Omega = \\{t | t \\geq 0\\}\\)\nPara el sexo de una cría: \\(\\Omega = \\{\\text{Macho, Hembra}\\}\\)\nPara el conteo de larvas: \\(\\Omega = \\{0, 1, 2, ...\\}\\)\n\n\n\n13.1.3 Evento\nUn evento A es un subconjunto del espacio muestral \\(\\Omega\\). En terminología de conjuntos, un evento es simplemente un conjunto de resultados posibles del experimento aleatorio. Los eventos se denotan con letras mayúsculas como A, B, C, etc. (López & González, 2018).\nEjemplos de eventos:\n\n\\(A_1\\)​: Sale un número par en el lanzamiento de un dado, \\(A_1 = \\{2, 4, 6\\}\\)\n\\(A_2\\)​: Ocurren dos caras en cuatro lanzamientos, \\(A_2 = \\{2\\}\\)\n\\(A_3\\)​: La lámpara se quema en menos de 3 horas, \\(A_3 = \\{t | 0 \\leq t &lt; 3\\}\\)",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introducción a probabilidades</span>"
    ]
  },
  {
    "objectID": "C6.1.html#métodos-para-asignar-probabilidades",
    "href": "C6.1.html#métodos-para-asignar-probabilidades",
    "title": "13  Introducción a probabilidades",
    "section": "13.2 Métodos para Asignar Probabilidades",
    "text": "13.2 Métodos para Asignar Probabilidades\nIndependientemente del método utilizado, se deben satisfacer dos requisitos básicos:\n\nLos valores de probabilidad asignados a cada resultado experimental deben estar entre 0 y 1: \\[\\LARGE 0 \\leq P(E_i) \\leq 1, \\text{ para toda } i\\]\nLa suma de todas las probabilidades de resultados experimentales debe ser 1: \\[\\LARGE \\sum_{i=1}^{k} P(E_i) = 1\\]\n\n\n13.2.1 Método Clásico\nSi un evento A puede ocurrir en \\(h\\) maneras diferentes de un número total de \\(n\\) maneras posibles, todas igualmente probables, entonces la probabilidad del evento es:\n\\[\\LARGE P(A) = \\frac{h}{n} = \\frac{\\text{número de resultados favorables}}{\\text{número de resultados posibles}}\\]\nEjemplo: En el lanzamiento de dos dados honestos, calcule las probabilidades de los siguientes eventos:\nA: La suma de los valores es igual a 7\nB: Los resultados en los dados son iguales\nC: La suma de los valores es 9 o más\nEl espacio muestral contiene 36 resultados posibles. Contando los casos favorables:\n\nPara A: \\({(1,6),(2,5),(3,4),(4,3),(5,2),(6,1)}\\), entonces \\(P(A) = \\frac{6}{36} = 0.167\\)\nPara B: \\({(1,1), (2,2), (3,3), (4,4), (5,5), (6,6)}\\), entonces \\(P(B) = \\frac{6}{36} = 0.167\\)\nPara C: 10 casos favorables, entonces \\(P(C) = \\frac{10}{36} = 0.278P\\)\n\n\n\n13.2.2 Método de la Frecuencia Relativa\nSi después de nnn repeticiones de un experimento donde nnn es “muy grande”, un evento ocurre hhh veces, entonces la probabilidad del evento es:\n\\[\\huge P(A) = \\frac{h}{n}\\]\nEjemplo: Si se lanza una moneda 1000 veces y resultan 532 caras, se puede estimar que: \\[\\Large P(\\text{cara}) = \\frac{532}{1000} = 0.532\\]\n\n\n13.2.3 Método Subjetivo\nEste método está basado en el juicio personal. Se puede usar cualquier dato disponible junto con la experiencia e intuición del investigador.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introducción a probabilidades</span>"
    ]
  },
  {
    "objectID": "C6.1.html#relaciones-básicas-de-probabilidad",
    "href": "C6.1.html#relaciones-básicas-de-probabilidad",
    "title": "13  Introducción a probabilidades",
    "section": "13.3 Relaciones Básicas de Probabilidad",
    "text": "13.3 Relaciones Básicas de Probabilidad\n\n13.3.1 Complemento de un Evento\nDado un evento A, el complemento de A se define como el evento formado por todos los puntos muestrales que no están en A, y se representa por \\(A^c\\).\n\\[\\LARGE P(A) + P(A^c) = 1\\]\nPor lo tanto: \\(P(A) = 1 - P(A^c)\\)\n\n\n13.3.2 Ley Aditiva\nLa ley aditiva es útil cuando se tienen dos eventos y se desea conocer la probabilidad de que ocurra por lo menos uno de ellos. Para eventos A y B:\n\\[\\Large P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\nEjemplo: El gerente de personal de una empresa agroforestal encontró que el 30% de los empleados que salieron lo hicieron por insatisfacción salarial, el 20% por insatisfacción laboral, y el 12% por ambas razones.\nSean:\n\nS: evento de salida por salario\nW: evento de salida por trabajo\n\n\\[\\large P(S \\cup W) = P(S) + P(W) - P(S \\cap W) = 0.30 + 0.20 - 0.12 = 0.38\\]\n\n\n13.3.3 Eventos Mutuamente Excluyentes\nDos eventos son mutuamente excluyentes si no tienen puntos muestrales en común, es decir, \\(P(A \\cap B) = 0\\).\nPara eventos mutuamente excluyentes:\n\\[\\LARGE P(A \\cup B) = P(A) + P(B)\\]",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introducción a probabilidades</span>"
    ]
  },
  {
    "objectID": "C6.1.html#probabilidad-condicional",
    "href": "C6.1.html#probabilidad-condicional",
    "title": "13  Introducción a probabilidades",
    "section": "13.4 Probabilidad Condicional",
    "text": "13.4 Probabilidad Condicional\nLa probabilidad condicional de un evento A dado que ha ocurrido B se denota como \\(P(A|B)\\) y se define como:\n\\[\\LARGE P(A|B) = \\frac{P(A \\cap B)}{P(B)}, \\text{ siempre que } P(B) &gt; 0\\]\nEsta notación se lee como “la probabilidad de A dado B” y representa la probabilidad de que ocurra A sabiendo que B ya ha ocurrido.\nEjemplo: En una facultad de agronomía se tiene la siguiente distribución de estudiantes:\n\n\n\nCarrera\nMasculino\nFemenino\nTotal\n\n\n\n\nAgronomía\n160\n40\n200\n\n\nForestal\n30\n10\n40\n\n\nAgroindustrial\n15\n10\n25\n\n\nTotal\n205\n60\n265\n\n\n\nDado que un alumno cursa Agronomía (A), ¿cuál es la probabilidad de que sea masculino (H)?\n\\[\\Large P(H|A) = \\frac{P(H \\cap A)}{P(A)} = \\frac{160/265}{200/265} = \\frac{160}{200} = 0.80\\]",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introducción a probabilidades</span>"
    ]
  },
  {
    "objectID": "C6.1.html#eventos-independientes",
    "href": "C6.1.html#eventos-independientes",
    "title": "13  Introducción a probabilidades",
    "section": "13.5 Eventos Independientes",
    "text": "13.5 Eventos Independientes\nDos eventos A y B son independientes si:\n\\[\\Large P(A|B) = P(A) \\text{ o } P(B|A) = P(B)\\]\nDe lo contrario, los eventos son dependientes.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introducción a probabilidades</span>"
    ]
  },
  {
    "objectID": "C6.1.html#ley-multiplicativa",
    "href": "C6.1.html#ley-multiplicativa",
    "title": "13  Introducción a probabilidades",
    "section": "13.6 Ley Multiplicativa",
    "text": "13.6 Ley Multiplicativa\nMientras que la ley aditiva se utiliza para determinar la probabilidad de una unión entre dos eventos, la ley multiplicativa se usa para determinar la probabilidad de una intersección de dos eventos:\n\\[\\LARGE P(A \\cap B) = P(B) \\cdot P(A|B)\\]\no también:\n\\[\\LARGE P(A \\cap B) = P(A) \\cdot P(B|A)\\]\n\n13.6.1 Ley Multiplicativa para Eventos Independientes\nPara eventos independientes:\n\\[\\LARGE P(A \\cap B) = P(A) \\cdot P(B)\\]\nEjemplo: El gerente de una gasolinera sabe que el 80% de los clientes usan tarjeta de crédito. ¿Cuál es la probabilidad de que dos clientes consecutivos usen tarjeta de crédito?\n\\[\\LARGE P(A \\cap B) = P(A) \\cdot P(B) = 0.8 \\times 0.8 = 0.64\\]",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introducción a probabilidades</span>"
    ]
  },
  {
    "objectID": "C6.1.html#diagramas-de-árbol",
    "href": "C6.1.html#diagramas-de-árbol",
    "title": "13  Introducción a probabilidades",
    "section": "13.7 Diagramas de Árbol",
    "text": "13.7 Diagramas de Árbol\nUn diagrama de árbol es una herramienta gráfica que se emplea frecuentemente en conexión con el principio multiplicativo. Debido a su apariencia, permite visualizar todos los posibles resultados de un experimento compuesto y facilita el cálculo de probabilidades.\nEjemplo: Si un hombre tiene 2 camisas (\\(S_1, S_2\\)) y 4 corbatas (\\(T_1, T_2, T_3, T_4\\)), entonces tiene \\(2 \\times 4 = 8\\) maneras de escoger una camisa y luego una corbata.\nEl diagrama de árbol correspondiente sería:\n\n\n\n\n\n\n13.7.1 Uso de Diagramas de Árbol en Probabilidad Condicional\nLos diagramas de árbol son especialmente útiles para problemas de probabilidad condicional, donde las probabilidades en las ramas posteriores dependen de los resultados de las ramas anteriores.\nEjemplo aplicado: Una empresa agrícola tiene tres proveedores de semillas. El proveedor A suministra el 40% de las semillas, el proveedor B el 35%, y el proveedor C el 25%. Las tasas de germinación son del 95%, 90%, y 85% respectivamente.\nEl diagrama de árbol sería:",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introducción a probabilidades</span>"
    ]
  },
  {
    "objectID": "C6.1.html#teorema-de-bayes",
    "href": "C6.1.html#teorema-de-bayes",
    "title": "13  Introducción a probabilidades",
    "section": "13.8 Teorema de Bayes",
    "text": "13.8 Teorema de Bayes\nEl teorema de Bayes también se conoce como “probabilidad de las causas”, es decir, la probabilidad de un hecho anterior sabiendo la probabilidad de un hecho posterior. Se basa en que los eventos definidos sobre un espacio muestral son particiones del mismo.\nSi \\(A_1, A_2, A_3, ..., A_n\\)​ son eventos mutuamente excluyentes y exhaustivos, y \\(B\\) es un evento observado, entonces:\n\\[\\LARGE P(A_i|B) = \\frac{P(A_i) \\cdot P(B|A_i)}{\\sum_{j=1}^{n} P(A_j) \\cdot P(B|A_j)}\\]\ndonde:\n\n\\(P(A_i)\\) son las probabilidades a priori\n\\(P(B|A_i)\\) son las probabilidades condicionales\n\\(P(A_i|B)\\) son las probabilidades a posteriori\n\nEjemplo resuelto: Una fábrica con 3 sucursales produce 40%, 35% y 25% del total de la producción. Tienen porcentajes de artículos defectuosos de 4%, 6% y 8%, respectivamente. Si se elige aleatoriamente un artículo:\na) ¿Cuál es la probabilidad de que no sea defectuoso?\nUsando la ley de probabilidad total:\n\\[\\large P(C) = P(A_1) \\cdot P(C|A_1) + P(A_2) \\cdot P(C|A_2) + P(A_3) \\cdot P(C|A_3)\\]\n\\[\\large P(C) = 0.40 \\times 0.96 + 0.35 \\times 0.94 + 0.25 \\times 0.92 = 0.943\\]\nb) Si resultó defectuoso, ¿cuál es la probabilidad de que proceda de la primera sucursal?\nPrimero calculamos \\[\\Large P(B) = 1 - P(C) = 1 - 0.943 = 0.057\\]\nLuego aplicamos Bayes:\n\\[\\Large P(A_1|B) = \\frac{P(A_1) \\cdot P(B|A_1)}{P(B)} = \\frac{0.40 \\times 0.04}{0.057} = 0.2807\\]\n\n13.8.1 Tabla de Análisis para el Teorema de Bayes\n\n\n\n\n\n\n\n\n\n\nEventos\nProbabilidades previas\nProbabilidades condicionales\nProbabilidades conjuntas\nProbabilidades posteriores\n\n\n\n\n\\(A_i\\)​\n\\(P(A_i)\\)\n\\(P(C)\\)\n\\(P(A_i) \\cdot P(C|A_i)\\)\n\\(P(A_i|  B)\\)\n\n\n\\(A_1\\)​\n0.40\n0.04\n0.016\n0.2807\n\n\n\\(A_2\\)​\n0.35\n0.06\n0.021\n0.3684\n\n\n\\(A_3\\)​\n0.25\n0.08\n0.020\n0.3509\n\n\nTotal\n1.00\n\nP(B) = 0.057\n1.0000",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introducción a probabilidades</span>"
    ]
  },
  {
    "objectID": "C6.1.html#notación-correcta-para-probabilidades",
    "href": "C6.1.html#notación-correcta-para-probabilidades",
    "title": "13  Introducción a probabilidades",
    "section": "13.9 Notación Correcta para Probabilidades",
    "text": "13.9 Notación Correcta para Probabilidades\nEs fundamental utilizar la notación correcta para evitar confusiones:\n\n\\(P(A)\\): Probabilidad marginal del evento A\n\\(P(A \\cap B)\\): Probabilidad conjunta de A y B (intersección)\n\\(P(A \\cup B)\\): Probabilidad de la unión de A y B\n\\(P(A|B)\\): Probabilidad condicional de A dado B\n\\(P(A^c)\\): Probabilidad del complemento de A\n\\(A \\perp B\\): A y B son independientes",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introducción a probabilidades</span>"
    ]
  },
  {
    "objectID": "C7.1.html",
    "href": "C7.1.html",
    "title": "14  Distribuciones Binomial y Poisson en R",
    "section": "",
    "text": "14.1 Introducción\nEl estudio de las distribuciones de probabilidad constituye uno de los pilares fundamentales de la estadística aplicada. En el contexto de las ciencias agronómicas, estas herramientas matemáticas permiten modelar y analizar fenómenos aleatorios que ocurren frecuentemente en la investigación y práctica agrícola. Las distribuciones binomial y de Poisson, como distribuciones discretas, son especialmente útiles para describir eventos de conteo, tales como el número de semillas germinadas, la cantidad de plagas observadas en una parcela, o la ocurrencia de eventos climáticos adversos.\nSegún López y González (2018), las variables aleatorias discretas son aquellas que pueden tomar un conjunto finito o numerable de valores, generalmente asociados a conteos de eventos. El software estadístico R proporciona funciones específicas para el cálculo de probabilidades en estas distribuciones, facilitando el análisis estadístico y la toma de decisiones basada en evidencia.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuciones Binomial y Poisson en R</span>"
    ]
  },
  {
    "objectID": "C7.1.html#distribución-binomial",
    "href": "C7.1.html#distribución-binomial",
    "title": "14  Distribuciones Binomial y Poisson en R",
    "section": "14.2 Distribución Binomial",
    "text": "14.2 Distribución Binomial\n\n14.2.1 Características y definición\nLa distribución binomial describe el número de éxitos obtenidos en una secuencia de ensayos independientes, donde cada ensayo presenta únicamente dos posibles resultados: éxito o fracaso. López y González (2018) establecen que un experimento binomial posee las siguientes características fundamentales:\n\nConsta de \\(n\\) ensayos o pruebas idénticas (ensayos de Bernoulli)\nCada prueba puede tener uno de dos resultados posibles (éxito o fracaso)\nLa probabilidad de un éxito en una sola prueba es igual a \\(p\\), y permanece constante de una prueba a otra. La probabilidad de fracaso es igual a \\((1-p)\\) y se denota con la letra \\(q\\)\nEl resultado obtenido en cada prueba es independiente de los resultados obtenidos anteriormente\n\nLa distribución binomial se representa como \\(B(n,p)\\), siendo \\(n\\) y \\(p\\) los parámetros de dicha distribución.\n\n\n14.2.2 Función de probabilidad\nLa función de probabilidad de la distribución binomial se expresa matemáticamente como:\n\\[\\LARGE P(X = x) = \\binom{n}{x} p^x q^{n-x}, \\quad x = 0,1,2,\\ldots,n\\]\ndonde:\n\n\\(X\\) es la variable aleatoria que representa el número de éxitos\n\\(x\\) es el número de éxitos observados\n\\(n\\) es el número total de ensayos\n\\(p\\) es la probabilidad de éxito en cada ensayo\n\\(q = 1-p\\) es la probabilidad de fracaso\n\\(\\binom{n}{x} = \\frac{n!}{x!(n-x)!}\\) es el coeficiente binomial\n\n\n\n14.2.3 Parámetros de la distribución binomial\nLos parámetros de tendencia central y dispersión de la distribución binomial son:\n\nMedia: \\(E(X) = np\\)\nVarianza: \\(V(X) = npq\\)",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuciones Binomial y Poisson en R</span>"
    ]
  },
  {
    "objectID": "C7.1.html#cálculo-de-probabilidades-binomiales-en-r",
    "href": "C7.1.html#cálculo-de-probabilidades-binomiales-en-r",
    "title": "14  Distribuciones Binomial y Poisson en R",
    "section": "14.3 Cálculo de probabilidades binomiales en R",
    "text": "14.3 Cálculo de probabilidades binomiales en R\nEl software R proporciona funciones específicas para el cálculo de probabilidades binomiales. A continuación se describen las funciones principales y sus argumentos.\n\n14.3.1 Función para calcular P(X = x)\nPara calcular la probabilidad de obtener exactamente xxx éxitos, se utiliza la función:\n\\[\\LARGE \\texttt{dbinom(x, size, prob)} \\]\nArgumentos en orden:\n\n\\(\\texttt{x}\\): número de éxitos deseados (valor específico de la variable aleatoria)\n\\(\\texttt{size}\\): número total de ensayos (\\(n\\))\n\\(\\texttt{prob}\\): probabilidad de éxito en cada ensayo (\\(p\\))\n\n\n\n14.3.2 Función para calcular P(X ≤ x) y P(X &gt; x)\nPara calcular probabilidades acumuladas, se utiliza la función:\n\\[\\LARGE \\texttt{pbinom(q, size, prob, lower.tail)}\\]\nArgumentos en orden:\n\n\\(\\texttt{q}\\): valor hasta el cual se desea calcular la probabilidad acumulada\n\\(\\texttt{size}\\): número total de ensayos (nnn)\n\\(\\texttt{prob}\\): probabilidad de éxito en cada ensayo (ppp)\n\\(\\texttt{lower.tail}\\): argumento lógico que indica si se calcula \\(P(X \\leq x) (\\texttt{TRUE}, por defecto)\\) o \\(P(X &gt; x) (\\texttt{FALSE})\\)\n\n\n\n14.3.3 Ejemplo práctico: Germinación de semillas\nSupóngase que se siembran 20 semillas de maíz y se sabe que la probabilidad de germinación de cada semilla es de 0.8. Se desea calcular las siguientes probabilidades:\n\n14.3.3.1 Caso 1: P(X = 16) - Probabilidad de que germinen exactamente 16 semillas\n\ndbinom(16, 20, 0.8)\n\n[1] 0.2181994\n\n\n\n\n14.3.3.2 Caso 2: P(X ≤ 15) - Probabilidad de que germinen 15 o menos semillas\n\npbinom(15, 20, 0.8)\n\n[1] 0.3703517\n\n\n\n\n14.3.3.3 Caso 3: P(X &gt; 18) - Probabilidad de que germinen más de 18 semillas\n\npbinom(18, 20, 0.8, lower.tail = FALSE)\n\n[1] 0.06917529",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuciones Binomial y Poisson en R</span>"
    ]
  },
  {
    "objectID": "C7.1.html#distribución-de-poisson",
    "href": "C7.1.html#distribución-de-poisson",
    "title": "14  Distribuciones Binomial y Poisson en R",
    "section": "14.4 Distribución de Poisson",
    "text": "14.4 Distribución de Poisson\n\n14.4.1 Características y definición\nLa distribución de Poisson, desarrollada por Simeón Dennis Poisson (1781-1840), es un modelo apropiado para describir el número de eventos raros que ocurren en un intervalo de tiempo o espacio específico. López y González (2018) indican que esta distribución es útil para modelar eventos con las siguientes características:\n\nLos eventos ocurren de manera independiente\nLa tasa promedio de ocurrencia permanece constante\nLos eventos son raros o poco frecuentes\n\n\n\n14.4.2 Función de probabilidad\nUna variable aleatoria \\(X\\) tiene distribución de Poisson con parámetro \\(\\lambda &gt; 0\\), si su función de probabilidad está dada por:\n\\[\\Large P(X = x) = \\frac{e^{-\\lambda} \\lambda^x}{x!}, \\quad x = 0,1,2,\\ldots  \\]\ndonde:\n\n\\(\\lambda\\) representa el número medio de ocurrencias por intervalo de tiempo\n\\(e = 2.71828\\) es la base de los logaritmos naturales\n\nLa notación utilizada es: \\(X \\sim Po(\\lambda)\\)\n\n\n14.4.3 Parámetros de la distribución de Poisson\nLos parámetros de la distribución de Poisson son:\n\nMedia:\\(E(X) = \\lambda\\)\nVarianza: \\(V(X) = \\lambda\\)",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuciones Binomial y Poisson en R</span>"
    ]
  },
  {
    "objectID": "C7.1.html#cálculo-de-probabilidades-de-poisson-en-r",
    "href": "C7.1.html#cálculo-de-probabilidades-de-poisson-en-r",
    "title": "14  Distribuciones Binomial y Poisson en R",
    "section": "14.5 Cálculo de probabilidades de Poisson en R",
    "text": "14.5 Cálculo de probabilidades de Poisson en R\n\n14.5.1 Función para calcular P(X = x)\nPara calcular la probabilidad de observar exactamente \\(x\\) eventos, se utiliza:\n\\[\\LARGE \\texttt{dpois(x, lambda)}\\]\nArgumentos en orden:\n\n\\(\\texttt{x}\\): número de eventos observados\n\\(\\texttt{lambda}\\): tasa promedio de ocurrencia (\\(\\lambda\\))\n\n\n\n14.5.2 Función para calcular P(X ≤ x) y P(X &gt; x)\nPara probabilidades acumuladas, se utiliza:\n\\[\\LARGE \\texttt{ppois(q, lambda, lower.tail)}  \\]\nArgumentos en orden:\n\n\\(\\texttt{q}\\): valor hasta el cual se desea calcular la probabilidad acumulada\n\\(\\texttt{lambda}\\): tasa promedio de ocurrencia (λ)\n\\(\\texttt{lower.tail}\\): argumento lógico para \\(P(X \\leq x)\\) (\\(\\texttt{TRUE}\\)) o \\(P(X &gt; x)\\) (\\(\\texttt{FALSE}\\))\n\n\n\n14.5.3 Ejemplo práctico: Incidencia de plagas\nSupóngase que en un cultivo de tomate se observa un promedio de 3 plagas por metro cuadrado. Se desea calcular las siguientes probabilidades:\n\n14.5.3.1 Caso 1: P(X = 5) - Probabilidad de observar exactamente 5 plagas\n\ndpois(5, 3)\n\n[1] 0.1008188\n\n\n\n\n14.5.3.2 Caso 2: P(X ≤ 2) - Probabilidad de observar 2 o menos plagas\n\nppois(2, 3)\n\n[1] 0.4231901\n\n\n\n\n14.5.3.3 Caso 3: P(X &gt; 4) - Probabilidad de observar más de 4 plagas\n\nppois(4, 3, lower.tail = FALSE)\n\n[1] 0.1847368",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuciones Binomial y Poisson en R</span>"
    ]
  },
  {
    "objectID": "C7.1.html#interpretación-y-aplicaciones-en-agronomía",
    "href": "C7.1.html#interpretación-y-aplicaciones-en-agronomía",
    "title": "14  Distribuciones Binomial y Poisson en R",
    "section": "14.6 Interpretación y aplicaciones en agronomía",
    "text": "14.6 Interpretación y aplicaciones en agronomía\nLas distribuciones binomial y de Poisson encuentran numerosas aplicaciones en el campo agronómico. La distribución binomial es particularmente útil para modelar situaciones donde se evalúa el éxito o fracaso de un proceso, como la germinación de semillas, la supervivencia de plantas trasplantadas, o la efectividad de tratamientos fitosanitarios.\nPor su parte, la distribución de Poisson es apropiada para modelar la ocurrencia de eventos raros, tales como la aparición de plagas específicas, la incidencia de enfermedades en cultivos, o la ocurrencia de eventos climáticos extremos.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribuciones Binomial y Poisson en R</span>"
    ]
  },
  {
    "objectID": "C8.1.html",
    "href": "C8.1.html",
    "title": "15  Distribución normal",
    "section": "",
    "text": "15.1 Introducción\nLa distribución normal, también conocida como distribución gaussiana o campana de Gauss, es una de las distribuciones de probabilidad continua más importantes en estadística. Su relevancia radica en que muchos fenómenos naturales y sociales tienden a seguir esta distribución, y además, sirve como base para numerosas pruebas y modelos estadísticos.\nSegún López y González (2018), la distribución normal es fundamental en bioestadística debido a que muchas variables biométricas tienden a distribuirse normalmente, la distribución de las medias muestrales de una variable cualquiera tiende a ser normal (Teorema del Límite Central), y muchas pruebas estadísticas asumen la normalidad de los datos.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribución normal</span>"
    ]
  },
  {
    "objectID": "C8.1.html#características-y-definición",
    "href": "C8.1.html#características-y-definición",
    "title": "15  Distribución normal",
    "section": "15.2 Características y definición",
    "text": "15.2 Características y definición\nLa distribución normal se caracteriza por ser simétrica y tener forma de campana. Está completamente definida por dos parámetros: la media (\\(\\mu\\)) y la desviación estándar (\\(\\sigma\\)). La función de densidad de probabilidad de la distribución normal se expresa como:\n\\[\\Large f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{1}{2} \\left(\\frac{x - \\mu}{\\sigma}\\right)^2}, \\quad -\\infty &lt; x &lt; \\infty  \\]\ndonde:\n\n\\(x\\) es la variable aleatoria continua\n\\(\\mu\\) es la media de la distribución\n\\(\\sigma\\) es la desviación estándar de la distribución\n\\(e\\) es la base del logaritmo natural (aproximadamente 2.71828)\n\\(\\pi\\) es la constante pi (aproximadamente 3.14159)\n\nLa notación utilizada es: \\(X \\sim N(\\mu, \\sigma^2)\\), donde \\(\\mu\\) es la media y \\(\\sigma^2\\) es la varianza.\n\n15.2.1 Propiedades de la distribución normal\nLópez y González (2018) destacan las siguientes propiedades de la distribución normal:\n\nExiste una familia de distribuciones normales, cada una definida por su media (\\(\\mu\\)) y desviación estándar (\\(\\sigma\\)).\nEl punto más alto de la curva normal es la media, que coincide con la mediana y la moda.\nLa distribución es simétrica alrededor de la media.\nLos extremos de la distribución se extienden indefinidamente sin tocar el eje horizontal.\nLa desviación estándar (\\(\\sigma\\)) determina el ancho de la curva; valores mayores indican mayor dispersión.\nEl área total bajo la curva es igual a 1.\nLas probabilidades se determinan mediante áreas bajo la curva.\nLa regla empírica establece que aproximadamente el 68% de las observaciones se encuentran dentro de una desviación estándar de la media (\\(\\mu \\pm \\sigma\\)), el 95% dentro de dos desviaciones estándar (\\(\\mu \\pm 2\\sigma\\)), y el 99.7% dentro de tres desviaciones estándar (\\(\\mu \\pm 3\\sigma\\)).",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribución normal</span>"
    ]
  },
  {
    "objectID": "C8.1.html#cálculo-de-probabilidades-normales-en-r",
    "href": "C8.1.html#cálculo-de-probabilidades-normales-en-r",
    "title": "15  Distribución normal",
    "section": "15.3 Cálculo de probabilidades normales en R",
    "text": "15.3 Cálculo de probabilidades normales en R\nEl software R proporciona funciones para calcular probabilidades asociadas a la distribución normal.\n\n15.3.1 Función para calcular la función de densidad de probabilidad\nPara calcular la función de densidad de probabilidad en un punto \\(x\\), se utiliza la función:\n\\[\\LARGE \\texttt{dnorm(x, mean, sd)}  \\]\nArgumentos en orden:\n\n\\(\\texttt{x}\\): valor de la variable aleatoria en el que se evalúa la función de densidad\n\\(\\texttt{mean}\\): media de la distribución (\\(\\mu\\))\n\\(\\texttt{sd}\\): desviación estándar de la distribución (\\(\\sigma\\))\n\n\n\n15.3.2 Función para calcular probabilidades acumuladas\nPara calcular la probabilidad acumulada \\(P(X \\leq x)\\), se utiliza la función:\n\\[\\LARGE \\texttt{pnorm(q, mean, sd, lower.tail)}  \\]\nArgumentos en orden:\n\n\\(\\texttt{q}\\): valor hasta el cual se desea calcular la probabilidad acumulada\n\\(\\texttt{mean}\\): media de la distribución (\\(\\mu\\))\n\\(\\texttt{sd}\\): desviación estándar de la distribución (\\(\\sigma\\))\n\\(\\texttt{lower.tail}\\): argumento lógico que indica si se calcula \\(P(X \\leq x)\\) (\\(\\texttt{TRUE}, por defecto\\)) o \\(P(X &gt; x)\\) (\\(\\texttt{FALSE}\\))\n\n\n\n15.3.3 Ejemplo práctico: Estatura de estudiantes\nSupóngase que la estatura de los estudiantes de una universidad se distribuye normalmente con una media de 170 cm y una desviación estándar de 10 cm. Se desea calcular las siguientes probabilidades:\n\n15.3.3.1 Caso 1: P(X ≤ 180) - Probabilidad de que un estudiante mida 180 cm o menos\n\npnorm(180, 170, 10)\n\n[1] 0.8413447\n\n\n\n\n15.3.3.2 Caso 2: P(X &gt; 160) - Probabilidad de que un estudiante mida más de 160 cm\n\npnorm(160, 170, 10, lower.tail = FALSE)\n\n[1] 0.8413447\n\n\n\n\n15.3.3.3 Caso 3: P(165 ≤ X ≤ 175) - Probabilidad de que un estudiante mida entre 165 cm y 175 cm\nPara calcular esta probabilidad, se resta la probabilidad acumulada hasta 165 cm de la probabilidad acumulada hasta 175 cm:\n\npnorm(175, 170, 10) - pnorm(165, 170, 10)\n\n[1] 0.3829249",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribución normal</span>"
    ]
  },
  {
    "objectID": "C8.1.html#interpretación-y-aplicaciones-en-agronomía",
    "href": "C8.1.html#interpretación-y-aplicaciones-en-agronomía",
    "title": "15  Distribución normal",
    "section": "15.5 Interpretación y aplicaciones en agronomía",
    "text": "15.5 Interpretación y aplicaciones en agronomía\nLa distribución normal es ampliamente utilizada en agronomía para modelar variables continuas como la altura de las plantas, el rendimiento de los cultivos, el peso de los frutos, y las temperaturas. Permite realizar inferencias estadísticas, como la estimación de intervalos de confianza y la realización de pruebas de hipótesis, que son fundamentales para la investigación y la toma de decisiones en el sector agropecuario.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribución normal</span>"
    ]
  },
  {
    "objectID": "C8.1.html#estandarización-de-la-variable-normal",
    "href": "C8.1.html#estandarización-de-la-variable-normal",
    "title": "15  Distribución normal",
    "section": "15.4 Estandarización de la variable normal",
    "text": "15.4 Estandarización de la variable normal\n\n15.4.1 Ejemplo práctico: Duración de la temporada de heladas en Guatemala\nEl Instituto Nacional de Sismología, Vulcanología, Meteorología e Hidrología (INSIVUMEH) de Guatemala ha determinado que la duración de la temporada de heladas sigue una distribución normal. Se conoce la siguiente información:\n\nLa duración promedio de la temporada de heladas es de 120 días (\\(\\mu = 120\\))\nLa probabilidad de que la temporada dure más de 133 días es del 25.78% (\\(P(X &gt; 133) = 0.2578\\))\n\nObjetivo: Determinar la desviación estándar (\\(\\sigma\\)) de la distribución normal.\n\n15.4.1.1 Paso 1: Estandarización de la variable\nPara resolver este problema, se debe estandarizar la variable \\(X\\) (duración de la temporada de heladas) utilizando la transformación a \\(Z\\):\n\\[\\huge Z = \\frac{X - \\mu}{\\sigma} \\]\ndonde:\n\n\\(X = 133\\) días\n\\(\\mu = 120\\) días\n\\(\\sigma\\) = desviación estándar (valor a determinar)\n\nSustituyendo los valores conocidos:\n\\[\\LARGE Z = \\frac{133 - 120}{\\sigma} = \\frac{13}{\\sigma} \\]\n\n\n15.4.1.2 Paso 2: Cálculo de la probabilidad acumulada\nDado que P(X &gt; 133) = 0.2578, se puede determinar la probabilidad acumulada hasta 133:\n\\[\\Large P(X \\leq 133) = 1 - P(X &gt; 133) = 1 - 0.2578 = 0.7422 \\]\nPor lo tanto:\n\\[\\Large P\\left(Z \\leq \\frac{13}{\\sigma}\\right) = 0.7422 )=0.7422\\]\n\n\n15.4.1.3 Paso 3: Encontrar el valor Z correspondiente\nSe debe encontrar el valor \\(z\\) tal que P(\\(Z \\leq z\\)) = 0.7422 en la distribución normal estándar.\nEn R, se utiliza la función:\n\\[\\huge \\texttt{qnorm(p, mean, sd)} \\]\nArgumentos:\n\n\\(\\texttt{p}\\): probabilidad acumulada deseada\n\\(\\texttt{mean}\\): media de la distribución (0 para la normal estándar)\n\\(\\texttt{sd}\\): desviación estándar de la distribución (1 para la normal estándar)\n\n\nqnorm(0.7422, mean = 0, sd = 1)\n\n[1] 0.6501428\n\n\n\n\n15.4.1.4 Paso 4: Despejar la desviación estándar\nIgualando la expresión estandarizada con el valor \\(z\\) encontrado:\n\\[\\huge \\frac{13}{\\sigma} = 0.65  \\]\nDespejando:\n\\[\\huge \\sigma = \\frac{13}{0.65} = 20 \\]\n\n\n15.4.1.5 Verificación en R\nPara verificar el resultado, se puede calcular la probabilidad \\(P(X &gt; 133)\\) con los parámetros encontrados:\n\npnorm(133, mean = 120, sd = 20, lower.tail = FALSE)\n\n[1] 0.2578461\n\n\nEste resultado confirma que la desviación estándar calculada es correcta.\n\n\n15.4.1.6 Interpretación\nLa desviación estándar de la duración de la temporada de heladas en Guatemala es de 20 días (\\(\\sigma = 20\\)). Esto significa que la duración de la temporada de heladas varía alrededor de la media (120 días) con una dispersión de 20 días.\nCon esta información, se puede establecer que la duración de la temporada de heladas en Guatemala sigue una distribución \\(N(120, 20^2)\\), lo que permite realizar predicciones y análisis probabilísticos para la planificación agrícola y la gestión de riesgos climáticos.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Distribución normal</span>"
    ]
  },
  {
    "objectID": "C9.1.html",
    "href": "C9.1.html",
    "title": "16  Estimación puntual e intervalos de confianza en R",
    "section": "",
    "text": "16.1 Introducción\nLa estimación de parámetros poblacionales a partir de muestras es una de las tareas fundamentales en la estadística aplicada, especialmente en la investigación agronómica. En la toma de decisiones sobre producción, selección de variedades o evaluación de innovaciones tecnológicas, es común que el investigador disponga únicamente de datos muestrales. Por ello, resulta esencial contar con herramientas que permitan inferir, con un nivel de confianza conocido, los valores verdaderos de la población a partir de la información obtenida en el laboratorio o en campo (López & González, 2018).\nEl uso de intervalos de confianza permite cuantificar la incertidumbre inherente a la estimación de parámetros, como la media o la varianza, y facilita la comunicación de resultados de manera rigurosa y transparente. El software R proporciona funciones específicas para calcular estimaciones puntuales e intervalos de confianza, lo que agiliza el análisis estadístico y la interpretación de los datos en contextos agronómicos.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Estimación puntual e intervalos de confianza en R</span>"
    ]
  },
  {
    "objectID": "C9.1.html#fundamentos-teóricos",
    "href": "C9.1.html#fundamentos-teóricos",
    "title": "16  Estimación puntual e intervalos de confianza en R",
    "section": "16.2 Fundamentos teóricos",
    "text": "16.2 Fundamentos teóricos\n\n16.2.1 Estimación puntual\nLa estimación puntual consiste en asignar un único valor numérico, calculado a partir de los datos muestrales, como mejor aproximación del parámetro poblacional de interés. Por ejemplo, la media muestral (\\(\\bar{x}\\)) se utiliza como estimador puntual de la media poblacional (\\(\\mu\\)).\n\n\n16.2.2 Intervalo de confianza\nUn intervalo de confianza es un rango de valores, calculado a partir de los datos muestrales, que con una determinada probabilidad (nivel de confianza) contiene al verdadero valor del parámetro poblacional. Matemáticamente, para la media poblacional, el intervalo de confianza se expresa como:\n\\[\\huge \\bar{x} \\pm z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\\]\n\n\\(\\bar{x}\\) es la media muestral,\n\\(z_{\\alpha/2}\\) es el valor crítico de la distribución normal estándar para el nivel de confianza deseado,\n\\(\\sigma\\) es la desviación estándar poblacional (o muestral, si \\(\\sigma\\) es desconocida),\n\\(n\\) es el tamaño de la muestra.\n\nCuando la desviación estándar poblacional es desconocida y el tamaño de la muestra es pequeño (n &lt; 30), se utiliza la distribución t de Student en lugar de la normal estándar.\n\n\n16.2.3 Nivel de confianza y significancia\nEl nivel de confianza (\\(1 - \\alpha\\)) representa la probabilidad de que el intervalo calculado contenga al verdadero parámetro poblacional. Comúnmente, se utilizan niveles de confianza del 90%, 95% o 99%. El valor \\(\\alpha\\) representa la significancia, es decir, la probabilidad de que el intervalo no contenga al parámetro poblacional.\nFactores que afectan la amplitud del intervalo\nLa amplitud del intervalo de confianza está influenciada por varios factores:\n\nTamaño de la muestra (\\(n\\)): A mayor tamaño de la muestra, menor es la amplitud del intervalo.\nDesviación estándar (\\(\\sigma\\)) : A mayor variabilidad en los datos, mayor es la amplitud del intervalo.\nNivel de confianza (\\(1 - \\alpha\\)): A mayor nivel de confianza, mayor es la amplitud del intervalo.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Estimación puntual e intervalos de confianza en R</span>"
    ]
  },
  {
    "objectID": "C9.1.html#intervalos-de-confianza-para-la-media-con-desviación-estándar-conocida",
    "href": "C9.1.html#intervalos-de-confianza-para-la-media-con-desviación-estándar-conocida",
    "title": "Estimación puntual e intervalos de confianza en R",
    "section": "Intervalos de confianza para la media con desviación estándar conocida",
    "text": "Intervalos de confianza para la media con desviación estándar conocida\nCuando la desviación estándar de la población () es conocida, el intervalo de confianza para la media poblacional () se calcula utilizando la distribución normal estándar (z):\n\\[\\huge \\bar{x} \\pm z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\\]",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Estimación puntual e intervalos de confianza en R</span>"
    ]
  },
  {
    "objectID": "C9.1.html#intervalos-de-confianza-para-la-media-con-desviación-estándar-desconocida",
    "href": "C9.1.html#intervalos-de-confianza-para-la-media-con-desviación-estándar-desconocida",
    "title": "Estimación puntual e intervalos de confianza en R",
    "section": "Intervalos de confianza para la media con desviación estándar desconocida",
    "text": "Intervalos de confianza para la media con desviación estándar desconocida\nCuando la desviación estándar de la población (\\(\\sigma\\)) es desconocida, se utiliza la desviación estándar muestral (\\(s\\)) como estimación, y el intervalo de confianza se calcula utilizando la distribución t de Student:\n\\[\\huge \\bar{x} \\pm t\\_{\\alpha/2, n-1} \\cdot \\frac{s}{\\sqrt{n}} \\]\ndonde \\(t_{\\alpha/2, n-1}\\) es el valor crítico de la distribución t de Student con n−1n-1n−1 grados de libertad.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Estimación puntual e intervalos de confianza en R</span>"
    ]
  },
  {
    "objectID": "C9.1.html#intervalos-de-confianza-para-la-varianza",
    "href": "C9.1.html#intervalos-de-confianza-para-la-varianza",
    "title": "Estimación puntual e intervalos de confianza en R",
    "section": "Intervalos de confianza para la varianza",
    "text": "Intervalos de confianza para la varianza\nEl intervalo de confianza para la varianza poblacional (\\(\\sigma^2\\)) se calcula utilizando la distribución chi-cuadrado (\\(\\chi^2\\)):\n\\[\\LARGE \\frac{(n-1)s^2}{\\chi^2_{\\alpha/2, n-1}} \\leq \\sigma^2 \\leq \\frac{(n-1)s^2}{\\chi^2_{1-\\alpha/2, n-1}} \\]\ndonde:\n\n\\(s^2\\) es la varianza muestral,\n\\(\\chi^2_{\\alpha/2, n-1}\\) y \\(\\chi^2_{1-\\alpha/2, n-1}\\) son los valores críticos de la distribución chi-cuadrado con \\(n-1\\) grados de libertad.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Estimación puntual e intervalos de confianza en R</span>"
    ]
  },
  {
    "objectID": "C9.1.html#intervalos-de-confianza-para-la-proporción",
    "href": "C9.1.html#intervalos-de-confianza-para-la-proporción",
    "title": "Estimación puntual e intervalos de confianza en R",
    "section": "Intervalos de confianza para la proporción",
    "text": "Intervalos de confianza para la proporción\nEl intervalo de confianza para la proporción poblacional (p) se calcula como:\n\\[\\LARGE \\hat{p} \\pm z_{\\alpha/2} \\cdot \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\]​\ndonde:\n\n\\(\\hat{p}\\) es la proporción muestral,\n\\(z_{\\alpha/2}\\) es el valor crítico de la distribución normal estándar.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Estimación puntual e intervalos de confianza en R</span>"
    ]
  },
  {
    "objectID": "C9.1.html#ejemplos-de-cálculo-de-intervalos-de-confianza-en-r",
    "href": "C9.1.html#ejemplos-de-cálculo-de-intervalos-de-confianza-en-r",
    "title": "16  Estimación puntual e intervalos de confianza en R",
    "section": "16.4 Ejemplos de cálculo de intervalos de confianza en R",
    "text": "16.4 Ejemplos de cálculo de intervalos de confianza en R\n\n16.4.1 Ejemplo 1: Intervalo de confianza para la media con desviación estándar conocida\nContexto agronómico: Una empresa productora de semillas de maíz conoce que la desviación estándar del peso de las semillas es de 0.15 gramos. Se toma una muestra aleatoria de 25 semillas y se obtiene un peso promedio de 0.85 gramos. Se desea construir un intervalo de confianza del 95% para el peso promedio poblacional.\nCálculo manual:\n\\[\n\\begin{aligned}\nn &= 25 \\\\\n\\bar{x} &= 0.85 \\text{ g} \\\\\n\\sigma &= 0.15 \\text{ g} \\\\\n\\alpha &= 0.05 \\\\\nz_{\\alpha/2} &= z_{0.025} = 1.96\n\\end{aligned}\n\\]\nCálculo del error estándar:\n\\[\n\\text{Error estándar} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{0.15}{\\sqrt{25}} = \\frac{0.15}{5} = 0.03\n\\]\nMargen de error:\n\\[\n\\text{Margen de error} = z_{\\alpha/2} \\times \\text{Error estándar} = 1.96 \\times 0.03 = 0.0588\n\\]\nIntervalo de confianza al 95%:\n\\[\n\\begin{aligned}\nIC_{95\\%} = \\bar{x} \\pm \\text{Margen de error}  \\\\\nIC_{95\\%} = 0.85 \\pm 0.0588  \\\\\nIC_{95\\%} = [0.7912,\\ 0.9088]\n\\end{aligned}\n\\]\nImplementación en R:\n\n# Uso de la función con los datos del ejemplo\nresultado &lt;- ic_media_sigma(x_barra = 0.85,\n                            sigma = 0.15, \n                            n = 25, \n                            confianza = 0.95)\n\n=== INTERVALO DE CONFIANZA PARA LA MEDIA ===\nDesviación estándar poblacional conocida\n\nDatos:\n- Media muestral: 0.85 \n- Desviación estándar poblacional: 0.15 \n- Tamaño de muestra: 25 \n- Nivel de confianza: 95 %\n\nCálculos:\n- Error estándar: 0.03 \n- Valor z crítico: 1.96 \n- Margen de error: 0.0588 \n\nRESULTADO:\nIC al 95 %: [ 0.7912 , 0.9088 ]\n\n\n\n\n16.4.2 Ejemplo 2: Intervalo de confianza para la media con desviación estándar desconocida\nContexto agronómico: Un investigador desea estimar la altura promedio de plantas de frijol a los 30 días después de la siembra. Se selecciona una muestra aleatoria de 15 plantas y se registran las siguientes alturas en centímetros:\n\n\n\n12.5\n14.2\n13.8\n\n\n15.1\n12.9\n14.7\n\n\n13.3\n14.9\n13.6\n\n\n14.4\n12.8\n15.3\n\n\n13.9\n14.1\n13.7\n\n\n\nDatos:\n\\[\n\\begin{aligned}\nn &= 15 \\\\\n\\bar{x} &= 13.89 \\text{ cm} \\\\\ns &= 0.85 \\text{ cm} \\\\\n\\alpha &= 0.05\n\\end{aligned}\n\\]\nGrados de libertad:\n\\[\ngl = n - 1 = 15 - 1 = 14\n\\]\nValor crítico de t:\n\\[\nt_{\\alpha/2, 14} = t_{0.025, 14} = 2.145\n\\]\nError estándar:\n\\[\n\\text{Error estándar} = \\frac{s}{\\sqrt{n}} = \\frac{0.85}{\\sqrt{15}} = 0.2195\n\\]\nMargen de error:\n\\[\n\\text{Margen de error} = t_{\\alpha/2,14} \\times \\text{Error estándar} = 2.145 \\times 0.2195 = 0.4708\n\\]\nIntervalo de confianza al 95%:\n\\[\nIC_{95\\%} = \\bar{x} \\pm \\text{Margen de error} = 13.89 \\pm 0.4708 = [13.42,\\ 14.36]\n\\]\nImplementación en R:\nUsando la función por defecto de R:\n\n# Datos del problema\nalturas &lt;- c(12.5, 14.2, 13.8, 15.1, 12.9, 14.7, 13.3, 14.9, \n             13.6, 14.4, 12.8, 15.3, 13.9, 14.1, 13.7)\n\n# Cálculo directo con función incorporada\nresultado &lt;- t.test(alturas, conf.level = 0.95)\nprint(resultado)\n\n\n    One Sample t-test\n\ndata:  alturas\nt = 63.729, df = 14, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 13.47730 14.41604\nsample estimates:\nmean of x \n 13.94667 \n\n\nUsando la función personalizada:\n\n# Opción 1: Pasando los datos directamente\nresultado1 &lt;- ic_media_s(datos = alturas, \n                         confianza = 0.95)\n\n=== INTERVALO DE CONFIANZA PARA LA MEDIA ===\nDesviación estándar poblacional desconocida\nDistribución utilizada: t de Student \nCriterio: n &lt; 30\n\nDatos originales:\n12.5, 14.2, 13.8, 15.1, 12.9, 14.7, 13.3, 14.9, 13.6, 14.4, 12.8, 15.3, 13.9, 14.1, 13.7 \n\nEstadísticos calculados:\n- Tamaño de muestra (n): 15 \n- Media muestral (x̄): 13.9467 \n- Desviación estándar muestral (s): 0.8476 \n- Grados de libertad: 14 \n- Nivel de confianza: 95 %\n\nCálculos del intervalo:\n- Error estándar: 0.2188 \n- Valor t crítico: 2.1448 \n- Margen de error: 0.4694 \n\nRESULTADO:\nIC al 95 %: [ 13.4773 , 14.416 ]\n\n# Opción 2: Pasando los estadísticos calculados\nresultado2 &lt;- ic_media_s(x_barra = 13.89, \n                         s = 0.85, \n                         n = 15, \n                         confianza = 0.95)\n\n=== INTERVALO DE CONFIANZA PARA LA MEDIA ===\nDesviación estándar poblacional desconocida\nDistribución utilizada: t de Student \nCriterio: n &lt; 30\n\nEstadísticos calculados:\n- Tamaño de muestra (n): 15 \n- Media muestral (x̄): 13.89 \n- Desviación estándar muestral (s): 0.85 \n- Grados de libertad: 14 \n- Nivel de confianza: 95 %\n\nCálculos del intervalo:\n- Error estándar: 0.2195 \n- Valor t crítico: 2.1448 \n- Margen de error: 0.4707 \n\nRESULTADO:\nIC al 95 %: [ 13.4193 , 14.3607 ]\n\n\n\n\n16.4.3 Ejemplo 3: Intervalo de confianza para la varianza\nContexto agronómico: Se evalúa la variabilidad en el peso de 20 tomates con una desviación estándar muestral de 45 gramos.\nDatos:\n\\[\n\\begin{aligned}\nn &= 20 \\\\\ns &= 45 \\text{ g} \\\\\ns^2 &= 2025 \\text{ g}^2 \\\\\n\\alpha &= 0.10\n\\end{aligned}\n\\]\nGrados de libertad:\n\\[\ngl = n - 1 = 20 - 1 = 19\n\\]\nValores críticos de la distribución chi-cuadrado:\n\\[\n\\chi^2_{0.05, 19} = 30.144, \\quad \\chi^2_{0.95, 19} = 10.117\n\\]\nLímite inferior para la varianza:\n\\[\n\\frac{(n - 1) \\cdot s^2}{\\chi^2_{\\alpha/2, \\, n-1}} = \\frac{19 \\cdot 2025}{30.144} = 1276.9\n\\]\nLímite superior para la varianza:\n\\[\n\\frac{(n - 1) \\cdot s^2}{\\chi^2_{1 - \\alpha/2, \\, n-1}} = \\frac{19 \\cdot 2025}{10.117} = 3803.8\n\\]\nIntervalo de confianza del 90 % para la varianza \\(\\sigma^2\\):\n\\[\nIC_{90\\%} \\text{ para } \\sigma^2 = [1276.9,\\ 3803.8] \\text{ g}^2\n\\]\nIntervalo de confianza del 90 % para la desviación estándar \\(\\sigma\\):\n\\[\nIC_{90\\%} \\text{ para } \\sigma = [\\sqrt{1276.9},\\ \\sqrt{3803.8}] = [35.73,\\ 61.68] \\text{ g}\n\\]\nImplementación en R:\n\n# Ejemplo con los datos del problema\nresultado &lt;- ic_varianza(s = 45, \n                         n = 20, \n                         confianza = 0.90)\n\n=== INTERVALO DE CONFIANZA PARA LA VARIANZA ===\nDistribución Chi-cuadrado\n\nEstadísticos calculados:\n- Tamaño de muestra (n): 20 \n- Desviación estándar muestral (s): 45 \n- Varianza muestral (s²): 2025 \n- Grados de libertad: 19 \n- Nivel de confianza: 90 %\n- Nivel de significancia (α): 0.1 \n\nValores críticos de Chi-cuadrado:\n- χ² 0.05 , 19 = 10.117 \n- χ² 0.95 , 19 = 30.1435 \n\nCálculos del intervalo:\n- Límite inferior varianza: ( 19 × 2025 ) / 30.144 = 1276.4 \n- Límite superior varianza: ( 19 × 2025 ) / 10.117 = 3803 \n\nRESULTADOS:\nIC al 90 % para σ²: [ 1276.4 , 3803 ] IC al 90 % para σ:  [ 35.73 , 61.67 ] \n\n\n\n\n16.4.4 Ejemplo 4: Intervalo de confianza para la proporción\nContexto agronómico: De 200 plantas de trigo evaluadas, 156 mostraron resistencia a una enfermedad.\nCálculo manual:\nDatos:\n\\[\n\\begin{aligned}\nn &= 200 \\\\\nx &= 156 \\\\\n\\hat{p} &= \\frac{156}{200} = 0.78 \\\\\n\\alpha &= 0.05 \\\\\nz_{\\alpha/2} &= z_{0.025} = 1.96\n\\end{aligned}\n\\]\nError estándar:\n\\[\n\\text{Error estándar} = \\sqrt{ \\frac{\\hat{p}(1 - \\hat{p})}{n} } = \\sqrt{ \\frac{0.78 \\cdot 0.22}{200} } = \\sqrt{0.000858} = 0.0293\n\\]\nMargen de error:\n\\[\n\\text{Margen de error} = z_{\\alpha/2} \\cdot \\text{Error estándar} = 1.96 \\cdot 0.0293 = 0.0574\n\\]\nIntervalo de confianza al 95 %:\n\\[\nIC_{95\\%} = \\hat{p} \\pm \\text{Margen de error} = 0.78 \\pm 0.0574 = [0.7226,\\ 0.8374]\n\\]\nImplementación en R:\nUsando la función base de R:\n\n# Cálculo directo con función incorporada en R base\nprop.test(x = 156, \n          n = 200, \n          conf.level = 0.95, \n          correct = FALSE)\n\n\n    1-sample proportions test without continuity correction\n\ndata:  156 out of 200, null probability 0.5\nX-squared = 62.72, df = 1, p-value = 2.383e-15\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.7176120 0.8318346\nsample estimates:\n   p \n0.78 \n\n\nNota: correct = FALSE evita la corrección de continuidad para que el resultado sea idéntico al cálculo manual.\nUsando la función personalizada:\n\n# Uso con los datos del ejemplo\nic_proporcion(x = 156,\n              n = 200, \n              confianza = 0.95)\n\n=== INTERVALO DE CONFIANZA PARA UNA PROPORCIÓN ===\nDatos:\n- Éxitos (x): 156 \n- Tamaño de muestra (n): 200 \n- Proporción muestral (p̂): 0.78 \n- Nivel de confianza: 95 %\n\nCálculos:\n- Error estándar: 0.0293 \n- Valor z crítico: 1.96 \n- Margen de error: 0.0574 \n\nRESULTADO:\nIC al 95 %: [ 0.7226 , 0.8374 ]",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Estimación puntual e intervalos de confianza en R</span>"
    ]
  },
  {
    "objectID": "C9.1.html#formulas-para-el-calculo-de-intervalos-de-confianza",
    "href": "C9.1.html#formulas-para-el-calculo-de-intervalos-de-confianza",
    "title": "16  Estimación puntual e intervalos de confianza en R",
    "section": "16.3 Formulas para el calculo de intervalos de confianza",
    "text": "16.3 Formulas para el calculo de intervalos de confianza\n\n16.3.1 Intervalos de confianza para la media con desviación estándar conocida\nCuando la desviación estándar de la población (\\(\\sigma\\)) es conocida, el intervalo de confianza para la media poblacional (\\(\\mu\\)) se calcula utilizando la distribución normal estándar (\\(z\\)):\n\\[\\huge \\bar{x} \\pm z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\\]\nPara automatizar este proceso en R se puede emplear la siguiente formula personalizada:\n\n# Función personalizada para intervalo de confianza (sigma conocida)\nic_media_sigma &lt;- function(x_barra, \n                           sigma, \n                           n, \n                           confianza = 0.95) {\n  # Cálculos\n  error_estandar &lt;- sigma / sqrt(n)\n  alpha &lt;- 1 - confianza\n  z_critico &lt;- qnorm(1 - alpha/2)\n  margen_error &lt;- z_critico * error_estandar\n  \n  # Límites del intervalo\n  limite_inf &lt;- x_barra - margen_error\n  limite_sup &lt;- x_barra + margen_error\n  \n  # Resultados organizados\n  resultados &lt;- list(\n    media_muestra = x_barra,\n    error_estandar = error_estandar,\n    z_critico = z_critico,\n    margen_error = margen_error,\n    limite_inferior = limite_inf,\n    limite_superior = limite_sup,\n    intervalo = c(limite_inf, limite_sup),\n    confianza = confianza * 100\n  )\n  \n  # Mostrar resultados\n  cat(\"=== INTERVALO DE CONFIANZA PARA LA MEDIA ===\\n\")\n  cat(\"Desviación estándar poblacional conocida\\n\\n\")\n  cat(\"Datos:\\n\")\n  cat(\"- Media muestral:\", x_barra, \"\\n\")\n  cat(\"- Desviación estándar poblacional:\", sigma, \"\\n\")\n  cat(\"- Tamaño de muestra:\", n, \"\\n\")\n  cat(\"- Nivel de confianza:\", confianza*100, \"%\\n\\n\")\n  cat(\"Cálculos:\\n\")\n  cat(\"- Error estándar:\", round(error_estandar, 4), \"\\n\")\n  cat(\"- Valor z crítico:\", round(z_critico, 4), \"\\n\")\n  cat(\"- Margen de error:\", round(margen_error, 4), \"\\n\\n\")\n  cat(\"RESULTADO:\\n\")\n  cat(\"IC al\", confianza*100, \"%: [\", round(limite_inf, 4), \n      \",\", round(limite_sup, 4), \"]\\n\")\n  \n  return(invisible(resultados))\n}\n\nEsta función cuenta con la siguiente sintaxis para su uso:\n\\[\n\\Large \\text{ic\\_media\\_sigma(x\\_barra, sigma, n, confianza)}\n\\]\nArgumentos en orden:\n\nx_barra: Media muestral\nsigma: Desviación estandar poblacional conocida\nn: Tamaño de la muestra\nconfianza: Nivel de confianza\n\n\n\n16.3.2 Intervalos de confianza para la media con desviación estándar desconocida\nCuando la desviación estándar de la población (\\(\\sigma\\)) es desconocida, se utiliza la desviación estándar muestral (\\(s\\)) como estimación. La elección de la distribución apropiada para calcular el intervalo de confianza depende del tamaño de la muestra:\nCriterio de selección de distribución:\nPara muestras pequeñas (n &lt; 30): Se utiliza la distribución t de Student:\n\\[\\huge \\bar{x} \\pm t_{\\alpha/2, n-1} \\cdot \\frac{s}{\\sqrt{n}} \\]\ndonde \\(t_{\\alpha/2, n-1}\\) es el valor crítico de la distribución t de Student con \\(n-1\\) grados de libertad.\nPara muestras grandes (n ≥ 30): Se puede utilizar la distribución normal estándar (Z)\n\\[\\huge \\bar{x} \\pm z_{\\alpha/2} \\cdot \\frac{s}{\\sqrt{n}}\\]\ndonde \\(z_{\\alpha/2}\\) es el valor crítico de la distribución normal estándar.\nPara automatizar este proceso en R se puede emplear la siguiente formula personalizada:\n\n# Función robusta que decide automáticamente entre Z y t\nic_media_s &lt;- function(datos = NULL, \n                       x_barra = NULL, \n                       s = NULL, \n                       n = NULL, \n                       confianza = 0.95) {\n  \n  # Si se proporcionan los datos directamente\n  if (!is.null(datos)) {\n    n &lt;- length(datos)\n    x_barra &lt;- mean(datos)\n    s &lt;- sd(datos)\n  }\n  \n  # Verificar que tenemos todos los parámetros necesarios\n  if (is.null(x_barra) || is.null(s) || is.null(n)) {\n    stop(\"Debe proporcionar los datos o los valores de x_barra, s y n\")\n  }\n  \n  # Decidir qué distribución usar\n  usar_z &lt;- n &gt;= 30\n  \n  # Cálculos comunes\n  alpha &lt;- 1 - confianza\n  error_estandar &lt;- s / sqrt(n)\n  \n  if (usar_z) {\n    # Usar distribución Z\n    valor_critico &lt;- qnorm(1 - alpha/2)\n    distribucion &lt;- \"Z (Normal estándar)\"\n    gl &lt;- NA\n  } else {\n    # Usar distribución t\n    gl &lt;- n - 1\n    valor_critico &lt;- qt(1 - alpha/2, gl)\n    distribucion &lt;- \"t de Student\"\n  }\n  \n  margen_error &lt;- valor_critico * error_estandar\n  \n  # Límites del intervalo\n  limite_inf &lt;- x_barra - margen_error\n  limite_sup &lt;- x_barra + margen_error\n  \n  # Resultados organizados\n  resultados &lt;- list(\n    datos = if(!is.null(datos)) datos else \"No proporcionados\",\n    n = n,\n    media_muestra = x_barra,\n    desv_estandar_muestra = s,\n    distribucion_usada = distribucion,\n    grados_libertad = if(usar_z) NA else gl,\n    error_estandar = error_estandar,\n    valor_critico = valor_critico,\n    margen_error = margen_error,\n    limite_inferior = limite_inf,\n    limite_superior = limite_sup,\n    intervalo = c(limite_inf, limite_sup),\n    confianza = confianza * 100\n  )\n  \n  # Mostrar resultados\n  cat(\"=== INTERVALO DE CONFIANZA PARA LA MEDIA ===\\n\")\n  cat(\"Desviación estándar poblacional desconocida\\n\")\n  cat(\"Distribución utilizada:\", distribucion, \"\\n\")\n  cat(\"Criterio: n\", if(usar_z) \"≥\" else \"&lt;\", \"30\\n\\n\")\n  \n  if (!is.null(datos)) {\n    cat(\"Datos originales:\\n\")\n    if (length(datos) &lt;= 20) {\n      cat(paste(datos, collapse = \", \"), \"\\n\\n\")\n    } else {\n      cat(\"Muestra de\", length(datos), \"observaciones\\n\\n\")\n    }\n  }\n  \n  cat(\"Estadísticos calculados:\\n\")\n  cat(\"- Tamaño de muestra (n):\", n, \"\\n\")\n  cat(\"- Media muestral (x̄):\", round(x_barra, 4), \"\\n\")\n  cat(\"- Desviación estándar muestral (s):\", round(s, 4), \"\\n\")\n  if (!usar_z) cat(\"- Grados de libertad:\", gl, \"\\n\")\n  cat(\"- Nivel de confianza:\", confianza*100, \"%\\n\\n\")\n  \n  cat(\"Cálculos del intervalo:\\n\")\n  cat(\"- Error estándar:\", round(error_estandar, 4), \"\\n\")\n  cat(\"- Valor\", if(usar_z) \"z\" else \"t\", \"crítico:\",\n      round(valor_critico, 4), \"\\n\")\n  cat(\"- Margen de error:\", round(margen_error, 4), \"\\n\\n\")\n  \n  cat(\"RESULTADO:\\n\")\n  cat(\"IC al\", confianza*100, \"%: [\", round(limite_inf, 4), \n      \",\", round(limite_sup, 4), \"]\\n\\n\")\n  \n  return(invisible(resultados))\n}\n\nEsta función cuenta con la siguiente sintaxis para su uso:\n\\[\n\\Large \\text{ic\\_media\\_s(datos, confianza)}\n\\] Argumentos en orden:\n\ndatos: Vector con los datos muestrales\nconfianza: Nivel de confianza\n\nTambién tiene la siguiente sintaxis cuando no se cuenta con los datos de la muestra directamente:\n\\[\n\\Large \\text{ic\\_media\\_s(x\\_barra, s, n, confianza)}\n\\]\nArgumentos en orden:\n\nx_barra: Media muestral\ns: Desviación estandar muestral\nn: Tamaño de la muestra\nconfianza: Nivel de confianza\n\n\n\n16.3.3 Intervalos de confianza para la varianza\nEl intervalo de confianza para la varianza poblacional (\\(\\sigma^2\\)) se calcula utilizando la distribución chi-cuadrado (\\(\\chi^2\\)):\n\\[\\LARGE \\frac{(n-1)s^2}{\\chi^2_{\\alpha/2, n-1}} \\leq \\sigma^2 \\leq \\frac{(n-1)s^2}{\\chi^2_{1-\\alpha/2, n-1}} \\]\ndonde:\n\n\\(s^2\\) es la varianza muestral,\n\\(\\chi^2_{\\alpha/2, n-1}\\) y \\(\\chi^2_{1-\\alpha/2, n-1}\\) son los valores críticos de la distribución chi-cuadrado con \\(n-1\\) grados de libertad.\n\nPara automatizar este proceso en R se puede emplear la siguiente formula personalizada:\n\n# Función personalizada para intervalo de confianza de varianza\nic_varianza &lt;- function(datos = NULL, \n                        s = NULL, \n                        n = NULL, \n                        confianza = 0.95) {\n  \n  # Si se proporcionan los datos directamente\n  if (!is.null(datos)) {\n    n &lt;- length(datos)\n    s &lt;- sd(datos)\n  }\n  \n  # Verificar que tenemos todos los parámetros necesarios\n  if (is.null(s) || is.null(n)) {\n    stop(\"Debe proporcionar los datos o los valores de s y n\")\n  }\n  \n  # Cálculos básicos\n  s2 &lt;- s^2  # varianza muestral\n  gl &lt;- n - 1  # grados de libertad\n  alpha &lt;- 1 - confianza\n  \n  # Valores críticos de chi-cuadrado\n  chi2_inf &lt;- qchisq(alpha/2, gl)        # límite inferior\n  chi2_sup &lt;- qchisq(1 - alpha/2, gl)    # límite superior\n  \n  # Intervalos de confianza para la varianza\n  ic_var_inf &lt;- (gl * s2) / chi2_sup\n  ic_var_sup &lt;- (gl * s2) / chi2_inf\n  \n  # Intervalos de confianza para la desviación estándar\n  ic_sd_inf &lt;- sqrt(ic_var_inf)\n  ic_sd_sup &lt;- sqrt(ic_var_sup)\n  \n  # Resultados organizados\n  resultados &lt;- list(\n    datos = if(!is.null(datos)) datos else \"No proporcionados\",\n    n = n,\n    desv_estandar_muestra = s,\n    varianza_muestra = s2,\n    grados_libertad = gl,\n    chi2_inferior = chi2_inf,\n    chi2_superior = chi2_sup,\n    ic_varianza = c(ic_var_inf, ic_var_sup),\n    ic_desv_estandar = c(ic_sd_inf, ic_sd_sup),\n    confianza = confianza * 100\n  )\n  \n  # Mostrar resultados\n  cat(\"=== INTERVALO DE CONFIANZA PARA LA VARIANZA ===\\n\")\n  cat(\"Distribución Chi-cuadrado\\n\\n\")\n  \n  if (!is.null(datos)) {\n    cat(\"Datos originales:\\n\")\n    if (length(datos) &lt;= 20) {\n      cat(paste(datos, collapse = \", \"), \"\\n\\n\")\n    } else {\n      cat(\"Muestra de\", length(datos), \"observaciones\\n\\n\")\n    }\n  }\n  \n  cat(\"Estadísticos calculados:\\n\")\n  cat(\"- Tamaño de muestra (n):\", n, \"\\n\")\n  cat(\"- Desviación estándar muestral (s):\", round(s, 4), \"\\n\")\n  cat(\"- Varianza muestral (s²):\", round(s2, 4), \"\\n\")\n  cat(\"- Grados de libertad:\", gl, \"\\n\")\n  cat(\"- Nivel de confianza:\", confianza*100, \"%\\n\")\n  cat(\"- Nivel de significancia (α):\", alpha, \"\\n\\n\")\n  \n  cat(\"Valores críticos de Chi-cuadrado:\\n\")\n  cat(\"- χ²\", alpha/2, \",\", gl, \"=\", round(chi2_inf, 4), \"\\n\")\n  cat(\"- χ²\", 1-alpha/2, \",\", gl, \"=\", round(chi2_sup, 4), \"\\n\\n\")\n  \n  cat(\"Cálculos del intervalo:\\n\")\n  cat(\"- Límite inferior varianza: (\", gl, \"×\", round(s2,1), \") /\", \n      round(chi2_sup,3), \"=\", round(ic_var_inf, 1), \"\\n\")\n  cat(\"- Límite superior varianza: (\", gl, \"×\", round(s2,1), \") /\", \n      round(chi2_inf,3), \"=\", round(ic_var_sup, 1), \"\\n\\n\")\n  \n  cat(\"RESULTADOS:\\n\")\n  cat(\"IC al\", confianza*100, \"% para σ²: [\", round(ic_var_inf, 1), \n      \",\", round(ic_var_sup, 1), \"] \")\n  cat(\"IC al\", confianza*100, \"% para σ:  [\", round(ic_sd_inf, 2), \n      \",\", round(ic_sd_sup, 2), \"] \")\n  \n  return(invisible(resultados))\n}\n\nEsta función cuenta con la siguiente sintaxis para su uso:\n\\[\n\\Large \\text{ic\\_varianza(datos, confianza)}\n\\] Argumentos en orden:\n\ndatos: Vector con los datos de la muestra\nconfianza: Nivel de confianza\n\nTambién tiene la siguiente sintaxis cuando no se cuenta con los datos de la muestra directamente:\n\\[\n\\Large \\text{ic\\_varianza(s, n, confianza)}\n\\] Argumentos en orden:\n\ns: Desviación estándar muestral\nn: Tamaño de la muestra\nconfianza: Nivel de confianza\n\n\n\n16.3.4 Intervalos de confianza para la proporción\nEl intervalo de confianza para la proporción poblacional (p) se calcula como:\n\\[\\LARGE \\hat{p} \\pm z_{\\alpha/2} \\cdot \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\]​\ndonde:\n\n\\(\\hat{p}\\) es la proporción muestral,\n\\(z_{\\alpha/2}\\) es el valor crítico de la distribución normal estándar.\n\nPara automatizar este proceso en R se puede emplear la siguiente formula personalizada:\n\n# Función personalizada para intervalo de confianza de una proporción\nic_proporcion &lt;- function(x, \n                          n, \n                          confianza = 0.95) {\n  p_hat &lt;- x / n\n  alpha &lt;- 1 - confianza\n  z_critico &lt;- qnorm(1 - alpha/2)\n  error_estandar &lt;- sqrt(p_hat * (1 - p_hat) / n)\n  margen_error &lt;- z_critico * error_estandar\n  limite_inf &lt;- p_hat - margen_error\n  limite_sup &lt;- p_hat + margen_error\n  \n  # Resultados organizados\n  resultados &lt;- list(\n    proporcion_muestral = p_hat,\n    error_estandar = error_estandar,\n    z_critico = z_critico,\n    margen_error = margen_error,\n    limite_inferior = limite_inf,\n    limite_superior = limite_sup,\n    intervalo = c(limite_inf, limite_sup),\n    confianza = confianza * 100\n  )\n  \n  # Mostrar resultados\n  cat(\"=== INTERVALO DE CONFIANZA PARA UNA PROPORCIÓN ===\\n\")\n  cat(\"Datos:\\n\")\n  cat(\"- Éxitos (x):\", x, \"\\n\")\n  cat(\"- Tamaño de muestra (n):\", n, \"\\n\")\n  cat(\"- Proporción muestral (p̂):\", round(p_hat, 4), \"\\n\")\n  cat(\"- Nivel de confianza:\", confianza*100, \"%\\n\\n\")\n  \n  cat(\"Cálculos:\\n\")\n  cat(\"- Error estándar:\", round(error_estandar, 4), \"\\n\")\n  cat(\"- Valor z crítico:\", round(z_critico, 4), \"\\n\")\n  cat(\"- Margen de error:\", round(margen_error, 4), \"\\n\\n\")\n  \n  cat(\"RESULTADO:\\n\")\n  cat(\"IC al\", confianza*100, \"%: [\", round(limite_inf, 4), \n      \",\", round(limite_sup, 4), \"]\\n\")\n  \n  return(invisible(resultados))\n}\n\nEsta función cuenta con la siguiente sintaxis para su uso:\n\\[\n\\Large \\text{ic\\_proporcion(x, n, confianza)}\n\\] Argumentos en orden:\n\nx: numero de observaciones “exitosas” en la muestra\nn: Tamaño de la muestra\nconfianza: Nivel de confianza",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Estimación puntual e intervalos de confianza en R</span>"
    ]
  },
  {
    "objectID": "C10.1.html",
    "href": "C10.1.html",
    "title": "17  Pruebas de Hipótesis Paramétricas en R",
    "section": "",
    "text": "17.1 Fundamentos de las pruebas de hipótesis\nEn la investigación agronómica, es fundamental tomar decisiones basadas en datos. Las pruebas de hipótesis permiten evaluar si los resultados observados en una muestra pueden generalizarse a la población de interés o si son producto del azar. Este capítulo guía al estudiante en la aplicación de pruebas de hipótesis paramétricas utilizando R, desde la formulación de hipótesis hasta la interpretación de resultados, empleando ejemplos prácticos y reales del ámbito agronómico (López & González, 2018).\nUna prueba de hipótesis es un procedimiento estadístico que permite decidir, con un nivel de confianza predefinido, si una afirmación sobre un parámetro poblacional es compatible con los datos muestrales. El proceso general incluye:\nCriterios de selección de la prueba:",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Pruebas de Hipótesis Paramétricas en R</span>"
    ]
  },
  {
    "objectID": "C10.1.html#fundamentos-de-las-pruebas-de-hipótesis",
    "href": "C10.1.html#fundamentos-de-las-pruebas-de-hipótesis",
    "title": "17  Pruebas de Hipótesis Paramétricas en R",
    "section": "",
    "text": "Plantear la hipótesis nula (\\(H_0\\)) y la alternativa (\\(H_a\\)).\nSeleccionar el estadístico de prueba adecuado según el tipo de dato y los supuestos.\nCalcular el valor del estadístico y el valor-p.\nComparar el valor-p con el nivel de significancia (\\(\\alpha\\)), generalmente 0.05.\nTomar una decisión: rechazar o no rechazar \\(H_0\\).\n\n\n\nTipo de variable (cuantitativa o cualitativa).\nTamaño de la muestra.\nConocimiento de la varianza poblacional.\nIndependencia o dependencia entre muestras.\nHomogeneidad de varianzas.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Pruebas de Hipótesis Paramétricas en R</span>"
    ]
  },
  {
    "objectID": "C10.1.html#prueba-de-hipótesis-sobre-una-media",
    "href": "C10.1.html#prueba-de-hipótesis-sobre-una-media",
    "title": "17  Pruebas de Hipótesis Paramétricas en R",
    "section": "17.2 Prueba de hipótesis sobre una media",
    "text": "17.2 Prueba de hipótesis sobre una media\nEsta prueba se utiliza para determinar si la media de una población difiere de un valor específico. Es útil, por ejemplo, para verificar si el peso promedio de semillas, el rendimiento de un cultivo o el contenido de un nutriente cumple con un estándar.\n\n17.2.1 Criterios de selección\n\nVariable cuantitativa continua.\nLa muestra debe ser aleatoria.\nSi la varianza poblacional es conocida y la muestra es grande (\\(n \\geq 30\\)), se usa la prueba z.\nSi la varianza es desconocida y la muestra es pequeña (\\(n&lt;30\\)), se usa la prueba t de Student.\n\n\n\n17.2.2 Fórmulas\na) Prueba z (varianza conocida):\n\\[\\huge z = \\frac{\\bar{x} - \\mu_0}{\\sigma / \\sqrt{n}}  \\]​​\nb) Prueba t (varianza desconocida):\n\\[\\huge t = \\frac{\\bar{x} - \\mu_0}{s / \\sqrt{n}} \\]\ndonde \\(gl = n-1\\).\n\n\n17.2.3 Ejemplo hipotético\nSupóngase que se afirma que el peso promedio de semillas de maíz es de 250 mg. Se toma una muestra de 20 semillas, obteniéndose una media de 242 mg y una desviación estándar de 15 mg. Se desea saber, con un nivel de significancia del 5%, si el peso medio difiere del valor afirmado.\n1. Planteamiento de hipótesis:\n\n\\(H_0: \\mu = 250\\) mg\n\\(H_a: \\mu \\neq 250\\) mg\n\n2. Cálculo del estadístico:\n\\[\\Large t = \\frac{242 - 250}{15 / \\sqrt{20}} = \\frac{-8}{3.354} = -2.39 \\]\n3. Región crítica:\nPara \\(gl=19\\) y \\(\\alpha = 0.05\\) (bilateral), el valor crítico es \\(\\pm 2.093\\).\n4. Decisión:\nComo \\(|-2.39| &gt; 2.093\\), se rechaza H_0.\n5. Conclusión:\nCon un 5% de significancia, existe evidencia de que el peso medio difiere de 250 mg.\n\n\n17.2.4 Código en R explicado\n\n# Instalar paquete si no está instalado\n## Para realizar pruebas de hipotesis\nif (!require(BSDA)) install.packages(\"BSDA\")\nif (!require(EnvStats)) install.packages(\"EnvStats\")\n\n\n# Prueba t con estadísticos resumidos usando tsum.test()\ntsum.test(mean.x = 242,\n          s.x = 15,\n          n.x = 20,\n          mu = 250,\n          alternative = \"two.sided\",\n          conf.level = 0.95)\n\n\n    One-sample t-Test\n\ndata:  Summarized x\nt = -2.3851, df = 19, p-value = 0.02765\nalternative hypothesis: true mean is not equal to 250\n95 percent confidence interval:\n 234.9798 249.0202\nsample estimates:\nmean of x \n      242 \n\n\nParámetros de tsum.test():\n\nmean.x: media muestral (242 mg)\ns.x: desviación estándar muestral (15 mg)\nn.x: tamaño de muestra (20)\nmu: valor hipotético bajo H₀ (250 mg)\nalternative: tipo de prueba (“two.sided” para bilateral)\nconf.level: nivel de confianza (0.95 para 95%)",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Pruebas de Hipótesis Paramétricas en R</span>"
    ]
  },
  {
    "objectID": "C10.1.html#prueba-de-hipótesis-sobre-dos-medias",
    "href": "C10.1.html#prueba-de-hipótesis-sobre-dos-medias",
    "title": "17  Pruebas de Hipótesis Paramétricas en R",
    "section": "17.3 Prueba de hipótesis sobre dos medias",
    "text": "17.3 Prueba de hipótesis sobre dos medias\nPermite comparar si las medias de dos poblaciones son iguales o diferentes. Es útil, por ejemplo, para comparar el rendimiento de dos variedades de cultivo, el efecto de dos tratamientos o la altura de plantas de dos especies.\n\n17.3.1 Criterios de selección\n\nLas muestras pueden ser independientes (grupos distintos) o dependientes (mediciones pareadas).\nSe debe verificar si las varianzas son iguales o diferentes.\nSi las muestras son grandes (\\(n_1, n_2 \\geq 30\\)), se puede usar la prueba z; si son pequeñas y la varianza es desconocida, se usa la prueba t.\n\n\n\n17.3.2 Fórmulas\na) Muestras independientes, varianzas iguales (t “pooled”):\n\\[\\huge t = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}  \\]\ndonde\n\\[\\huge s_p^2 = \\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}  \\]\nb) Muestras independientes, varianzas diferentes (Welch):\n\\[\\huge t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}} \\]\nc) Muestras dependientes (pareadas):\n\\[\\huge t = \\frac{\\bar{d}}{s_d / \\sqrt{n}}\\] ​\ndonde \\(\\bar{d}\\) es la media de las diferencias y \\(s_d\\)​ su desviación estándar.\n\n\n17.3.3 Ejemplo hipotético (independientes, varianzas iguales)\nSe comparan las alturas de dos especies forestales.\n\nEspecie 1: \\(\\bar{x}_1 = 25.97\\) m, \\(s_1 = 1.36\\), \\(n_1 = 13\\)\nEspecie 2: \\(\\bar{x}_2 = 25.39\\) m, \\(s_2 = 1.77\\), \\(n_2 = 14\\)\n\n1. Hipótesis:\n\n\\(H_0: \\mu_1 = \\mu_2\\)\n\\(H_a: \\mu_1 \\neq \\mu_2\\)\n\n2. Cálculo:\n\\[\\LARGE s_p^2 = \\frac{12 \\times 1.36^2 + 13 \\times 1.77^2}{25} = 2.30  \\]\n\\[\\huge s_p = \\sqrt{2.30} = 1.52  \\]\n\\[\\huge t = \\frac{25.97 - 25.39}{1.52 \\sqrt{\\frac{1}{13} + \\frac{1}{14}}} = 0.94\\]\n3. Decisión: Para \\(gl=25\\), \\(t_{0.025} = 2.060\\). Como \\(0.94 &lt; 2.060\\), no se rechaza \\(H_0\\).\n\n\n17.3.4 Código en R explicado\n\n# Datos del ejercicio\nmean1 &lt;- 25.97; s1 &lt;- 1.36; n1 &lt;- 13  # Especie 1\nmean2 &lt;- 25.39; s2 &lt;- 1.77; n2 &lt;- 14  # Especie 2\n\n# Prueba t para dos muestras independientes con varianzas iguales\ntsum.test(mean.x = mean1, s.x = s1, n.x = n1,\n          mean.y = mean2, s.y = s2, n.y = n2,\n          alternative = \"two.sided\",\n          mu = 0,        # diferencia hipotética (H₀: μ₁ - μ₂ = 0)\n          var.equal = TRUE,          # asume varianzas iguales (pooled)\n          conf.level = 0.95)         # nivel de confianza\n\n\n    Standard Two-Sample t-Test\n\ndata:  Summarized x and y\nt = 0.94918, df = 25, p-value = 0.3516\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.678492  1.838492\nsample estimates:\nmean of x mean of y \n    25.97     25.39 \n\n\nParámetros de tsum.test() para dos muestras:\n\nmean.x, s.x, n.x: estadísticos de la muestra 1\nmean.y, s.y, n.y: estadísticos de la muestra 2\nmu: diferencia hipotética bajo H₀ (0 para igualdad de medias)\nvar.equal = TRUE: usa varianza pooled (varianzas iguales)\nalternative: “two.sided” para prueba bilateral\n\n\n\n17.3.5 Ejemplo hipotético (pareadas)\nSe evalúa el efecto de una capacitación en 10 empleados, midiendo el puntaje antes y después.\n1. Hipótesis:\n\n\\(H_0: \\mu_D = 0\\) (no hay diferencia)\n\\(H_a: \\mu_D \\neq 0\\) (hay diferencia)\n\n2. Cálculo:\nSupóngase que la media de las diferencias es \\(-0.4\\) y la desviación estándar \\(0.8\\) .\n\\[\\huge t = \\frac{-0.4}{0.8/\\sqrt{10}} = -1.58 \\]\n3. Decisión:\nPara \\(gl = 9\\), \\(t_{0.05} = 2.262\\) . Como \\(|-1.58| &lt; 2.262\\), no se rechaza \\(H_0\\).\n\n\n17.3.6 Código en R explicado\n\n# Datos del ejercicio (estadísticos de las diferencias)\nn &lt;- 10\nmean_diff &lt;- -0.4    # media de diferencias (antes - después)\nsd_diff &lt;- 0.8       # desviación estándar de diferencias\n\n# Prueba t pareada usando estadísticos resumidos\n# Para muestras pareadas, usamos tsum.test() con una sola muestra\n# (las diferencias)\ntsum.test(mean.x = mean_diff,\n          s.x = sd_diff,\n          n.x = n,\n          mu = 0,                    # H₀: μ_D = 0\n          alternative = \"two.sided\",\n          conf.level = 0.95)\n\nWarning in tsum.test(mean.x = mean_diff, s.x = sd_diff, n.x = n, mu = 0, :\nargument 'var.equal' ignored for one-sample test.\n\n\n\n    One-sample t-Test\n\ndata:  Summarized x\nt = -1.5811, df = 9, p-value = 0.1483\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -0.9722855  0.1722855\nsample estimates:\nmean of x \n     -0.4 \n\n\nUna prueba t pareada es equivalente a una prueba t de una muestra sobre las diferencias.\nPor eso usamos tsum.test() con:\n\nmean.x: media de las diferencias (-0.4)\ns.x: desviación estándar de las diferencias (0.8)\nn.x: número de pares (10)\nmu = 0: hipótesis nula (no hay diferencia promedio)\n\nAlternativa con datos individuales:\nSi tuvieras los datos originales:\n\n# Datos\nantes &lt;- c(9.0,7.3,6.7,5.3,8.7,6.3,7.9,7.3,8.0,8.5)\ndespues &lt;- c(9.2,8.2,8.5,4.9,8.9,5.8,8.2,7.8,9.5,8.0)\n# Test para datos pareados\nt.test(antes, despues,\n       paired = TRUE,\n       alternative = \"two.sided\",\n       conf.level = 0.95)\n\n\n    Paired t-test\n\ndata:  antes and despues\nt = -1.5784, df = 9, p-value = 0.1489\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.9732782  0.1732782\nsample estimates:\nmean difference \n           -0.4 \n\n\nPor eso usamos t.test() con:\n\nantes: Vector numerico con los datos iniciales.\ndespues: Vector numerico con los datos finales o pareados.\npaired: si es una prueba de t pareada (TRUE)\nalternative: “two.sided” hace referencia a que compara una igualdad.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Pruebas de Hipótesis Paramétricas en R</span>"
    ]
  },
  {
    "objectID": "C10.1.html#prueba-de-hipótesis-sobre-una-proporción",
    "href": "C10.1.html#prueba-de-hipótesis-sobre-una-proporción",
    "title": "17  Pruebas de Hipótesis Paramétricas en R",
    "section": "17.4 Prueba de hipótesis sobre una proporción",
    "text": "17.4 Prueba de hipótesis sobre una proporción\nPermite determinar si la proporción de una característica en la población es igual a un valor específico. Por ejemplo, si la proporción de agricultores que adopta una tecnología supera el 60%.\n\n17.4.1 Criterios de selección\n\nVariable cualitativa dicotómica.\nTamaño muestral suficiente para aproximación normal (\\(np_0 &gt; 5np\\) y \\(n(1-p_0) &gt; 5\\)).\n\nFórmula\n\\[\\huge z = \\frac{\\hat{p} - p_0}{\\sqrt{p_0(1-p_0)/n}}\\]\n\n\n17.4.2 Ejemplo hipotético\nDe 180 agricultores, 120 adoptaron un fertilizante. Se desea saber si la proporción es diferente de 0.60.\n\\[\\LARGE \\hat{p} = \\frac{120}{180} = 0.667\\]\n\\[\\LARGE z = \\frac{0.667 - 0.60}{\\sqrt{0.60 \\times 0.40 / 180}} = 1.56\\]\nPara \\(\\alpha = 0.05\\), \\(z_{0.025} = 1.96\\). Como \\(1.56 &lt; 1.96\\), no se rechaza \\(H_0\\).\n\n\n17.4.3 Código en R explicado\n\nprop.test(x = 120, n = 180,\n          p = 0.60,                # valor bajo H0\n          alternative = \"two.sided\",\n          correct = FALSE)         # sin corrección de continuidad\n\n\n    1-sample proportions test without continuity correction\n\ndata:  120 out of 180, null probability 0.6\nX-squared = 3.3333, df = 1, p-value = 0.06789\nalternative hypothesis: true p is not equal to 0.6\n95 percent confidence interval:\n 0.5949523 0.7314158\nsample estimates:\n        p \n0.6666667 \n\n\n\nx: número de éxitos.\nn: tamaño de la muestra.\np: proporción bajo \\(H_0\\)​.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Pruebas de Hipótesis Paramétricas en R</span>"
    ]
  },
  {
    "objectID": "C10.1.html#prueba-de-hipótesis-sobre-dos-proporciones",
    "href": "C10.1.html#prueba-de-hipótesis-sobre-dos-proporciones",
    "title": "17  Pruebas de Hipótesis Paramétricas en R",
    "section": "17.5 Prueba de hipótesis sobre dos proporciones",
    "text": "17.5 Prueba de hipótesis sobre dos proporciones\nPermite comparar si la proporción de una característica es igual en dos poblaciones. Por ejemplo, comparar la proporción de adopción de una tecnología entre hombres y mujeres.\n\n17.5.1 Criterios de selección\n\nVariable cualitativa dicotómica.\nMuestras independientes.\nTamaño muestral suficiente.\n\n\n\n17.5.2 Fórmulas\n\\[\\huge \\hat{p}_c = \\frac{x_1 + x_2}{n_1 + n_2}\\]\n\\[\\LARGE z = \\frac{\\hat{p}_1 - \\hat{p}_2}{\\sqrt{\\hat{p}_c(1-\\hat{p}_c)\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}}\\]\n\n\n17.5.3 Ejemplo hipotético\nEn una encuesta, 110 de 200 hombres y 210 de 300 mujeres respondieron. ¿Existe diferencia en las proporciones?\n\\[\\LARGE \\hat{p}_1 = 0.55,; \\hat{p}_2 = 0.70\\]\n\\[\\LARGE \\hat{p}_c = \\frac{110+210}{200+300} = 0.64\\]\n\\[\\LARGE z = \\frac{0.55 - 0.70}{\\sqrt{0.64 \\times 0.36 \\left(\\frac{1}{200} + \\frac{1}{300}\\right)}} = -3.42\\]\nComo \\(|-3.42| &gt; 1.96\\), se rechaza \\(H_0\\).\n\n\n17.5.4 Código en R explicado\n\nxp &lt;- c(110, 210)   # éxitos en cada grupo\nnp &lt;- c(200, 300)   # tamaño de cada grupo\n\nprop.test(xp, np,\n          alternative = \"two.sided\",\n          correct = FALSE)\n\n\n    2-sample test for equality of proportions without continuity correction\n\ndata:  xp out of np\nX-squared = 11.719, df = 1, p-value = 0.0006187\nalternative hypothesis: two.sided\n95 percent confidence interval:\n -0.23627182 -0.06372818\nsample estimates:\nprop 1 prop 2 \n  0.55   0.70 \n\n\n\nxp: vector de éxitos.\nnp: vector de tamaños.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Pruebas de Hipótesis Paramétricas en R</span>"
    ]
  },
  {
    "objectID": "C10.1.html#prueba-de-hipótesis-sobre-varianzas",
    "href": "C10.1.html#prueba-de-hipótesis-sobre-varianzas",
    "title": "17  Pruebas de Hipótesis Paramétricas en R",
    "section": "17.6 Prueba de hipótesis sobre varianzas",
    "text": "17.6 Prueba de hipótesis sobre varianzas\nLa prueba de hipótesis sobre varianzas permite evaluar si la variabilidad observada en una muestra es compatible con un valor de referencia o si existen diferencias en la variabilidad entre dos poblaciones. Este tipo de prueba es fundamental en agronomía para analizar la uniformidad de procesos, como la comparación de la variabilidad en el rendimiento de cultivos bajo diferentes métodos de riego o el control de calidad de productos agrícolas.\n\n17.6.1 Criterios de selección\n\nLa variable de interés debe ser cuantitativa y continua.\nLos datos deben provenir de poblaciones con distribución normal.\nPara comparar dos varianzas, las muestras deben ser independientes.\n\n\n\n17.6.2 Fórmulas\na) Una varianza (\\(\\chi^2\\)): Esta prueba se utiliza para determinar si la varianza de una población es igual a un valor específico, generalmente un estándar de calidad o una especificación técnica.\n\\[\\huge \\chi^2 = \\frac{(n-1)s^2}{\\sigma_0^2} \\]​\ndonde:\n\n\\(n\\) es el tamaño de la muestra,\n\\(s^2\\) es la varianza muestral,\n\\(\\sigma_0^2\\) es la varianza poblacional bajo la hipótesis nula.\n\nPara este calculo no existe una función predefinida en R que lo realice con fines prácticos se desarrollo la siguiente función personalizada para esta tarea:\n\n# Función personalizada para prueba de hipótesis de una varianza\nvar_test_chi &lt;- function(x = NULL, \n                         n = NULL, \n                         s2 = NULL, \n                         sigma0_2,\n                         alternative = \"two.sided\",\n                         alpha = 0.05) {\n  \n  # Validación de argumentos\n  if (is.null(x) && (is.null(n) || is.null(s2))) {\n    stop(\"Debe proporcionar 'x' (vector de datos) o \n         'n' y 's2' (estadísticos muestrales)\")\n  }\n  \n  if (!is.null(x) && (!is.null(n) || !is.null(s2))) {\n    warning(\"Se proporcionaron datos y estadísticos. \n            Se usarán los datos 'x'\")\n  }\n  \n  # Calcular estadísticos si se proporcionan los datos\n  if (!is.null(x)) {\n    n &lt;- length(x)\n    s2 &lt;- var(x)\n  }\n  \n  # Validar alternative\n  alternative &lt;- match.arg(alternative, c(\"two.sided\", \"less\", \"greater\"))\n  \n  # Calcular estadístico chi-cuadrado\n  chi_sq &lt;- (n - 1) * s2 / sigma0_2\n  df &lt;- n - 1\n  \n  # Calcular valor-p según el tipo de prueba\n  if (alternative == \"two.sided\") {\n    # Para prueba bilateral\n    p_value &lt;- 2 * min(pchisq(chi_sq, df), \n                       pchisq(chi_sq, df, lower.tail = FALSE))\n  } else if (alternative == \"greater\") {\n    p_value &lt;- pchisq(chi_sq, df, lower.tail = FALSE)\n  } else { # alternative == \"less\"\n    p_value &lt;- pchisq(chi_sq, df, lower.tail = TRUE)\n  }\n  \n  # Decisión\n  decision &lt;- ifelse(p_value &lt; alpha, \"Rechazar H0\", \"No rechazar H0\")\n  \n  # Valor crítico\n  if (alternative == \"two.sided\") {\n    crit_lower &lt;- qchisq(alpha/2, df)\n    crit_upper &lt;- qchisq(1 - alpha/2, df)\n    critical_value &lt;- c(crit_lower, crit_upper)\n  } else if (alternative == \"greater\") {\n    critical_value &lt;- qchisq(1 - alpha, df)\n  } else { # alternative == \"less\"\n    critical_value &lt;- qchisq(alpha, df)\n  }\n  \n  # Crear objeto de resultado\n  result &lt;- list(\n    statistic = chi_sq,\n    parameter = df,\n    p.value = p_value,\n    critical.value = critical_value,\n    alternative = alternative,\n    method = \"Prueba de hipótesis para una varianza (Chi-cuadrado)\",\n    data.name = deparse(substitute(x)),\n    sample.size = n,\n    sample.variance = s2,\n    null.variance = sigma0_2,\n    alpha = alpha,\n    decision = decision\n  )\n  \n  class(result) &lt;- \"var_test_custom\"\n  return(result)\n}\n\n# Método print personalizado para mostrar resultados de forma clara\nprint.var_test_custom &lt;- function(x, ...) {\n  cat(\"\\n\")\n  cat(x$method, \"\\n\")\n  cat(\"Datos:\", x$data.name, \"\\n\")\n  cat(\"\\n\")\n  cat(\"Hipótesis:\\n\")\n  if (x$alternative == \"two.sided\") {\n    cat(\"H0: sigma^2 =\", x$null.variance, \"\\n\")\n    cat(\"Ha: sigma^2 ≠\", x$null.variance, \"\\n\")\n  } else if (x$alternative == \"greater\") {\n    cat(\"H0: sigma^2 ≤\", x$null.variance, \"\\n\")\n    cat(\"Ha: sigma^2 &gt;\", x$null.variance, \"\\n\")\n  } else {\n    cat(\"H0: sigma^2 ≥\", x$null.variance, \"\\n\")\n    cat(\"Ha: sigma^2 &lt;\", x$null.variance, \"\\n\")\n  }\n  cat(\"\\n\")\n  cat(\"Estadísticos de la muestra:\\n\")\n  cat(\"n =\", x$sample.size, \"\\n\")\n  cat(\"s^2 =\", round(x$sample.variance, 4), \"\\n\")\n  cat(\"\\n\")\n  cat(\"Estadístico de prueba:\\n\")\n  cat(\"Chi-cuadrado =\", round(x$statistic, 4), \"\\n\")\n  cat(\"Grados de libertad =\", x$parameter, \"\\n\")\n  cat(\"\\n\")\n  cat(\"Valor crítico(s):\\n\")\n  if (length(x$critical.value) == 2) {\n    cat(\"Chi^2(\", x$alpha/2, \",\", x$parameter, \") =\",\n        round(x$critical.value[1], 4), \"\\n\")\n    cat(\"Chi^2(\", 1-x$alpha/2, \",\", x$parameter, \") =\",\n        round(x$critical.value[2], 4), \"\\n\")\n  } else {\n    cat(\"Chi^2 crítico =\", round(x$critical.value, 4), \"\\n\")\n  }\n  cat(\"\\n\")\n  cat(\"Valor-p =\", round(x$p.value, 6), \"\\n\")\n  cat(\"Nivel de significancia =\", x$alpha, \"\\n\")\n  cat(\"\\n\")\n  cat(\"Decisión:\", x$decision, \"\\n\")\n  cat(\"\\n\")\n}\n\nEsta función cuenta con la siguiente sintaxis para su uso:\n\\[ \\Large \\text{var\\_test\\_chi}(x, sigma0_2, alternative, alpha) \\] Argumentos en orden:\n\nx: Vector con los datos de la muestra\nsigma0_2: Varianza poblacional con la que se está comparando\nalternative: Opción en carácter que indica el tipo de prueba utilizando los mismos argumentos que las otras funciones “greater”, “less” y “two.sided”.\nalpha: nivel de significancia\n\nTambién tiene la siguiente sintaxis cuando no se cuenta con los datos de la muestra directamente:\n\\[ \\Large \\text{var\\_test\\_chi}(n, s2, sigma0_2, alternative, alpha) \\] Argumentos en orden:\n\nn: Tamaño de la muestra\ns2: Varianza muestral\nsigma0_2: Varianza poblacional con la que se está comparando\nalternative: Opción en carácter que indica el tipo de prueba utilizando los mismos argumentos que las otras funciones “greater”, “less” y “two.sided”.\nalpha: nivel de significancia\n\nb) Dos varianzas (F de Fisher):\n\\[\\huge F = \\frac{s_1^2}{s_2^2}\\]\ndonde:\n\n\\(s_1^2\\) y \\(s_2^2\\) son las varianzas muestrales de los dos grupos,\n\\(n_1\\) y \\(n_2\\) son los tamaños de muestra de cada grupo.\n\n\n\n17.6.3 Ejemplo hipotético (una varianza)\nSupóngase que una empresa agrícola establece que la varianza máxima aceptable en el peso de frutos de tomate es de \\(\\sigma_0^2 = 4\\) g². Se toma una muestra de 10 frutos y se obtiene una varianza muestral de \\(s^2 = 5.8\\) g². Se desea saber, con un nivel de significancia del 5%, si la variabilidad excede el estándar.\n1. Planteamiento de hipótesis:\n\n\\(H_0: \\sigma^2 = 4\\) g² (la varianza cumple el estándar)\n\\(H_a: \\sigma^2 &gt; 4\\) g² (la varianza excede el estándar)\n\n2. Cálculo del estadístico:\n\\[\\LARGE \\chi^2 = \\frac{(10-1) \\times 5.8}{4} = \\frac{52.2}{4} = 13.05\\]\nDecisión:\nEl valor crítico para \\(\\alpha = 0.05\\) y \\(gl = 9\\) es \\(\\chi^2\\_{0.05,9} = 16.92\\). Como \\(13.05 &lt; 16.92\\), no se rechaza \\(H_0\\)​.\nCódigo en R explicado:\n\n# Aplicacion de la funcion personalizada\nvar_test_chi(n = 10, s2 = 5.8,\n                              sigma0_2 = 4,\n                              alternative = \"greater\",\n                              alpha = 0.05)\n\n\nPrueba de hipótesis para una varianza (Chi-cuadrado) \nDatos: NULL \n\nHipótesis:\nH0: sigma^2 ≤ 4 \nHa: sigma^2 &gt; 4 \n\nEstadísticos de la muestra:\nn = 10 \ns^2 = 5.8 \n\nEstadístico de prueba:\nChi-cuadrado = 13.05 \nGrados de libertad = 9 \n\nValor crítico(s):\nChi^2 crítico = 16.919 \n\nValor-p = 0.160357 \nNivel de significancia = 0.05 \n\nDecisión: No rechazar H0 \n\n\nPara la solución de este problema se emplea la funcion personalizada var_test_chique permite realizar una prueba de hipotesis de la varianza para una muestra empleando los argumentos mencionados en la sección donde se presentó la función.\n\n\n17.6.4 Ejemplo hipotético (dos varianzas)\nSe desea comparar la varianza del rendimiento de dos tratamientos de riego.\nDatos:\n\nTratamiento 1: 10, 12, 11, 13, 12, 11, 14, 13\nTratamiento 2: 9, 10, 11, 10, 12, 10, 11, 10\n\nPlanteamiento de hipótesis:\n\n\\(H_0: \\sigma_1^2 = \\sigma_2^2\\)​ (las varianzas son iguales)\n\\(H_a: \\sigma_1^2 \\neq \\sigma_2^2\\) (las varianzas son diferentes)\n\nCálculo y decisión en R:\n\ntrat1 &lt;- c(10, 12, 11, 13, 12, 11, 14, 13)\ntrat2 &lt;- c(9, 10, 11, 10, 12, 10, 11, 10)\n\nvar.test(trat1, trat2,\n         alternative = \"two.sided\", # prueba bilateral\n         conf.level = 0.95)         # nivel de confianza\n\n\n    F test to compare two variances\n\ndata:  trat1 and trat2\nF = 2.0426, num df = 7, denom df = 7, p-value = 0.3667\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  0.408927 10.202368\nsample estimates:\nratio of variances \n          2.042553 \n\n\n\nvar.test: realiza la prueba F para comparar varianzas.\nalternative: define si la prueba es bilateral o unilateral.\nconf.level: establece el nivel de confianza.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Pruebas de Hipótesis Paramétricas en R</span>"
    ]
  },
  {
    "objectID": "C11.1.html",
    "href": "C11.1.html",
    "title": "18  Análisis de correlación lineal simple",
    "section": "",
    "text": "18.1 Covarianza\nEl análisis de correlación lineal simple permite cuantificar el grado de asociación lineal entre dos variables cuantitativas. En agronomía, este análisis es fundamental para evaluar relaciones como el diámetro y el peso de frutos, o el contenido de materia orgánica y calcio en suelos (López & González, 2018). La correlación no implica causalidad, pero sí proporciona una medida objetiva de la fuerza y dirección de la relación lineal entre dos variables (Moore et al., 2017).\nLa covarianza mide la tendencia conjunta de dos variables a aumentar o disminuir simultáneamente. Su valor puede ser positivo, negativo o cero, pero su magnitud depende de las unidades de las variables, lo que dificulta la comparación entre estudios.\nLa covarianza poblacional se define como:\n\\[\\LARGE \\operatorname{Cov}(X, Y) = \\mathrm{E}[(X - \\mu_X)(Y - \\mu_Y)] \\]\nEl estimador muestral de la covarianza es:\n\\[\\LARGE \\hat{\\operatorname{Cov}}(X, Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y}) \\]\nEjemplo paso a paso:\nConsidérese los siguientes datos de peso de padres (\\(X\\)) y peso de hijos (\\(Y\\)) en kilogramos:\n\\[\\begin{array}{ccccccccccc}   \nx_i & 78 & 65 & 86 & 68 & 83 & 68 & 75 & 80 & 82 & 66 \\\\   \ny_i & 60 & 52 & 68 & 53 & 65 & 57 & 58 & 62 & 65 & 53 \\\\   \n\\end{array} \\]​\n\\[\\LARGE \\bar{x} = \\frac{78 + 65 + \\ldots + 66}{10} = 75.1\\]\n\\[\\LARGE \\bar{y} = \\frac{60 + 52 + \\ldots + 53}{10} = 59.3\\]\n\\[\\LARGE (x_i - \\bar{x})(y_i - \\bar{y}) (xi​−xˉ)(yi​−yˉ​)\\]\nPor ejemplo, para el primer par:\n\\[\\Large (78 - 75.1)(60 - 59.3) = 2.9 \\times 0.7 = 2.03 \\]\nSe repite para cada par y se suman los resultados:\n\\[\\LARGE \\sum_{i=1}^{10} (x_i - \\bar{x})(y_i - \\bar{y}) = 386.7 \\]\n\\[\\LARGE \\hat{\\operatorname{Cov}}(X, Y) = \\frac{386.7}{10-1} = 42.97 \\]",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Análisis de correlación lineal simple</span>"
    ]
  },
  {
    "objectID": "C11.1.html#covarianza",
    "href": "C11.1.html#covarianza",
    "title": "18  Análisis de correlación lineal simple",
    "section": "",
    "text": "Calcular las medias:\n\n\n\nCalcular las diferencias respecto a la media y sus productos:\n\n\n\n\n\n\n\nCalcular la covarianza:",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Análisis de correlación lineal simple</span>"
    ]
  },
  {
    "objectID": "C11.1.html#coeficiente-de-correlación-de-pearson",
    "href": "C11.1.html#coeficiente-de-correlación-de-pearson",
    "title": "18  Análisis de correlación lineal simple",
    "section": "18.2 Coeficiente de correlación de Pearson",
    "text": "18.2 Coeficiente de correlación de Pearson\nEl coeficiente de correlación de Pearson (\\(r\\)) es una medida adimensional que cuantifica la fuerza y dirección de la relación lineal entre dos variables. Su valor oscila entre -1 y 1.\nDefinición poblacional:\n\\[\\huge \\rho = \\frac{\\operatorname{Cov}(X, Y)}{\\sigma_X \\sigma_Y}  \\]\nEstimador muestral:\n\\[\\huge r = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}   {\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}}\\]\nCálculo paso a paso:\n\nCalcular las sumas de cuadrados:\n\n\\[\\huge S_{xx} = \\sum_{i=1}^{n} (x_i - \\bar{x})^2 \\]\n\\[\\huge S_{yy} = \\sum_{i=1}^{n} (y_i - \\bar{y})^2\\]\n\nCalcular el numerador y denominador:\n\n\\[\\LARGE \\text{Numerador} = \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y}) = 386.7\\]\n\\[\\huge \\text{Denominador} = \\sqrt{S_{xx} \\cdot S_{yy}} \\]\nSupóngase que \\(S_{xx} = 546.9\\) y \\(S_{yy} = 288.1\\):\n\\[\\Large \\text{Denominador} = \\sqrt{546.9 \\times 288.1} = \\sqrt{157,561.89} = 396.9  \\]\n\nCalcular r:\n\n\\[\\huge r = \\frac{386.7}{396.9} = 0.974\\]\nInterpretación: Un valor de \\(r = 0.974\\) indica una asociación lineal positiva muy fuerte entre las variables.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Análisis de correlación lineal simple</span>"
    ]
  },
  {
    "objectID": "C11.1.html#prueba-de-significancia-para-el-coeficiente-de-correlación",
    "href": "C11.1.html#prueba-de-significancia-para-el-coeficiente-de-correlación",
    "title": "18  Análisis de correlación lineal simple",
    "section": "18.3 Prueba de significancia para el coeficiente de correlación",
    "text": "18.3 Prueba de significancia para el coeficiente de correlación\nPara determinar si la correlación observada es estadísticamente significativa, se utiliza la siguiente hipótesis:\n\n\\(H_0: \\rho = 0\\) (no hay correlación lineal)\n\\(H_1: \\rho \\neq =0\\) (existe correlación lineal)\n\nEl estadístico de prueba es:\n\\[\\huge t = \\frac{r \\sqrt{n-2}}{\\sqrt{1 - r^2}}\\]\nEste estadístico sigue una distribución t de Student con \\(n-2\\) grados de libertad.\nEjemplo:\nCon \\(r = 0.974\\) y \\(n = 10\\):\n\\[\n\\LARGE\n\\begin{array}{l}\nt = \\frac{0.974 \\sqrt{10-2}}{\\sqrt{1 - 0.974^2}}  \\\\\n= \\frac{0.974 \\times 2.828}{\\sqrt{1 - 0.949}} \\\\\n= \\frac{2.754}{\\sqrt{0.051}} \\\\\n= \\frac{2.754}{0.226} \\\\\n= 12.19\n\\end{array}\n\\] Se compara el valor calculado con el valor crítico de t para \\(n-2 = 8\\) grados de libertad y el nivel de significancia deseado (por ejemplo, \\(\\alpha = 0.05\\). Si \\(|t| &gt; t_{crítico}\\), se rechaza \\(H_0\\).",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Análisis de correlación lineal simple</span>"
    ]
  },
  {
    "objectID": "C11.1.html#uso-de-funciones-en-r",
    "href": "C11.1.html#uso-de-funciones-en-r",
    "title": "18  Análisis de correlación lineal simple",
    "section": "18.4 Uso de funciones en R",
    "text": "18.4 Uso de funciones en R\n\n18.4.1 Función cov()\nLa función cov() permite calcular la covarianza muestral entre dos vectores numéricos. Su sintaxis general es:\n\ncov(x, \n    y, \n    use = \"everything\", \n    method = \"pearson\")\n\nArgumentos principales:\nLos argumentos principales son los siguientes:\n\nx, y: vectores numéricos que contienen los datos de las dos variables a comparar.\nuse: especifica el método para el tratamiento de valores faltantes. Por ejemplo, \"everything\" utiliza todos los datos, mientras que \"complete.obs\" excluye las observaciones con valores faltantes.\nmethod: indica el tipo de covarianza a calcular. El valor por defecto es \"pearson\", que corresponde a la covarianza clásica.\n\n\n\n18.4.2 Función cor()\nLa función cor() se utiliza para calcular el coeficiente de correlación entre dos vectores numéricos. La sintaxis básica es:\n\ncor(x, \n    y, \n    method = \"pearson\")\n\nArgumentos principales:\n\nx, y: vectores numéricos que representan las variables de interés.\nmethod: define el tipo de correlación a calcular. Puede tomar los valores \"pearson\" (por defecto, para correlación lineal), \"spearman\" (para correlación de rangos) o \"kendall\" (para correlación de concordancia).\n\n\n\n18.4.3 Función cor.test()\nLa función cor.test() realiza una prueba de hipótesis para el coeficiente de correlación entre dos variables. Su sintaxis general es:\n\ncor.test(x, \n         y, \n         alternative = \"two.sided\", \n         method = \"pearson\", \n         conf.level = 0.95)\n\nArgumentos principales:\n\nx, y: vectores numéricos que contienen los datos de las variables a analizar.\nalternative: especifica la hipótesis alternativa. Puede ser \"two.sided\" (prueba bilateral), \"less\" (prueba unilateral para correlación negativa) o \"greater\" (prueba unilateral para correlación positiva).\nmethod: determina el tipo de correlación a evaluar. Puede ser \"pearson\", \"spearman\" o \"kendall\".\nconf.level: establece el nivel de confianza para el intervalo del coeficiente de correlación, siendo el valor por defecto 0.95 (95%).\n\n\n\n18.4.4 Resolución del ejemplo en R\n\n# Importación de los valores\n# Datos del ejemplo: peso de padres (X) y peso de hijos (Y) en kilogramos\ndatos &lt;- data.frame(\n  Peso_Padres = c(78, 65, 86, 68, 83, 68, 75, 80, 82, 66),\n  Peso_Hijos = c(60, 52, 68, 53, 65, 57, 58, 62, 65, 53)\n)\n\n# Calculo de la suma de cuadrados (Sxx)\nsum((datos$Peso_Padres-mean(datos$Peso_Padres))^2)\n\n[1] 546.9\n\n# Calculo de la suma de cuadrados (Syy)\nsum((datos$Peso_Hijos-mean(datos$Peso_Hijos))^2)\n\n[1] 288.1\n\n# Calculo de la covarianza\ncov(datos$Peso_Padres,datos$Peso_Hijos)\n\n[1] 42.96667\n\n# Calculo del coeficiente de correalción\ncor(datos$Peso_Padres,datos$Peso_Hijos)\n\n[1] 0.974201\n\n# Test de correlación\ncor.test(datos$Peso_Padres, datos$Peso_Hijos,\n         alternative = \"two.sided\", \n         method = \"pearson\", conf.level = 0.95)\n\n\n    Pearson's product-moment correlation\n\ndata:  datos$Peso_Padres and datos$Peso_Hijos\nt = 12.209, df = 8, p-value = 1.879e-06\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8912550 0.9940775\nsample estimates:\n     cor \n0.974201 \n\n\nInterpretación: El coeficiente de correlación de Pearson calculado es \\(r = 0.974\\), lo que indica una asociación lineal positiva muy fuerte entre las variables analizadas. El valor del estadístico de prueba es \\(t = 12.209\\) con \\(8\\) grados de libertad, y el valor p asociado es \\(1.879 \\times 10^{-6}\\). Este valor p es considerablemente menor que el nivel de significancia convencional (\\(\\alpha = 0.05\\)), lo que proporciona evidencia estadísticamente significativa para rechazar la hipótesis nula de ausencia de correlación lineal (\\(H_0: \\rho = 0\\)).\nEl intervalo de confianza al 95% para el coeficiente de correlación se encuentra entre \\(0.891\\) y \\(0.994\\), lo que refuerza la conclusión de que la verdadera correlación poblacional es positiva y muy alta.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Análisis de correlación lineal simple</span>"
    ]
  },
  {
    "objectID": "C11.1.html#visualización-gráfica-en-el-análisis-de-correlación-lineal-simple",
    "href": "C11.1.html#visualización-gráfica-en-el-análisis-de-correlación-lineal-simple",
    "title": "18  Análisis de correlación lineal simple",
    "section": "18.5 Visualización Gráfica en el Análisis de Correlación Lineal Simple",
    "text": "18.5 Visualización Gráfica en el Análisis de Correlación Lineal Simple\nLa representación gráfica constituye una herramienta fundamental en el análisis de correlación lineal simple, ya que permite visualizar la naturaleza y fuerza de la relación entre dos variables cuantitativas (López & González, 2018). Los gráficos facilitan la interpretación de los resultados estadísticos y proporcionan una comprensión intuitiva de los datos antes de proceder con los cálculos formales del coeficiente de correlación de Pearson.\n\n18.5.1 Preparación de los Datos\nAntes de generar los gráficos, es necesario extraer los datos del conjunto de datos y organizarlos en vectores individuales para facilitar su manipulación:\n\n# Extraer los datos del dataframe a vectores\nx &lt;- datos$Peso_Padres\ny &lt;- datos$Peso_Hijos\n\nEsta separación permite un manejo más eficiente de las variables y facilita la aplicación de las funciones gráficas de R.\n\n\n18.5.2 Gráfico de Dispersión con Línea de Regresión\nEl diagrama de dispersión representa la herramienta visual más importante para evaluar la correlación lineal, ya que permite observar directamente el patrón de asociación entre las variables (López & González, 2018).\n\n# 1. Gráfico de dispersión básico con línea de regresión\nplot(x, y, \n     main = \"Correlación Lineal Simple\\nPeso Padres vs Peso Hijos\",\n     xlab = \"Peso de Padres (kg)\",\n     ylab = \"Peso de Hijos (kg)\",\n     pch = 19, \n     col = \"darkblue\",\n     cex = 1.2)\n\n# Agregar línea de regresión\nabline(lm(y ~ x), col = \"red\", lwd = 2)\n\n# Agregar líneas de las medias\nabline(v = mean(x), col = \"gray\", lty = 2, lwd = 1)\nabline(h = mean(y), col = \"gray\", lty = 2, lwd = 1)\n\n# Agregar texto con estadísticas\ntext(67, 67, paste(\"r =\", round(cor(x,y), 3)), \n     col = \"red\", font = 2, cex = 1.1)\n\n\n\n\n\n\n\n\nElementos Explicativos:\n\nPuntos de dispersión: Cada punto representa un par de observaciones (xi, yi)\nLínea de regresión: Muestra la tendencia lineal de los datos\nLíneas de medias: Indican los valores promedio de cada variable\nCoeficiente de correlación: Cuantifica la fuerza de la asociación lineal\n\n\n\n18.5.3 Gráfico con Intervalos de Confianza\nEste gráfico avanzado incorpora bandas de confianza que indican la incertidumbre asociada con la línea de regresión estimada.\n\n# 2. Gráfico con intervalos de confianza\nplot(x, y, \n     main = \"Dispersión con Banda de Confianza\",\n     xlab = \"Peso de Padres (kg)\",\n     ylab = \"Peso de Hijos (kg)\",\n     pch = 19, \n     col = \"darkgreen\",\n     cex = 1.2)\n\n# Crear secuencia para línea suave\nx_seq &lt;- seq(min(x), max(x), length.out = 100)\nmodelo &lt;- lm(y ~ x)\npredicciones &lt;- predict(modelo, newdata = data.frame(x = x_seq), \n                       interval = \"confidence\")\n\n# Agregar banda de confianza\npolygon(c(x_seq, rev(x_seq)), \n        c(predicciones[,\"lwr\"], rev(predicciones[,\"upr\"])),\n        col = rgb(0, 0, 1, 0.2), border = NA)\n\n# Línea de regresión\nlines(x_seq, predicciones[,\"fit\"], col = \"blue\", lwd = 2)\n\n\n\n\n\n\n\n\nInterpretación: La banda sombreada representa el intervalo de confianza del 95% para la línea de regresión, indicando el rango de valores donde se espera que se encuentre la verdadera relación poblacional.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Análisis de correlación lineal simple</span>"
    ]
  },
  {
    "objectID": "C11.1.html#mapa-mental-de-las-escalas-de-medición",
    "href": "C11.1.html#mapa-mental-de-las-escalas-de-medición",
    "title": "Análisis de correlación lineal simple",
    "section": "Mapa mental de las escalas de medición",
    "text": "Mapa mental de las escalas de medición\nA continuación, se presenta una aplicación interactiva diseñada para visualizar cómo los diferentes valores del coeficiente de correlación de Pearson (r) se reflejan en un gráfico de dispersión junto con su respectiva línea de tendencia. Esta herramienta facilita la comprensión visual y práctica del concepto de correlación lineal simple, permitiendo observar de manera dinámica cómo varía la relación entre dos variables a medida que cambia el valor de r.\nPara explorar la aplicación y experimentar con distintos escenarios de correlación, se recomienda acceder al siguiente enlace: https://ludwing-mj.shinyapps.io/pearson/.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Análisis de correlación lineal simple</span>"
    ]
  },
  {
    "objectID": "C11.1.html#simulación-interactiva-del-coeficiente-de-pearson",
    "href": "C11.1.html#simulación-interactiva-del-coeficiente-de-pearson",
    "title": "18  Análisis de correlación lineal simple",
    "section": "18.6 Simulación interactiva del coeficiente de Pearson",
    "text": "18.6 Simulación interactiva del coeficiente de Pearson\nA continuación, se presenta una aplicación interactiva diseñada para visualizar cómo los diferentes valores del coeficiente de correlación de Pearson (r) se reflejan en un gráfico de dispersión junto con su respectiva línea de tendencia. Esta herramienta facilita la comprensión visual y práctica del concepto de correlación lineal simple, permitiendo observar de manera dinámica cómo varía la relación entre dos variables a medida que cambia el valor de r.\nPara explorar la aplicación y experimentar con distintos escenarios de correlación, se recomienda acceder al siguiente enlace: https://ludwing-mj.shinyapps.io/pearson/.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Análisis de correlación lineal simple</span>"
    ]
  },
  {
    "objectID": "C11.2.html",
    "href": "C11.2.html",
    "title": "19  Regresión Lineal Simple usando R",
    "section": "",
    "text": "19.1 Fundamentos Teóricos\nLa regresión lineal simple es una técnica estadística fundamental para analizar la relación entre dos variables cuantitativas, permitiendo modelar y predecir el comportamiento de una variable dependiente a partir de una variable independiente. En el contexto de la agronomía, esta herramienta resulta esencial para comprender fenómenos como la relación entre el peso en cultivos o animales, entre otros ejemplos relevantes (Montgomery et al., 2021; López & González, 2018).\nEl modelo de regresión lineal simple se expresa mediante la siguiente ecuación:\n\\[\\huge Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i\\]\nEn esta expresión:\nEl objetivo de la regresión es estimar los valores de \\(\\beta_0\\)​ y \\(\\beta_1\\)​ que mejor se ajustan a los datos observados. Para ello, se utiliza el método de mínimos cuadrados, que minimiza la suma de los cuadrados de las diferencias entre los valores observados y los valores predichos por el modelo (Montgomery et al., 2021).\nLas fórmulas para los estimadores de mínimos cuadrados son:\n\\[\\LARGE \\hat{\\beta_1} = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}\\]\n\\[\\LARGE \\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x}\\]\ndonde \\(\\bar{x}\\) y \\(\\bar{y}\\) son las medias de las variables \\(X\\) y \\(Y\\) respectivamente.",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Regresión Lineal Simple usando R</span>"
    ]
  },
  {
    "objectID": "C11.2.html#marco-teórico",
    "href": "C11.2.html#marco-teórico",
    "title": "Regresión Lineal Simple usando R",
    "section": "",
    "text": "Modelo de Regresión Lineal Simple\nEl modelo poblacional se expresa matemáticamente como:\n\\[\\huge Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i\\]\ndonde \\(Y_i\\) representa la variable dependiente, \\(X_i\\) la variable independiente, \\(\\beta_0\\) el intercepto poblacional, \\(\\beta_1\\) la pendiente poblacional, y \\(\\varepsilon_i\\) el término de error aleatorio.\n\n\nEstimadores de Mínimos Cuadrados\nLos estimadores se obtienen mediante las siguientes fórmulas:\n\\[\\LARGE \\hat{\\beta_1} = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}\\]\n\\[\\LARGE \\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x}\\]\n\n\nSupuestos del Modelo\nEl modelo de regresión lineal simple requiere el cumplimiento de cuatro supuestos fundamentales:\n\nLinealidad: La relación entre X e Y es lineal\nNormalidad: Los errores siguen una distribución normal\nHomocedasticidad: La varianza de los errores es constante\nIndependencia: Las observaciones son independientes entre sí",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Regresión Lineal Simple usando R</span>"
    ]
  },
  {
    "objectID": "C11.2.html#análisis-práctico-en-r",
    "href": "C11.2.html#análisis-práctico-en-r",
    "title": "19  Regresión Lineal Simple usando R",
    "section": "19.3 Análisis Práctico en R",
    "text": "19.3 Análisis Práctico en R\n\n19.3.1 Instalación y carga de paquetes\nEl análisis inicia con la carga de los paquetes especializados y la exploración de los datos:\n\n# Instalación y carga de paquetes necesarios\nif (!require(tidyverse)) install.packages(\"tidyverse\")\nif (!require(car)) install.packages(\"car\")\nif (!require(lmtest)) install.packages(\"lmtest\")\nif (!require(nortest)) install.packages(\"nortest\")\n\nSe recomienda siempre inspeccionar los datos antes de analizarlos. En este ejemplo, se utiliza un conjunto de datos ficticio sobre el peso de padres e hijos empleado para explicar el análisis de correlación lineal:\n\n# Datos del ejemplo: peso de padres (X) y peso de hijos (Y) en kilogramos\ndatos &lt;- data.frame(\n  Peso_Padres = c(78, 65, 86, 68, 83, 68, 75, 80, 82, 66),\n  Peso_Hijos = c(60, 52, 68, 53, 65, 57, 58, 62, 65, 53)\n)\n\nEs recomendable graficar los datos para observar la posible relación lineal:\n\n# Gráfico de dispersión\nggplot(datos, aes(x = Peso_Padres, y = Peso_Hijos)) +\n  geom_point() +\n  labs(title = \"Relación entre el peso de padres e hijos\",\n       x = \"Peso de padres (kg)\",\n       y = \"Peso de hijos (kg)\")\n\n\n\n\n\n\n\n\n\n\n19.3.2 Ajuste del Modelo\nPara ajustar el modelo, se utiliza la función lm(), cuya sintaxis general es:\n\nmodelo &lt;- lm(Y ~ X, data = datos)\n\nEn este caso:\n\nmodelo &lt;- lm(Peso_Hijos ~ Peso_Padres, data = datos)\n\nPara obtener un resumen detallado del modelo, se emplea:\n\nsummary(modelo)\n\n\nCall:\nlm(formula = Peso_Hijos ~ Peso_Padres, data = datos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.35052 -1.11314 -0.02222  0.64948  2.72024 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.19857    4.37024   1.418    0.194    \nPeso_Padres  0.70708    0.05791  12.209 1.88e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.354 on 8 degrees of freedom\nMultiple R-squared:  0.9491,    Adjusted R-squared:  0.9427 \nF-statistic: 149.1 on 1 and 8 DF,  p-value: 1.879e-06\n\n\nEl resumen incluye los coeficientes estimados, sus errores estándar, valores t y p, así como el coeficiente de determinación (\\(R^2\\)), que indica la proporción de la variabilidad de \\(Y\\) explicada por \\(X\\).\n\n\n19.3.3 Evaluación Crítica de Supuestos\n\n19.3.3.1 Supuesto de Linealidad\nSe evalúa mediante el gráfico de residuos vs valores ajustados. Si los residuos se distribuyen aleatoriamente alrededor de cero, el supuesto se considera cumplido.\n\nplot(modelo, which = 1)  # Residuals vs Fitted\n\n\n\n\n\n\n\n\n\n\n19.3.3.2 Supuesto de Normalidad\nSe puede evaluar visualmente con un gráfico Q-Q y mediante pruebas estadísticas como Shapiro-Wilk y Anderson-Darling:\nGráfico Q-Q:\n\n# Gráfico Q-Q\nplot(modelo, which = 2)  # Normal Q-Q\n\n\n\n\n\n\n\n\nPrueba de Shapiro-Wilk:\n\n\\(H_0​\\): Los residuos siguen distribución normal\n\\(H_a\\)​: Los residuos no siguen distribución normal\n\n\nshapiro.test(residuals(modelo))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(modelo)\nW = 0.9049, p-value = 0.2478\n\n\nPrueba de Anderson-Darling (más potente para muestras grandes):\n\nad.test(residuals(modelo))\n\n\n    Anderson-Darling normality test\n\ndata:  residuals(modelo)\nA = 0.36544, p-value = 0.3604\n\n\n\n\n19.3.3.3 Supuesto de Homocedasticidad\nSe evalúa con la Prueba de Breusch-Pagan:\n\n\\(H_0\\)​: Varianza constante (homocedasticidad)\n\\(H_a\\)​: Varianza no constante (heterocedasticidad)\n\n\nbptest(modelo)\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo\nBP = 0.71286, df = 1, p-value = 0.3985\n\n\n\n\n19.3.3.4 Supuesto de independencia\nEn estudios experimentales, la independencia suele garantizarse mediante un diseño adecuado. En estudios observacionales, se recomienda analizar el contexto y, si es posible, realizar pruebas adicionales.",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Regresión Lineal Simple usando R</span>"
    ]
  },
  {
    "objectID": "C11.2.html#interpretación-de-resultados",
    "href": "C11.2.html#interpretación-de-resultados",
    "title": "19  Regresión Lineal Simple usando R",
    "section": "19.5 Interpretación de Resultados",
    "text": "19.5 Interpretación de Resultados\n\n19.5.1 Coeficientes del Modelo\n\nIntercepto (\\(\\hat{\\beta_0}\\)​): Valor esperado de Y cuando X = 0\nPendiente (\\(\\hat{\\beta_1}\\)​): Cambio promedio en Y por unidad de cambio en X\n\n\n\n19.5.2 Bondad de Ajuste\nEl coeficiente de determinación (\\(R^2\\)) indica la proporción de variabilidad explicada:\n\\[\\huge R^2 = \\frac{SC_{Regresión}}{SC_{Total}}\\]\n​\n\n\\(R^2 &gt; 0.7\\): Ajuste bueno\n\\(-0.5 &lt; R^2 &lt; 0.7\\): Ajuste moderado\n\\(R^2 &lt; 0.5\\): Ajuste pobre\n\n\n\n19.5.3 Significancia Estadística\nLa prueba F global evalúa:\n\n\\(H_0\\)​: \\(\\beta_1 = 0\\) (no hay relación lineal)\n\\(H_a\\)​: \\(\\beta_1 \\neq 0\\) (existe relación lineal)\n\n\n\n19.5.4 Criterios de Decisión para los supuestos\n\n\n\nSupuesto\nPrueba\nCriterio de Aceptación\n\n\n\n\nNormalidad\nShapiro-Wilk\np-valor &gt; 0.05\n\n\nHomocedasticidad\nBreusch-Pagan\np-valor &gt; 0.05\n\n\nLinealidad\nGráfico residuos\nPatrón aleatorio\n\n\nIndependencia\nContexto experimental\nDiseño adecuado\n\n\n\n\n\n19.5.5 Pasos para una Interpretación Integral y Conclusiones\n\nEvaluar significancia del modelo (prueba F global)\nVerificar supuestos mediante pruebas estadísticas y gráficos\nInterpretar coeficientes en el contexto del problema\nEvaluar bondad de ajuste (\\(R^2\\) y \\(R^2\\) ajustado)\nIdentificar limitaciones del modelo\nFormular recomendaciones prácticas",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Regresión Lineal Simple usando R</span>"
    ]
  },
  {
    "objectID": "C11.2.html#aplicaciones-prácticas",
    "href": "C11.2.html#aplicaciones-prácticas",
    "title": "Regresión Lineal Simple usando R",
    "section": "Aplicaciones Prácticas",
    "text": "Aplicaciones Prácticas\n\nPredicción para Nuevos Datos\n\n# Nuevos pesos de padres\nnuevos_pesos &lt;- data.frame(Peso_Padres = c(60, 75, 80))\npredicciones &lt;- predict(modelo, nuevos_pesos, interval = \"prediction\")\npredicciones\n\n       fit      lwr      upr\n1 48.62315 44.77666 52.46963\n2 59.22929 55.95375 62.50484\n3 62.76467 59.42443 66.10492",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Regresión Lineal Simple usando R</span>"
    ]
  },
  {
    "objectID": "C11.2.html#criterios-de-decisión",
    "href": "C11.2.html#criterios-de-decisión",
    "title": "Regresión Lineal Simple usando R",
    "section": "Criterios de Decisión",
    "text": "Criterios de Decisión\n\n\n\nSupuesto\nPrueba\nCriterio de Aceptación\n\n\n\n\nNormalidad\nShapiro-Wilk\np-valor &gt; 0.05\n\n\nHomocedasticidad\nBreusch-Pagan\np-valor &gt; 0.05\n\n\nLinealidad\nGráfico residuos\nPatrón aleatorio\n\n\nIndependencia\nContexto experimental\nDiseño adecuado",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Regresión Lineal Simple usando R</span>"
    ]
  },
  {
    "objectID": "C11.2.html#interpretación-integral-y-conclusiones",
    "href": "C11.2.html#interpretación-integral-y-conclusiones",
    "title": "Regresión Lineal Simple usando R",
    "section": "Interpretación Integral y Conclusiones",
    "text": "Interpretación Integral y Conclusiones\n\nEvaluar significancia del modelo (prueba F global)\nVerificar supuestos mediante pruebas estadísticas y gráficos\nInterpretar coeficientes en el contexto del problema\nEvaluar bondad de ajuste (\\(R^2\\) y \\(R^2\\) ajustado)\nIdentificar limitaciones del modelo\nFormular recomendaciones prácticas",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Regresión Lineal Simple usando R</span>"
    ]
  },
  {
    "objectID": "C11.2.html#fundamentos-teóricos",
    "href": "C11.2.html#fundamentos-teóricos",
    "title": "19  Regresión Lineal Simple usando R",
    "section": "",
    "text": "\\(Y_i\\) representa el valor observado de la variable dependiente para el individuo i.\n\\(X_i\\) es el valor observado de la variable independiente para el individuo i.\n\\(\\beta_0\\) es el intercepto o constante, que indica el valor esperado de \\(Y\\) cuando \\(X=0\\).\n\\(\\beta_1\\) es la pendiente, que representa el cambio promedio en \\(Y\\) por cada unidad de cambio en \\(X\\).\n\\(\\varepsilon_i\\) es el término de error aleatorio, que recoge la variabilidad no explicada por el modelo.",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Regresión Lineal Simple usando R</span>"
    ]
  },
  {
    "objectID": "C11.2.html#supuestos-del-modelo",
    "href": "C11.2.html#supuestos-del-modelo",
    "title": "19  Regresión Lineal Simple usando R",
    "section": "19.2 Supuestos del Modelo",
    "text": "19.2 Supuestos del Modelo\nPara que los resultados de la regresión lineal simple sean válidos, es necesario que se cumplan los siguientes supuestos (López & González, 2018):\n\nLinealidad: La relación entre la variable independiente y la dependiente debe ser lineal. Esto significa que el efecto de \\(X\\) sobre \\(Y\\) es constante a lo largo de todo el rango de valores.\nNormalidad de los errores: Los residuos (diferencias entre los valores observados y los predichos) deben seguir una distribución normal.\nHomocedasticidad: La varianza de los errores debe ser constante para todos los valores de \\(X\\).\nIndependencia: Las observaciones deben ser independientes entre sí, es decir, el valor de una observación no debe influir en el valor de otra.\n\nEl incumplimiento de estos supuestos puede llevar a conclusiones erróneas o a una interpretación incorrecta de los resultados.",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Regresión Lineal Simple usando R</span>"
    ]
  },
  {
    "objectID": "C11.2.html#predicción-con-el-modelo-ajustado",
    "href": "C11.2.html#predicción-con-el-modelo-ajustado",
    "title": "19  Regresión Lineal Simple usando R",
    "section": "19.4 Predicción con el modelo ajustado",
    "text": "19.4 Predicción con el modelo ajustado\nUna vez ajustado el modelo, se pueden realizar predicciones para nuevos valores de la variable independiente:\n\n# Nuevos valores de Peso_Padres\nnuevos_pesos &lt;- data.frame(Peso_Padres = c(60, 75, 80))\n\n# Predicción con intervalos de predicción\npredicciones &lt;- predict(modelo, nuevos_pesos, interval = \"prediction\")\npredicciones\n\n       fit      lwr      upr\n1 48.62315 44.77666 52.46963\n2 59.22929 55.95375 62.50484\n3 62.76467 59.42443 66.10492\n\n\nEl resultado incluye el valor predicho y los límites inferior y superior del intervalo de predicción para cada nuevo valor.",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Regresión Lineal Simple usando R</span>"
    ]
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "Licencia",
    "section": "",
    "text": "Creative Commons Legal Code\nCC0 1.0 Universal\nCREATIVE COMMONS CORPORATION IS NOT A LAW FIRM AND DOES NOT PROVIDE\nLEGAL SERVICES. DISTRIBUTION OF THIS DOCUMENT DOES NOT CREATE AN\nATTORNEY-CLIENT RELATIONSHIP. CREATIVE COMMONS PROVIDES THIS\nINFORMATION ON AN \"AS-IS\" BASIS. CREATIVE COMMONS MAKES NO WARRANTIES\nREGARDING THE USE OF THIS DOCUMENT OR THE INFORMATION OR WORKS\nPROVIDED HEREUNDER, AND DISCLAIMS LIABILITY FOR DAMAGES RESULTING FROM\nTHE USE OF THIS DOCUMENT OR THE INFORMATION OR WORKS PROVIDED\nHEREUNDER.\nStatement of Purpose\nThe laws of most jurisdictions throughout the world automatically confer exclusive Copyright and Related Rights (defined below) upon the creator and subsequent owner(s) (each and all, an “owner”) of an original work of authorship and/or a database (each, a “Work”).\nCertain owners wish to permanently relinquish those rights to a Work for the purpose of contributing to a commons of creative, cultural and scientific works (“Commons”) that the public can reliably and without fear of later claims of infringement build upon, modify, incorporate in other works, reuse and redistribute as freely as possible in any form whatsoever and for any purposes, including without limitation commercial purposes. These owners may contribute to the Commons to promote the ideal of a free culture and the further production of creative, cultural and scientific works, or to gain reputation or greater distribution for their Work in part through the use and efforts of others.\nFor these and/or other purposes and motivations, and without any expectation of additional consideration or compensation, the person associating CC0 with a Work (the “Affirmer”), to the extent that he or she is an owner of Copyright and Related Rights in the Work, voluntarily elects to apply CC0 to the Work and publicly distribute the Work under its terms, with knowledge of his or her Copyright and Related Rights in the Work and the meaning and intended legal effect of CC0 on those rights.\n\nCopyright and Related Rights. A Work made available under CC0 may be protected by copyright and related or neighboring rights (“Copyright and Related Rights”). Copyright and Related Rights include, but are not limited to, the following:\n\n\n\nthe right to reproduce, adapt, distribute, perform, display, communicate, and translate a Work;\nmoral rights retained by the original author(s) and/or performer(s);\npublicity and privacy rights pertaining to a person’s image or likeness depicted in a Work;\nrights protecting against unfair competition in regards to a Work, subject to the limitations in paragraph 4(a), below;\nrights protecting the extraction, dissemination, use and reuse of data in a Work;\ndatabase rights (such as those arising under Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, and under any national implementation thereof, including any amended or successor version of such directive); and\nother similar, equivalent or corresponding rights throughout the world based on applicable law or treaty, and any national implementations thereof.\n\n\n\nWaiver. To the greatest extent permitted by, but not in contravention of, applicable law, Affirmer hereby overtly, fully, permanently, irrevocably and unconditionally waives, abandons, and surrenders all of Affirmer’s Copyright and Related Rights and associated claims and causes of action, whether now known or unknown (including existing as well as future claims and causes of action), in the Work (i) in all territories worldwide, (ii) for the maximum duration provided by applicable law or treaty (including future time extensions), (iii) in any current or future medium and for any number of copies, and (iv) for any purpose whatsoever, including without limitation commercial, advertising or promotional purposes (the “Waiver”). Affirmer makes the Waiver for the benefit of each member of the public at large and to the detriment of Affirmer’s heirs and successors, fully intending that such Waiver shall not be subject to revocation, rescission, cancellation, termination, or any other legal or equitable action to disrupt the quiet enjoyment of the Work by the public as contemplated by Affirmer’s express Statement of Purpose.\nPublic License Fallback. Should any part of the Waiver for any reason be judged legally invalid or ineffective under applicable law, then the Waiver shall be preserved to the maximum extent permitted taking into account Affirmer’s express Statement of Purpose. In addition, to the extent the Waiver is so judged Affirmer hereby grants to each affected person a royalty-free, non transferable, non sublicensable, non exclusive, irrevocable and unconditional license to exercise Affirmer’s Copyright and Related Rights in the Work (i) in all territories worldwide, (ii) for the maximum duration provided by applicable law or treaty (including future time extensions), (iii) in any current or future medium and for any number of copies, and (iv) for any purpose whatsoever, including without limitation commercial, advertising or promotional purposes (the “License”). The License shall be deemed effective as of the date CC0 was applied by Affirmer to the Work. Should any part of the License for any reason be judged legally invalid or ineffective under applicable law, such partial invalidity or ineffectiveness shall not invalidate the remainder of the License, and in such case Affirmer hereby affirms that he or she will not (i) exercise any of his or her remaining Copyright and Related Rights in the Work or (ii) assert any associated claims and causes of action with respect to the Work, in either case contrary to Affirmer’s express Statement of Purpose.\nLimitations and Disclaimers.\n\n\n\nNo trademark or patent rights held by Affirmer are waived, abandoned, surrendered, licensed or otherwise affected by this document.\nAffirmer offers the Work as-is and makes no representations or warranties of any kind concerning the Work, express, implied, statutory or otherwise, including without limitation warranties of title, merchantability, fitness for a particular purpose, non infringement, or the absence of latent or other defects, accuracy, or the present or absence of errors, whether or not discoverable, all to the greatest extent permissible under applicable law.\nAffirmer disclaims responsibility for clearing rights of other persons that may apply to the Work or any use thereof, including without limitation any person’s Copyright and Related Rights in the Work. Further, Affirmer disclaims responsibility for obtaining any necessary consents, permissions or other rights required for any use of the Work.\nAffirmer understands and acknowledges that Creative Commons is not a party to this document and has no duty or obligation with respect to this CC0 or use of the Work."
  }
]